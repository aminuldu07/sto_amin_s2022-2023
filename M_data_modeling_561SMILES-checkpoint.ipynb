{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b6f533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ALogP</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>AMR</th>\n",
       "      <th>apol</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>ATSm1</th>\n",
       "      <th>ATSm2</th>\n",
       "      <th>ATSm3</th>\n",
       "      <th>ATSm4</th>\n",
       "      <th>...</th>\n",
       "      <th>VAdjMat</th>\n",
       "      <th>MW</th>\n",
       "      <th>WTPT.1</th>\n",
       "      <th>WTPT.2</th>\n",
       "      <th>WTPT.3</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>WPOL</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "      <th>mean_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2H][C@@](C)(NC(=O)COC(F)F)c1cc(F)cc(Cl)c1COc2...</td>\n",
       "      <td>4.9035</td>\n",
       "      <td>24.044312</td>\n",
       "      <td>132.0162</td>\n",
       "      <td>71.093239</td>\n",
       "      <td>60</td>\n",
       "      <td>53.349434</td>\n",
       "      <td>47.297124</td>\n",
       "      <td>70.977093</td>\n",
       "      <td>73.804066</td>\n",
       "      <td>...</td>\n",
       "      <td>6.321928</td>\n",
       "      <td>533.930913</td>\n",
       "      <td>76.681182</td>\n",
       "      <td>2.017926</td>\n",
       "      <td>36.181243</td>\n",
       "      <td>4808</td>\n",
       "      <td>63</td>\n",
       "      <td>4.639</td>\n",
       "      <td>194</td>\n",
       "      <td>1.511929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2H][C@@](N)(CO)C(O)=O</td>\n",
       "      <td>-1.4888</td>\n",
       "      <td>2.216525</td>\n",
       "      <td>22.1161</td>\n",
       "      <td>13.453551</td>\n",
       "      <td>14</td>\n",
       "      <td>9.690430</td>\n",
       "      <td>7.246378</td>\n",
       "      <td>9.368815</td>\n",
       "      <td>8.992028</td>\n",
       "      <td>...</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>105.092711</td>\n",
       "      <td>14.271680</td>\n",
       "      <td>1.783960</td>\n",
       "      <td>11.777389</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.956</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.293797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2H]C([2H])([2H])N(C([2H])([2H])[2H])C([2H])([...</td>\n",
       "      <td>2.2509</td>\n",
       "      <td>5.066551</td>\n",
       "      <td>62.1359</td>\n",
       "      <td>34.790688</td>\n",
       "      <td>31</td>\n",
       "      <td>16.564855</td>\n",
       "      <td>18.002201</td>\n",
       "      <td>24.671700</td>\n",
       "      <td>23.731145</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>204.268694</td>\n",
       "      <td>48.532898</td>\n",
       "      <td>1.941316</td>\n",
       "      <td>32.890133</td>\n",
       "      <td>1278</td>\n",
       "      <td>48</td>\n",
       "      <td>1.633</td>\n",
       "      <td>76</td>\n",
       "      <td>0.148202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2H]C1([2H])[C@H]2C[C@@H](Oc3ccc(cn3)C(F)(F)F)...</td>\n",
       "      <td>3.6800</td>\n",
       "      <td>13.542400</td>\n",
       "      <td>107.9118</td>\n",
       "      <td>60.714274</td>\n",
       "      <td>51</td>\n",
       "      <td>42.011121</td>\n",
       "      <td>41.986894</td>\n",
       "      <td>67.242763</td>\n",
       "      <td>64.111806</td>\n",
       "      <td>...</td>\n",
       "      <td>6.209453</td>\n",
       "      <td>458.409095</td>\n",
       "      <td>71.640211</td>\n",
       "      <td>2.046863</td>\n",
       "      <td>33.229469</td>\n",
       "      <td>3752</td>\n",
       "      <td>61</td>\n",
       "      <td>4.196</td>\n",
       "      <td>184</td>\n",
       "      <td>-0.944121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2H]C1([2H])C([C@@H](CC#N)n2cc(cn2)-c3ncnc4[nH...</td>\n",
       "      <td>2.7411</td>\n",
       "      <td>7.513629</td>\n",
       "      <td>87.7190</td>\n",
       "      <td>48.522274</td>\n",
       "      <td>41</td>\n",
       "      <td>25.216222</td>\n",
       "      <td>28.693159</td>\n",
       "      <td>40.251216</td>\n",
       "      <td>37.588003</td>\n",
       "      <td>...</td>\n",
       "      <td>5.700440</td>\n",
       "      <td>306.365663</td>\n",
       "      <td>62.343269</td>\n",
       "      <td>2.011073</td>\n",
       "      <td>37.936323</td>\n",
       "      <td>2435</td>\n",
       "      <td>65</td>\n",
       "      <td>2.696</td>\n",
       "      <td>124</td>\n",
       "      <td>-0.076593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>OS(O)(=O)=O.C[C@H](N)Cc1ccccc1.C[C@H](N)Cc2ccccc2</td>\n",
       "      <td>1.9234</td>\n",
       "      <td>3.699468</td>\n",
       "      <td>101.1792</td>\n",
       "      <td>58.658204</td>\n",
       "      <td>53</td>\n",
       "      <td>34.945590</td>\n",
       "      <td>34.557962</td>\n",
       "      <td>35.311542</td>\n",
       "      <td>18.332364</td>\n",
       "      <td>...</td>\n",
       "      <td>5.584963</td>\n",
       "      <td>368.492698</td>\n",
       "      <td>47.570246</td>\n",
       "      <td>1.902810</td>\n",
       "      <td>16.789671</td>\n",
       "      <td>200000000068</td>\n",
       "      <td>18</td>\n",
       "      <td>1.760</td>\n",
       "      <td>108</td>\n",
       "      <td>0.446026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>OS(O)(=O)=O.COc1ccc(cc1)S(=O)(=O)NCc2cc(CN3CCC...</td>\n",
       "      <td>1.7642</td>\n",
       "      <td>3.112402</td>\n",
       "      <td>141.8191</td>\n",
       "      <td>81.093755</td>\n",
       "      <td>72</td>\n",
       "      <td>56.531199</td>\n",
       "      <td>60.281187</td>\n",
       "      <td>69.859569</td>\n",
       "      <td>56.323915</td>\n",
       "      <td>...</td>\n",
       "      <td>6.285402</td>\n",
       "      <td>557.683107</td>\n",
       "      <td>73.720532</td>\n",
       "      <td>1.992447</td>\n",
       "      <td>35.620419</td>\n",
       "      <td>160000002987</td>\n",
       "      <td>46</td>\n",
       "      <td>0.840</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.574772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>OS(O)(=O)=O.N[C@H]1C[C@@H]1c2ccccc2.N[C@H]3C[C...</td>\n",
       "      <td>1.0414</td>\n",
       "      <td>1.084514</td>\n",
       "      <td>97.1628</td>\n",
       "      <td>55.991032</td>\n",
       "      <td>49</td>\n",
       "      <td>34.945590</td>\n",
       "      <td>36.557962</td>\n",
       "      <td>35.311542</td>\n",
       "      <td>20.332364</td>\n",
       "      <td>...</td>\n",
       "      <td>5.700440</td>\n",
       "      <td>364.460935</td>\n",
       "      <td>48.425994</td>\n",
       "      <td>1.937040</td>\n",
       "      <td>16.857489</td>\n",
       "      <td>200000000054</td>\n",
       "      <td>20</td>\n",
       "      <td>0.950</td>\n",
       "      <td>124</td>\n",
       "      <td>-1.809539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>OS(O)(=O)=O.O[C@H]1CCN(C1)C(=O)Nc2cnn3ccc(nc23...</td>\n",
       "      <td>1.0149</td>\n",
       "      <td>1.030022</td>\n",
       "      <td>124.6342</td>\n",
       "      <td>68.389032</td>\n",
       "      <td>60</td>\n",
       "      <td>51.938537</td>\n",
       "      <td>53.573697</td>\n",
       "      <td>69.483914</td>\n",
       "      <td>57.391041</td>\n",
       "      <td>...</td>\n",
       "      <td>6.285402</td>\n",
       "      <td>526.515572</td>\n",
       "      <td>72.658877</td>\n",
       "      <td>2.018302</td>\n",
       "      <td>42.006338</td>\n",
       "      <td>155000002643</td>\n",
       "      <td>49</td>\n",
       "      <td>1.310</td>\n",
       "      <td>192</td>\n",
       "      <td>0.620174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>SCCNC(=O)c1cccc(c1)C(=O)NCCS</td>\n",
       "      <td>1.1100</td>\n",
       "      <td>1.232100</td>\n",
       "      <td>77.8512</td>\n",
       "      <td>41.392688</td>\n",
       "      <td>34</td>\n",
       "      <td>32.524405</td>\n",
       "      <td>22.668482</td>\n",
       "      <td>27.775405</td>\n",
       "      <td>29.884190</td>\n",
       "      <td>...</td>\n",
       "      <td>5.169925</td>\n",
       "      <td>284.400269</td>\n",
       "      <td>35.243255</td>\n",
       "      <td>1.957959</td>\n",
       "      <td>15.762500</td>\n",
       "      <td>685</td>\n",
       "      <td>23</td>\n",
       "      <td>2.176</td>\n",
       "      <td>80</td>\n",
       "      <td>-1.703678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SMILES   ALogP     ALogp2  \\\n",
       "0    [2H][C@@](C)(NC(=O)COC(F)F)c1cc(F)cc(Cl)c1COc2...  4.9035  24.044312   \n",
       "1                               [2H][C@@](N)(CO)C(O)=O -1.4888   2.216525   \n",
       "2    [2H]C([2H])([2H])N(C([2H])([2H])[2H])C([2H])([...  2.2509   5.066551   \n",
       "3    [2H]C1([2H])[C@H]2C[C@@H](Oc3ccc(cn3)C(F)(F)F)...  3.6800  13.542400   \n",
       "4    [2H]C1([2H])C([C@@H](CC#N)n2cc(cn2)-c3ncnc4[nH...  2.7411   7.513629   \n",
       "..                                                 ...     ...        ...   \n",
       "556  OS(O)(=O)=O.C[C@H](N)Cc1ccccc1.C[C@H](N)Cc2ccccc2  1.9234   3.699468   \n",
       "557  OS(O)(=O)=O.COc1ccc(cc1)S(=O)(=O)NCc2cc(CN3CCC...  1.7642   3.112402   \n",
       "558  OS(O)(=O)=O.N[C@H]1C[C@@H]1c2ccccc2.N[C@H]3C[C...  1.0414   1.084514   \n",
       "559  OS(O)(=O)=O.O[C@H]1CCN(C1)C(=O)Nc2cnn3ccc(nc23...  1.0149   1.030022   \n",
       "560                       SCCNC(=O)c1cccc(c1)C(=O)NCCS  1.1100   1.232100   \n",
       "\n",
       "          AMR       apol  nAtom      ATSm1      ATSm2      ATSm3      ATSm4  \\\n",
       "0    132.0162  71.093239     60  53.349434  47.297124  70.977093  73.804066   \n",
       "1     22.1161  13.453551     14   9.690430   7.246378   9.368815   8.992028   \n",
       "2     62.1359  34.790688     31  16.564855  18.002201  24.671700  23.731145   \n",
       "3    107.9118  60.714274     51  42.011121  41.986894  67.242763  64.111806   \n",
       "4     87.7190  48.522274     41  25.216222  28.693159  40.251216  37.588003   \n",
       "..        ...        ...    ...        ...        ...        ...        ...   \n",
       "556  101.1792  58.658204     53  34.945590  34.557962  35.311542  18.332364   \n",
       "557  141.8191  81.093755     72  56.531199  60.281187  69.859569  56.323915   \n",
       "558   97.1628  55.991032     49  34.945590  36.557962  35.311542  20.332364   \n",
       "559  124.6342  68.389032     60  51.938537  53.573697  69.483914  57.391041   \n",
       "560   77.8512  41.392688     34  32.524405  22.668482  27.775405  29.884190   \n",
       "\n",
       "     ...   VAdjMat          MW     WTPT.1    WTPT.2     WTPT.3         WPATH  \\\n",
       "0    ...  6.321928  533.930913  76.681182  2.017926  36.181243          4808   \n",
       "1    ...  3.584963  105.092711  14.271680  1.783960  11.777389            62   \n",
       "2    ...  5.000000  204.268694  48.532898  1.941316  32.890133          1278   \n",
       "3    ...  6.209453  458.409095  71.640211  2.046863  33.229469          3752   \n",
       "4    ...  5.700440  306.365663  62.343269  2.011073  37.936323          2435   \n",
       "..   ...       ...         ...        ...       ...        ...           ...   \n",
       "556  ...  5.584963  368.492698  47.570246  1.902810  16.789671  200000000068   \n",
       "557  ...  6.285402  557.683107  73.720532  1.992447  35.620419  160000002987   \n",
       "558  ...  5.700440  364.460935  48.425994  1.937040  16.857489  200000000054   \n",
       "559  ...  6.285402  526.515572  72.658877  2.018302  42.006338  155000002643   \n",
       "560  ...  5.169925  284.400269  35.243255  1.957959  15.762500           685   \n",
       "\n",
       "     WPOL  XLogP  Zagreb  mean_zscore  \n",
       "0      63  4.639     194     1.511929  \n",
       "1       9 -3.956      26    -0.293797  \n",
       "2      48  1.633      76     0.148202  \n",
       "3      61  4.196     184    -0.944121  \n",
       "4      65  2.696     124    -0.076593  \n",
       "..    ...    ...     ...          ...  \n",
       "556    18  1.760     108     0.446026  \n",
       "557    46  0.840     188    -0.574772  \n",
       "558    20  0.950     124    -1.809539  \n",
       "559    49  1.310     192     0.620174  \n",
       "560    23  2.176      80    -1.703678  \n",
       "\n",
       "[561 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('M_data_modeling_561SMILES.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa2a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5123df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 275335475579846656.0000, Val Loss: 738118923278352384.0000\n",
      "Epoch 2, Train Loss: 58381481864593408.0000, Val Loss: 33885466604339200.0000\n",
      "Epoch 3, Train Loss: 24548437483585536.0000, Val Loss: 31309667342745600.0000\n",
      "Epoch 4, Train Loss: 7439273124954112.0000, Val Loss: 24035403640078336.0000\n",
      "Epoch 5, Train Loss: 1713639337754624.0000, Val Loss: 6127645410459648.0000\n",
      "Epoch 6, Train Loss: 210132046708736.0000, Val Loss: 1053875922534400.0000\n",
      "Epoch 7, Train Loss: 231723149295616.0000, Val Loss: 209697902690304.0000\n",
      "Epoch 8, Train Loss: 28519589478400.0000, Val Loss: 108990499389440.0000\n",
      "Epoch 9, Train Loss: 1248597324595200.0000, Val Loss: 66422134800384.0000\n",
      "Epoch 10, Train Loss: 126997242052608.0000, Val Loss: 41777608261632.0000\n",
      "Epoch 11, Train Loss: 13106214338560.0000, Val Loss: 42993520214016.0000\n",
      "Epoch 12, Train Loss: 175399652818944.0000, Val Loss: 38981953650688.0000\n",
      "Epoch 13, Train Loss: 12855761960960.0000, Val Loss: 39785309667328.0000\n",
      "Epoch 14, Train Loss: 23828092682240.0000, Val Loss: 40587709382656.0000\n",
      "Epoch 15, Train Loss: 48556811485184.0000, Val Loss: 39469440827392.0000\n",
      "Epoch 16, Train Loss: 937159045414912.0000, Val Loss: 59330141356032.0000\n",
      "Epoch 17, Train Loss: 189278084661248.0000, Val Loss: 43471280799744.0000\n",
      "Epoch 18, Train Loss: 759427124690944.0000, Val Loss: 48911930621952.0000\n",
      "Epoch 19, Train Loss: 50865436098560.0000, Val Loss: 138047060443136.0000\n",
      "Epoch 20, Train Loss: 153841400020992.0000, Val Loss: 58730573987840.0000\n",
      "Epoch 21, Train Loss: 5121224212480.0000, Val Loss: 33325280395264.0000\n",
      "Epoch 22, Train Loss: 165753676365824.0000, Val Loss: 30007359438848.0000\n",
      "Epoch 23, Train Loss: 10284568674304.0000, Val Loss: 27740845637632.0000\n",
      "Epoch 24, Train Loss: 27458975825920.0000, Val Loss: 28127090704384.0000\n",
      "Epoch 25, Train Loss: 7713555218432.0000, Val Loss: 28800616235008.0000\n",
      "Epoch 26, Train Loss: 17558423994368.0000, Val Loss: 25317754273792.0000\n",
      "Epoch 27, Train Loss: 20762312310784.0000, Val Loss: 23896063475712.0000\n",
      "Epoch 28, Train Loss: 13547217092608.0000, Val Loss: 27016048934912.0000\n",
      "Epoch 29, Train Loss: 14736247750656.0000, Val Loss: 22181178245120.0000\n",
      "Epoch 30, Train Loss: 19025851580416.0000, Val Loss: 22269717905408.0000\n",
      "Epoch 31, Train Loss: 14355417530368.0000, Val Loss: 21970743721984.0000\n",
      "Epoch 32, Train Loss: 915373159350272.0000, Val Loss: 36417795260416.0000\n",
      "Epoch 33, Train Loss: 369572171481088.0000, Val Loss: 25772404244480.0000\n",
      "Epoch 34, Train Loss: 50088319647744.0000, Val Loss: 49340693348352.0000\n",
      "Epoch 35, Train Loss: 43139880452096.0000, Val Loss: 121916220243968.0000\n",
      "Epoch 36, Train Loss: 15387826585600.0000, Val Loss: 73823835652096.0000\n",
      "Epoch 37, Train Loss: 12310135439360.0000, Val Loss: 63566921072640.0000\n",
      "Epoch 38, Train Loss: 370465491124224.0000, Val Loss: 79038043389952.0000\n",
      "Epoch 39, Train Loss: 669287773634560.0000, Val Loss: 62107626242048.0000\n",
      "Epoch 40, Train Loss: 24443774566400.0000, Val Loss: 17554433114112.0000\n",
      "Epoch 41, Train Loss: 173657422823424.0000, Val Loss: 71872217612288.0000\n",
      "Epoch 42, Train Loss: 3451179900076032.0000, Val Loss: 2169411737747456.0000\n",
      "Epoch 43, Train Loss: 40030319935488.0000, Val Loss: 2975089486200832.0000\n",
      "Epoch 44, Train Loss: 25781037262962688.0000, Val Loss: 58817614184448.0000\n",
      "Epoch 45, Train Loss: 238232927207424.0000, Val Loss: 394979553837056.0000\n",
      "Epoch 46, Train Loss: 1502528004947968.0000, Val Loss: 511239553810432.0000\n",
      "Epoch 47, Train Loss: 2529268928086016.0000, Val Loss: 3346911247466496.0000\n",
      "Epoch 48, Train Loss: 10254684317024256.0000, Val Loss: 4852939751424.0000\n",
      "Epoch 49, Train Loss: 4382483965542400.0000, Val Loss: 100368000221184.0000\n",
      "Epoch 50, Train Loss: 274364675531997184.0000, Val Loss: 490872416239616.0000\n",
      "Epoch 51, Train Loss: 253647316664188928.0000, Val Loss: 345889184940032.0000\n",
      "Epoch 52, Train Loss: 7194065925832704.0000, Val Loss: 57388317922033664.0000\n",
      "Epoch 53, Train Loss: 272308605967925248.0000, Val Loss: 254808143245082624.0000\n",
      "Epoch 54, Train Loss: 96198196459470848.0000, Val Loss: 95601754351075328.0000\n",
      "Epoch 55, Train Loss: 15435332925259776.0000, Val Loss: 64653220743479296.0000\n",
      "Epoch 56, Train Loss: 1413594801504256.0000, Val Loss: 12023139248635904.0000\n",
      "Epoch 57, Train Loss: 189269124151508992.0000, Val Loss: 305635782658359296.0000\n",
      "Epoch 58, Train Loss: 10796338748850176.0000, Val Loss: 14497468834119680.0000\n",
      "Epoch 59, Train Loss: 10909046206889984.0000, Val Loss: 4555401764798464.0000\n",
      "Epoch 60, Train Loss: 74488442448248832.0000, Val Loss: 1459550951571456.0000\n",
      "Epoch 61, Train Loss: 23123969703936.0000, Val Loss: 276712411627520.0000\n",
      "Epoch 62, Train Loss: 89739315118080.0000, Val Loss: 258430732337152.0000\n",
      "Epoch 63, Train Loss: 1092473250119680.0000, Val Loss: 36183375609856.0000\n",
      "Epoch 64, Train Loss: 101515125587968.0000, Val Loss: 29862144245760.0000\n",
      "Epoch 65, Train Loss: 117391941959680.0000, Val Loss: 26984834924544.0000\n",
      "Epoch 66, Train Loss: 17085651484672.0000, Val Loss: 26920632713216.0000\n",
      "Epoch 67, Train Loss: 20855184687104.0000, Val Loss: 21609505095680.0000\n",
      "Epoch 68, Train Loss: 15903693471744.0000, Val Loss: 22404648665088.0000\n",
      "Epoch 69, Train Loss: 32698223558656.0000, Val Loss: 18769332142080.0000\n",
      "Epoch 70, Train Loss: 26264784076800.0000, Val Loss: 22185192194048.0000\n",
      "Epoch 71, Train Loss: 6495425527808.0000, Val Loss: 21093372919808.0000\n",
      "Epoch 72, Train Loss: 5478106005504.0000, Val Loss: 15927384997888.0000\n",
      "Epoch 73, Train Loss: 8175333408768.0000, Val Loss: 20107673731072.0000\n",
      "Epoch 74, Train Loss: 9135389147136.0000, Val Loss: 16469677047808.0000\n",
      "Epoch 75, Train Loss: 29609802334208.0000, Val Loss: 15981229375488.0000\n",
      "Epoch 76, Train Loss: 25178673250304.0000, Val Loss: 13093716361216.0000\n",
      "Epoch 77, Train Loss: 15441126752256.0000, Val Loss: 17068940328960.0000\n",
      "Epoch 78, Train Loss: 11512062148608.0000, Val Loss: 13952981401600.0000\n",
      "Epoch 79, Train Loss: 17145353207808.0000, Val Loss: 14892751912960.0000\n",
      "Epoch 80, Train Loss: 22163543293952.0000, Val Loss: 12794381467648.0000\n",
      "Epoch 81, Train Loss: 10347755864064.0000, Val Loss: 13200153116672.0000\n",
      "Epoch 82, Train Loss: 7978145546240.0000, Val Loss: 13642731880448.0000\n",
      "Epoch 83, Train Loss: 10425800327168.0000, Val Loss: 14434124693504.0000\n",
      "Epoch 84, Train Loss: 8253916315648.0000, Val Loss: 14919871234048.0000\n",
      "Epoch 85, Train Loss: 46582326099968.0000, Val Loss: 17506743877632.0000\n",
      "Epoch 86, Train Loss: 11365224808448.0000, Val Loss: 242560761069568.0000\n",
      "Epoch 87, Train Loss: 25973506441216.0000, Val Loss: 50022091587584.0000\n",
      "Epoch 88, Train Loss: 2151557365760.0000, Val Loss: 10454842736640.0000\n",
      "Epoch 89, Train Loss: 13826249457664.0000, Val Loss: 13961620619264.0000\n",
      "Epoch 90, Train Loss: 68539415265280.0000, Val Loss: 9701722947584.0000\n",
      "Epoch 91, Train Loss: 31139555180544.0000, Val Loss: 52557225394176.0000\n",
      "Epoch 92, Train Loss: 10985967452160.0000, Val Loss: 38721332183040.0000\n",
      "Epoch 93, Train Loss: 7671553458176.0000, Val Loss: 133333979758592.0000\n",
      "Epoch 94, Train Loss: 25188372578304000.0000, Val Loss: 116818362499072.0000\n",
      "Epoch 95, Train Loss: 13304570314752.0000, Val Loss: 30246707396608.0000\n",
      "Epoch 96, Train Loss: 6196940505088.0000, Val Loss: 8829329735680.0000\n",
      "Epoch 97, Train Loss: 20031480507924480.0000, Val Loss: 47693766328320.0000\n",
      "Epoch 98, Train Loss: 1910401721696256.0000, Val Loss: 422037512257536.0000\n",
      "Epoch 99, Train Loss: 14594220488654848.0000, Val Loss: 49255037272064.0000\n",
      "Epoch 100, Train Loss: 9474153467871232.0000, Val Loss: 18973851253735424.0000\n"
     ]
    }
   ],
   "source": [
    "# Define custom dataset class to handle data\n",
    "class DescriptorDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x = data.drop(columns=[\"SMILES\", \"mean_zscore\"]).values.astype(float)\n",
    "        self.y = data[\"mean_zscore\"].values.astype(float)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx]), torch.tensor(self.y[idx])\n",
    "    \n",
    "# Define custom neural network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create DataLoader objects for training and validation data\n",
    "train_dataset = DescriptorDataset(train_data)\n",
    "val_dataset = DescriptorDataset(val_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define neural network model\n",
    "net = Net(train_dataset.x.shape[1])\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Train model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs.flatten(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute validation loss\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = net(inputs.float())\n",
    "            val_loss += criterion(outputs.flatten(), labels.float())\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d858cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
