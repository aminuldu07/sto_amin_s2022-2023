{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f68a47f",
   "metadata": {},
   "source": [
    "<h1 style = \"color : navy;\"> QSAR Model Building & Evaluation_MF</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09045f0",
   "metadata": {},
   "source": [
    "## Suppress any warnings for all the upcoming cells\n",
    "- use this function with the \"ignore\" argument to ignore all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3728e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# If there is a specific type of warning that you want to ignore, you can specify this type in the filterwarnings function\n",
    "warnings.filterwarnings('ignore', category=UserWarning) # You would replace UserWarning with the specific warning class\n",
    "                                                        # you wish to ignore.\n",
    "\n",
    "# For the case of ignoring warnings from specific libraries, you can add the module parameter:\n",
    "warnings.filterwarnings('ignore', module='numpy')  # Ignore warnings from numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28532c4b",
   "metadata": {},
   "source": [
    "<h1 style = \" color : red ;\" > Required library</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47b8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6717947",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Machine Learning Model Building and Testing  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d081554",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\">Data Manipulation for machine learning model building</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0f455",
   "metadata": {},
   "source": [
    "<h4 style=\"color:blue;\">Read the \"_MLMB_df_no_zeros_no_nans4x4.csv\" data frame</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38af2a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2030, 194)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>zscore</th>\n",
       "      <th>Target</th>\n",
       "      <th>TSSPECIES</th>\n",
       "      <th>SEX</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>nHeavyAtom</th>\n",
       "      <th>nHetero</th>\n",
       "      <th>ATS0dv</th>\n",
       "      <th>ATS1dv</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW06</th>\n",
       "      <th>SRW08</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1[nH]nc2Nc3cc(ncc3C(=Nc12)c4ccccc4Cl)N5CCOCC5</td>\n",
       "      <td>-44.513706</td>\n",
       "      <td>toxic</td>\n",
       "      <td>DOG</td>\n",
       "      <td>M</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>383.604938</td>\n",
       "      <td>425.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>7.058758</td>\n",
       "      <td>8.686261</td>\n",
       "      <td>10.359170</td>\n",
       "      <td>78.040268</td>\n",
       "      <td>394.130887</td>\n",
       "      <td>8.385764</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>156</td>\n",
       "      <td>189</td>\n",
       "      <td>6.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COc1cc(N(C)CCN(C)C)c(NC(=O)C=C)cc1Nc2nccc(n2)-...</td>\n",
       "      <td>-40.997577</td>\n",
       "      <td>toxic</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.236339</td>\n",
       "      <td>8.843471</td>\n",
       "      <td>10.503724</td>\n",
       "      <td>87.974766</td>\n",
       "      <td>499.269573</td>\n",
       "      <td>7.132422</td>\n",
       "      <td>4557.0</td>\n",
       "      <td>192</td>\n",
       "      <td>226</td>\n",
       "      <td>8.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNC(=O)c1cn(C[C@H](F)CCc2ccc(NC(=O)Cc3cc(OC4CC...</td>\n",
       "      <td>-28.290163</td>\n",
       "      <td>toxic</td>\n",
       "      <td>DOG</td>\n",
       "      <td>F</td>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.296413</td>\n",
       "      <td>8.886686</td>\n",
       "      <td>10.515235</td>\n",
       "      <td>88.468481</td>\n",
       "      <td>532.215821</td>\n",
       "      <td>8.187936</td>\n",
       "      <td>6289.0</td>\n",
       "      <td>198</td>\n",
       "      <td>225</td>\n",
       "      <td>8.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cn1nc(nc1Nc2ccc3[nH]ncc3c2C4CC4)-c5ccc(cc5)C(=...</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>toxic</td>\n",
       "      <td>DOG</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.167809</td>\n",
       "      <td>8.782783</td>\n",
       "      <td>10.447642</td>\n",
       "      <td>88.519310</td>\n",
       "      <td>437.177565</td>\n",
       "      <td>8.248633</td>\n",
       "      <td>3319.0</td>\n",
       "      <td>176</td>\n",
       "      <td>211</td>\n",
       "      <td>6.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1cc(Nc2cc(N)ncn2)c(=O)n3c1C(=O)NC34CCCCC4</td>\n",
       "      <td>-15.928106</td>\n",
       "      <td>toxic</td>\n",
       "      <td>DOG</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.998510</td>\n",
       "      <td>8.683555</td>\n",
       "      <td>10.425757</td>\n",
       "      <td>75.161421</td>\n",
       "      <td>340.164774</td>\n",
       "      <td>7.559217</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>140</td>\n",
       "      <td>171</td>\n",
       "      <td>5.347222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES     zscore Target  \\\n",
       "0    Cc1[nH]nc2Nc3cc(ncc3C(=Nc12)c4ccccc4Cl)N5CCOCC5 -44.513706  toxic   \n",
       "1  COc1cc(N(C)CCN(C)C)c(NC(=O)C=C)cc1Nc2nccc(n2)-... -40.997577  toxic   \n",
       "2  CNC(=O)c1cn(C[C@H](F)CCc2ccc(NC(=O)Cc3cc(OC4CC... -28.290163  toxic   \n",
       "3  Cn1nc(nc1Nc2ccc3[nH]ncc3c2C4CC4)-c5ccc(cc5)C(=... -18.000000  toxic   \n",
       "4        Cc1cc(Nc2cc(N)ncn2)c(=O)n3c1C(=O)NC34CCCCC4 -15.928106  toxic   \n",
       "\n",
       "  TSSPECIES SEX  nAtom  nHeavyAtom  nHetero      ATS0dv      ATS1dv  ...  \\\n",
       "0       DOG   M     47          28        8  383.604938  425.111111  ...   \n",
       "1     MOUSE   M     70          37        9  496.000000  522.000000  ...   \n",
       "2       DOG   F     65          38       14  670.000000  600.000000  ...   \n",
       "3       DOG   M     53          32       10  520.000000  508.000000  ...   \n",
       "4       DOG   F     45          25        8  364.000000  386.000000  ...   \n",
       "\n",
       "      SRW06     SRW08      SRW10     TSRW10          MW       AMW   WPath  \\\n",
       "0  7.058758  8.686261  10.359170  78.040268  394.130887  8.385764  1873.0   \n",
       "1  7.236339  8.843471  10.503724  87.974766  499.269573  7.132422  4557.0   \n",
       "2  7.296413  8.886686  10.515235  88.468481  532.215821  8.187936  6289.0   \n",
       "3  7.167809  8.782783  10.447642  88.519310  437.177565  8.248633  3319.0   \n",
       "4  6.998510  8.683555  10.425757  75.161421  340.164774  7.559217  1390.0   \n",
       "\n",
       "   Zagreb1  Zagreb2  mZagreb2  \n",
       "0      156      189  6.027778  \n",
       "1      192      226  8.277778  \n",
       "2      198      225  8.194444  \n",
       "3      176      211  6.861111  \n",
       "4      140      171  5.347222  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the \"\"unique_SMILES_abs_max_zscore_rat.csv\"\" data frame \n",
    "MLMB_df_no_zeros_no_nans4x4 = pd.read_csv(\"MLMB_df_no_zeros_no_nans4x4.csv\")\n",
    "\n",
    "# print the data frame\n",
    "print(MLMB_df_no_zeros_no_nans4x4.shape)\n",
    "MLMB_df_no_zeros_no_nans4x4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d0e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each unique value:\n",
      "RAT       871\n",
      "DOG       546\n",
      "MOUSE     269\n",
      "MONKEY    223\n",
      "PIG        76\n",
      "RABBIT     41\n",
      "Monkey      2\n",
      "Rat         2\n",
      "Name: TSSPECIES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the unique values in the column TSSPECIES\n",
    "\n",
    "unique_counts = MLMB_df_no_zeros_no_nans4x4['TSSPECIES'].value_counts()\n",
    "print(\"Count of each unique value:\")\n",
    "print(unique_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e50c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# check the data type of a column\n",
    "print(MLMB_df_no_zeros_no_nans4x4['ATS0dv'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "71e4e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic         878\n",
      "mild_toxic    725\n",
      "non_toxic     427\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the unique values in the \"Target\" column\n",
    "target_counts = MLMB_df_no_zeros_no_nans4x4['Target'].value_counts()\n",
    "\n",
    "# Print the unique value counts\n",
    "print(target_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86331620",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> Create new data frame by dropping 'SMILES' & 'zscore' column  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99851e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the df: (2030, 192)\n",
      "(2030, 192)\n",
      "  Target TSSPECIES SEX  nAtom  nHeavyAtom\n",
      "0  toxic       DOG   M     47          28\n",
      "1  toxic     MOUSE   M     70          37\n",
      "2  toxic       DOG   F     65          38\n"
     ]
    }
   ],
   "source": [
    "# Define a new data frame \n",
    "df1 = MLMB_df_no_zeros_no_nans4x4 \n",
    "\n",
    "# Create a new DataFrame without the first two columns\n",
    "df = df1.iloc[:, 2:] \n",
    "\n",
    "print (\"The shape of the df:\", df.shape)\n",
    "print(df.shape)\n",
    "#print(df.head(1))\n",
    "print(df.iloc[:3, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c805f8e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:magenta;\"> 'Target' column encoding by Ordinal encoding </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee19ce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the df: (2030, 192)\n",
      "   Target TSSPECIES SEX\n",
      "0       2       DOG   M\n",
      "1       2     MOUSE   M\n",
      "2       2       DOG   F\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Define an ordinal mapping for your classes\n",
    "ordinal_mapping = {'non_toxic': 0, 'mild_toxic': 1, 'toxic': 2}\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = ce.OrdinalEncoder(mapping=[{'col': 'Target', 'mapping': ordinal_mapping}])\n",
    "\n",
    "# Apply encoder to 'target' column\n",
    "df['Target'] = encoder.fit_transform(df['Target'])\n",
    "\n",
    "# Now 'target' column is ordinal encoded\n",
    "#print(df['target'])\n",
    "print (\"The shape of the df:\", df.shape)\n",
    "#print (df_no_species.head(3))\n",
    "print(df.iloc[:3, :3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ed2e0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:magenta;\"> 'TSSPECIES' &  'SEX'column encoding by onehot encoding </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb211251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2030, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>nHeavyAtom</th>\n",
       "      <th>nHetero</th>\n",
       "      <th>ATS0dv</th>\n",
       "      <th>ATS1dv</th>\n",
       "      <th>ATS0d</th>\n",
       "      <th>ATS1d</th>\n",
       "      <th>ATS0Z</th>\n",
       "      <th>ATS1Z</th>\n",
       "      <th>...</th>\n",
       "      <th>TSSPECIES_DOG</th>\n",
       "      <th>TSSPECIES_MONKEY</th>\n",
       "      <th>TSSPECIES_MOUSE</th>\n",
       "      <th>TSSPECIES_Monkey</th>\n",
       "      <th>TSSPECIES_PIG</th>\n",
       "      <th>TSSPECIES_RABBIT</th>\n",
       "      <th>TSSPECIES_RAT</th>\n",
       "      <th>TSSPECIES_Rat</th>\n",
       "      <th>SEX_F</th>\n",
       "      <th>SEX_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>383.604938</td>\n",
       "      <td>425.111111</td>\n",
       "      <td>175</td>\n",
       "      <td>224</td>\n",
       "      <td>1386</td>\n",
       "      <td>1437</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>225</td>\n",
       "      <td>275</td>\n",
       "      <td>1512</td>\n",
       "      <td>1778</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>225</td>\n",
       "      <td>275</td>\n",
       "      <td>1718</td>\n",
       "      <td>1847</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  nAtom  nHeavyAtom  nHetero      ATS0dv      ATS1dv  ATS0d  ATS1d  \\\n",
       "0       2     47          28        8  383.604938  425.111111    175    224   \n",
       "1       2     70          37        9  496.000000  522.000000    225    275   \n",
       "2       2     65          38       14  670.000000  600.000000    225    275   \n",
       "\n",
       "   ATS0Z  ATS1Z  ...  TSSPECIES_DOG  TSSPECIES_MONKEY  TSSPECIES_MOUSE  \\\n",
       "0   1386   1437  ...              1                 0                0   \n",
       "1   1512   1778  ...              0                 0                1   \n",
       "2   1718   1847  ...              1                 0                0   \n",
       "\n",
       "   TSSPECIES_Monkey  TSSPECIES_PIG  TSSPECIES_RABBIT  TSSPECIES_RAT  \\\n",
       "0                 0              0                 0              0   \n",
       "1                 0              0                 0              0   \n",
       "2                 0              0                 0              0   \n",
       "\n",
       "   TSSPECIES_Rat  SEX_F  SEX_M  \n",
       "0              0      0      1  \n",
       "1              0      0      1  \n",
       "2              0      1      0  \n",
       "\n",
       "[3 rows x 200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-hot encoding for 'TSSPECIES' and 'SEX'\n",
    "df_encoded = pd.get_dummies(df, columns=['TSSPECIES', 'SEX'])\n",
    "\n",
    "# Print the updated dataframe\n",
    "print(df_encoded.shape)\n",
    "df_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a88e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41832057",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> \"Model  Data frame\" and \"Validation Data frame\" generation </h3>\n",
    "    <ul style = \" color : magenta;\">\n",
    "        <li> Select few rows from each \"unique target class\"</li>\n",
    "        <li>DataFrame.sample() function to randomly sample rows from the DataFrame</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "423c1423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model DataFrame: (1980, 200)\n",
      "   Target  nAtom  nHeavyAtom  nHetero      ATS0dv      ATS1dv\n",
      "0       2     47          28        8  383.604938  425.111111\n",
      "1       2     70          37        9  496.000000  522.000000\n",
      "2       2     65          38       14  670.000000  600.000000\n",
      "Validation DataFrame: (50, 200)\n",
      "      Target  nAtom  nHeavyAtom  nHetero      ATS0dv      ATS1dv\n",
      "2022       0     58          27        4  254.790123  266.000000\n",
      "1678       0     66          43       15  693.209876  689.222222\n",
      "1780       0     51          33       10  521.604938  537.111111\n"
     ]
    }
   ],
   "source": [
    "# Validation data separation from the data frame\n",
    "# Create a DataFrame of 'non_toxic' rows\n",
    "\n",
    "df_non_toxic = df_encoded[df_encoded['Target'] == 0]\n",
    "\n",
    "# Create a DataFrame of 'toxic' rows\n",
    "df_mild_toxic = df_encoded[df_encoded['Target'] == 1]\n",
    "\n",
    "# Create a DataFrame of 'toxic' rows\n",
    "df_toxic = df_encoded[df_encoded['Target'] == 2]\n",
    "\n",
    "# Randomly sample 9 'non_toxic' rows and 1 'toxic' row\n",
    "df2_validation = pd.concat([df_non_toxic.sample(7, random_state=42), df_mild_toxic.sample(15, random_state=42),df_toxic.sample(28, random_state=42)])\n",
    "\n",
    "# Create df2 as all rows from df not in df1\n",
    "df1_model = df_encoded.drop(df2_validation.index)\n",
    "\n",
    "print(\"Model DataFrame:\", df1_model.shape )\n",
    "#print(df1_model)\n",
    "print(df1_model.iloc[:3, :6])\n",
    "\n",
    "print(\"Validation DataFrame:\", df2_validation.shape )\n",
    "#print(df1_model)\n",
    "print(df2_validation.iloc[:3, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "32db9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'TSSPECIES_MOUSE' in df1_model.columns:\n",
    "#     print(\"Column 'TSSPECIES_MOUSE' is present in df_model.\")\n",
    "# else:\n",
    "#     print(\"Column 'TSSPECIES_MOUSE' is not present in df_model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44300c63",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Different Machine Learning Model building and testing :  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226b662",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\">List of Several Mchine Learning Model Built and Tested:</h3>\n",
    "<ol style=\"color:magenta;\">\n",
    "    <li>DummyClassifier</li>\n",
    "    <li>DummyClassifier</li>\n",
    "    <li>RandomForestClassifier</li>\n",
    "    <li>GradientBoostingClassifier</li>\n",
    "    <li>SVC</li>\n",
    "    <li>KNeighborsClassifier</li>\n",
    "    <li>DecisionTreeClassifier(</li>\n",
    "    <li>LogisticRegression</li>\n",
    "    <li>xgb.XGBClassifier</li>\n",
    "    <li>AdaBoostClassifier</li>\n",
    "    <li>GaussianNB</li>\n",
    "    <li>MLPClassifier</li>\n",
    "    <li>LGBMClassifier</li>\n",
    "    <li>CatBoostClassifier</li>\n",
    "    <li>ExtraTreesClassifier</li>    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ea292",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">......................\"Code\" for Combined Machine Learning Models .........</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedcf10c",
   "metadata": {},
   "source": [
    "<h3 style=\"color:brown;\"> Multiple Models built and tested Combinedly :  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b97e6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of models\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    SVC(random_state=42),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    LogisticRegression(random_state=42),\n",
    "    xgb.XGBClassifier(random_state=42),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(random_state=42),\n",
    "    LGBMClassifier(random_state=42),\n",
    "    CatBoostClassifier(random_state=42, verbose=False),\n",
    "    ExtraTreesClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "# Initialize empty lists for storing the results\n",
    "model_names = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Iterate over the models\n",
    "for model in models:\n",
    "    # Create and train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision = report['macro avg']['precision']\n",
    "    recall = report['macro avg']['recall']\n",
    "    f1_score = report['macro avg']['f1-score']\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Append the results to the lists\n",
    "    model_names.append(type(model).__name__)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    confusion_matrices.append(confusion_mat)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame({'Model': model_names, 'Precision': precisions,\n",
    "                           'Recall': recalls, 'F1-score': f1_scores,\n",
    "                           'Confusion Matrix': confusion_matrices})\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c1bc69e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.488688</td>\n",
       "      <td>0.487683</td>\n",
       "      <td>0.488064</td>\n",
       "      <td>[[30, 32, 21], [34, 65, 44], [15, 45, 110]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.452532</td>\n",
       "      <td>0.447546</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>[[23, 28, 32], [30, 59, 54], [12, 47, 111]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.288530</td>\n",
       "      <td>0.345382</td>\n",
       "      <td>0.224965</td>\n",
       "      <td>[[3, 0, 80], [4, 0, 139], [0, 0, 170]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.399293</td>\n",
       "      <td>0.401439</td>\n",
       "      <td>0.398865</td>\n",
       "      <td>[[28, 24, 31], [41, 55, 47], [34, 54, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.415574</td>\n",
       "      <td>0.415142</td>\n",
       "      <td>0.415183</td>\n",
       "      <td>[[25, 30, 28], [36, 61, 46], [24, 58, 88]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.253605</td>\n",
       "      <td>0.333428</td>\n",
       "      <td>0.206686</td>\n",
       "      <td>[[1, 0, 82], [0, 0, 143], [2, 0, 168]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.501956</td>\n",
       "      <td>0.500188</td>\n",
       "      <td>0.500830</td>\n",
       "      <td>[[30, 33, 20], [34, 67, 42], [13, 43, 114]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.438481</td>\n",
       "      <td>0.430545</td>\n",
       "      <td>0.431706</td>\n",
       "      <td>[[22, 29, 32], [25, 61, 57], [15, 53, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.327189</td>\n",
       "      <td>0.335355</td>\n",
       "      <td>0.240681</td>\n",
       "      <td>[[5, 69, 9], [8, 126, 9], [8, 151, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.384153</td>\n",
       "      <td>0.359126</td>\n",
       "      <td>0.324270</td>\n",
       "      <td>[[9, 9, 65], [13, 25, 105], [8, 27, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.482949</td>\n",
       "      <td>0.483596</td>\n",
       "      <td>0.482901</td>\n",
       "      <td>[[31, 33, 19], [35, 59, 49], [14, 43, 113]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.513142</td>\n",
       "      <td>0.508795</td>\n",
       "      <td>0.509479</td>\n",
       "      <td>[[33, 26, 24], [30, 63, 50], [11, 42, 117]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.495125</td>\n",
       "      <td>0.491605</td>\n",
       "      <td>0.492769</td>\n",
       "      <td>[[30, 33, 20], [30, 65, 48], [14, 44, 112]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Precision    Recall  F1-score  \\\n",
       "0       RandomForestClassifier   0.488688  0.487683  0.488064   \n",
       "1   GradientBoostingClassifier   0.452532  0.447546  0.447236   \n",
       "2                          SVC   0.288530  0.345382  0.224965   \n",
       "3         KNeighborsClassifier   0.399293  0.401439  0.398865   \n",
       "4       DecisionTreeClassifier   0.415574  0.415142  0.415183   \n",
       "5           LogisticRegression   0.253605  0.333428  0.206686   \n",
       "6                XGBClassifier   0.501956  0.500188  0.500830   \n",
       "7           AdaBoostClassifier   0.438481  0.430545  0.431706   \n",
       "8                   GaussianNB   0.327189  0.335355  0.240681   \n",
       "9                MLPClassifier   0.384153  0.359126  0.324270   \n",
       "10              LGBMClassifier   0.482949  0.483596  0.482901   \n",
       "11          CatBoostClassifier   0.513142  0.508795  0.509479   \n",
       "12        ExtraTreesClassifier   0.495125  0.491605  0.492769   \n",
       "\n",
       "                               Confusion Matrix  \n",
       "0   [[30, 32, 21], [34, 65, 44], [15, 45, 110]]  \n",
       "1   [[23, 28, 32], [30, 59, 54], [12, 47, 111]]  \n",
       "2        [[3, 0, 80], [4, 0, 139], [0, 0, 170]]  \n",
       "3    [[28, 24, 31], [41, 55, 47], [34, 54, 82]]  \n",
       "4    [[25, 30, 28], [36, 61, 46], [24, 58, 88]]  \n",
       "5        [[1, 0, 82], [0, 0, 143], [2, 0, 168]]  \n",
       "6   [[30, 33, 20], [34, 67, 42], [13, 43, 114]]  \n",
       "7   [[22, 29, 32], [25, 61, 57], [15, 53, 102]]  \n",
       "8       [[5, 69, 9], [8, 126, 9], [8, 151, 11]]  \n",
       "9     [[9, 9, 65], [13, 25, 105], [8, 27, 135]]  \n",
       "10  [[31, 33, 19], [35, 59, 49], [14, 43, 113]]  \n",
       "11  [[33, 26, 24], [30, 63, 50], [11, 42, 117]]  \n",
       "12  [[30, 33, 20], [30, 65, 48], [14, 44, 112]]  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116042fa",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Combined Model validation </h2>\n",
    "<ul style=\"color:blue;\"> \n",
    "    <li>Prediction on the selected validation data for all Models </LI>\n",
    "   </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "29043b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_df_val :\n",
      "\n",
      "                Models_name  y_val  y_val_pred Prediction\n",
      "0    RandomForestClassifier      0           1         No\n",
      "1    RandomForestClassifier      0           1         No\n",
      "2    RandomForestClassifier      0           0        Yes\n",
      "3    RandomForestClassifier      0           2         No\n",
      "4    RandomForestClassifier      0           0        Yes\n",
      "..                      ...    ...         ...        ...\n",
      "645    ExtraTreesClassifier      2           2        Yes\n",
      "646    ExtraTreesClassifier      2           2        Yes\n",
      "647    ExtraTreesClassifier      2           2        Yes\n",
      "648    ExtraTreesClassifier      2           2        Yes\n",
      "649    ExtraTreesClassifier      2           2        Yes\n",
      "\n",
      "[650 rows x 4 columns]\n",
      "\n",
      "new_df_summary : \n",
      "\n",
      "Prediction                        No  Yes\n",
      "Models_name                y_val         \n",
      "AdaBoostClassifier         0       5    2\n",
      "                           1      10    5\n",
      "                           2       9   19\n",
      "CatBoostClassifier         0       6    1\n",
      "                           1       8    7\n",
      "                           2      10   18\n",
      "DecisionTreeClassifier     0       5    2\n",
      "                           1       9    6\n",
      "                           2      13   15\n",
      "ExtraTreesClassifier       0       5    2\n",
      "                           1      10    5\n",
      "                           2      11   17\n",
      "GaussianNB                 0       7    0\n",
      "                           1       2   13\n",
      "                           2      26    2\n",
      "GradientBoostingClassifier 0       5    2\n",
      "                           1       9    6\n",
      "                           2       9   19\n",
      "KNeighborsClassifier       0       6    1\n",
      "                           1      11    4\n",
      "                           2      14   14\n",
      "LGBMClassifier             0       6    1\n",
      "                           1       8    7\n",
      "                           2      12   16\n",
      "LogisticRegression         0       7    0\n",
      "                           1      15    0\n",
      "                           2       0   28\n",
      "MLPClassifier              0       7    0\n",
      "                           1      13    2\n",
      "                           2       4   24\n",
      "RandomForestClassifier     0       5    2\n",
      "                           1      10    5\n",
      "                           2      11   17\n",
      "SVC                        0       7    0\n",
      "                           1      15    0\n",
      "                           2       0   28\n",
      "XGBClassifier              0       6    1\n",
      "                           1       9    6\n",
      "                           2      13   15\n",
      "\n",
      "new_df_grouped :\n",
      "\n",
      "Prediction                  No  Yes\n",
      "Models_name                        \n",
      "AdaBoostClassifier          24   26\n",
      "CatBoostClassifier          24   26\n",
      "DecisionTreeClassifier      27   23\n",
      "ExtraTreesClassifier        26   24\n",
      "GaussianNB                  35   15\n",
      "GradientBoostingClassifier  23   27\n",
      "KNeighborsClassifier        31   19\n",
      "LGBMClassifier              26   24\n",
      "LogisticRegression          22   28\n",
      "MLPClassifier               24   26\n",
      "RandomForestClassifier      26   24\n",
      "SVC                         22   28\n",
      "XGBClassifier               28   22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined Model validation code \n",
    "\n",
    "# Detailed Format\n",
    "\n",
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# List of models\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    SVC(random_state=42),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    LogisticRegression(random_state=42),\n",
    "    xgb.XGBClassifier(random_state=42),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(random_state=42),\n",
    "    LGBMClassifier(random_state=42),\n",
    "    CatBoostClassifier(random_state=42, verbose=False),\n",
    "    ExtraTreesClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame for storing the results\n",
    "results_dfs = []\n",
    "\n",
    "# Iterate over the models\n",
    "for model in models:\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # Convert the arrays to 1-dimensional if needed\n",
    "    y_val = y_val.ravel()\n",
    "    y_val_pred = y_val_pred.ravel()\n",
    "\n",
    "    # Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "    model_results = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "    \n",
    "    # Add 'comment' column based on the condition\n",
    "    model_results['Prediction'] = ['No' if y_true != y_pred else 'Yes' for y_true, y_pred in zip(y_val, y_val_pred)]\n",
    "    \n",
    "    # Set the model name as the index of the model_results DataFrame\n",
    "    model_results.index = [type(model).__name__] * len(model_results)\n",
    "\n",
    "    # Append the results DataFrame to the list\n",
    "    results_dfs.append(model_results) # concatenates  multiple dataf frmaes into a single data frame\n",
    "    \n",
    "# pd.concat(results_dfs) is concatenating the list of DataFrames 'results_dfs' into a single DataFrame 'results_df_val'   \n",
    "# The concat() method takes a list of DataFrames as its input and concatenates them into a single DataFrame.\n",
    "\n",
    "# Concatenate the results DataFrames into a single DataFrame\n",
    "results_df_val = pd.concat(results_dfs)\n",
    "\n",
    "\n",
    "# Reset index and rename the column as \"Models_name\"\n",
    "results_df_val.reset_index(inplace=True)\n",
    "results_df_val.rename(columns={'index': 'Models_name'}, inplace=True)\n",
    "\n",
    "\n",
    "# Print the combined results DataFrame\n",
    "print('results_df_val :')\n",
    "print()\n",
    "print(results_df_val)\n",
    "print()\n",
    "\n",
    "\n",
    "# Create a new variabe \n",
    "\n",
    "results_df_val1 = results_df_val\n",
    "#print(results_df_val1)\n",
    "\n",
    "\n",
    "# creation of the Summary data frame [Method-1]\n",
    "\n",
    "# value_counts provides more flexibility and allows additional operations such as renaming columns and resetting the index.\n",
    "new_df_summary = results_df_val1.groupby(['Models_name', 'y_val'])['Prediction'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Rename the columns\n",
    "#new_df_summary.rename(columns={'No': 'y_val_pred_NO', 'Yes': 'y_val_pred_Yes'}, inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "#new_df_summary.reset_index(inplace=True)\n",
    "\n",
    "# Print the data frame\n",
    "print('new_df_summary : ')\n",
    "print()\n",
    "print(new_df_summary)\n",
    "print()\n",
    "\n",
    "## Grouping for No/Yes Summing\n",
    "# Group by Models_name and sum the values in No and Yes columns\n",
    "new_df_grouped = new_df_summary.groupby('Models_name')['No', 'Yes'].sum()\n",
    "\n",
    "# Rename the columns\n",
    "#new_df_grouped.rename(columns={' y_val_pred_NO': 'Sum_NO', 'y_val_pred_Yes': 'Sum_Yes'}, inplace=True)\n",
    "\n",
    "# Reset the index to make 'Models_name' a regular column\n",
    "#new_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print('new_df_grouped :')\n",
    "print()\n",
    "print(new_df_grouped)\n",
    "print()\n",
    "\n",
    "# # merging data frames\n",
    "# final_results = pd.merge(new_df_summary, new_df_grouped, on='Models_name', how = 'inner')\n",
    "# final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc506d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fefddb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the display option to show all rows\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# # Print the DataFrame\n",
    "# print(results_df_val)\n",
    "\n",
    "# # Reset the display option to the default value\n",
    "# pd.reset_option('display.max_rows')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10f754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53889cfe",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">......................Individual Machine Learning Models Building and Testing.........</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acecc07",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Model-DummyClassifier : (strategy='most_frequent')  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7067212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        83\n",
      "           1       0.00      0.00      0.00       143\n",
      "           2       0.43      1.00      0.60       170\n",
      "\n",
      "    accuracy                           0.43       396\n",
      "   macro avg       0.14      0.33      0.20       396\n",
      "weighted avg       0.18      0.43      0.26       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   0  83]\n",
      " [  0   0 143]\n",
      " [  0   0 170]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection \n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the DummyClassifier\n",
    "dummy_model = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit the model to your data\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = dummy_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee52a43",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Model-DummyClassifier : strategies = ['stratified', 'most_frequent', 'prior', 'uniform'] </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8576cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: stratified\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.20      0.20        83\n",
      "           1       0.33      0.31      0.32       143\n",
      "           2       0.40      0.41      0.41       170\n",
      "\n",
      "    accuracy                           0.33       396\n",
      "   macro avg       0.31      0.31      0.31       396\n",
      "weighted avg       0.33      0.33      0.33       396\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Strategy: most_frequent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        83\n",
      "           1       0.00      0.00      0.00       143\n",
      "           2       0.43      1.00      0.60       170\n",
      "\n",
      "    accuracy                           0.43       396\n",
      "   macro avg       0.14      0.33      0.20       396\n",
      "weighted avg       0.18      0.43      0.26       396\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Strategy: prior\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        83\n",
      "           1       0.00      0.00      0.00       143\n",
      "           2       0.43      1.00      0.60       170\n",
      "\n",
      "    accuracy                           0.43       396\n",
      "   macro avg       0.14      0.33      0.20       396\n",
      "weighted avg       0.18      0.43      0.26       396\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Strategy: uniform\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.37      0.26        83\n",
      "           1       0.39      0.34      0.36       143\n",
      "           2       0.39      0.26      0.31       170\n",
      "\n",
      "    accuracy                           0.32       396\n",
      "   macro avg       0.33      0.33      0.31       396\n",
      "weighted avg       0.35      0.32      0.32       396\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31 22 30]\n",
      " [53 49 41]\n",
      " [70 55 45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create an instance of the DummyClassifier with different strategies\n",
    "strategies = ['stratified', 'most_frequent', 'prior', 'uniform']\n",
    "for strategy in strategies:\n",
    "    dummy_model = DummyClassifier(strategy=strategy)\n",
    "    dummy_model.fit(X_train, y_train)\n",
    "    y_pred = dummy_model.predict(X_test)\n",
    "    print(f\"Strategy: {strategy}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d1d3d2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-1 (RandomForestClassifier) :  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c88c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37        83\n",
      "           1       0.46      0.45      0.46       143\n",
      "           2       0.63      0.65      0.64       170\n",
      "\n",
      "    accuracy                           0.52       396\n",
      "   macro avg       0.49      0.49      0.49       396\n",
      "weighted avg       0.51      0.52      0.52       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 30  32  21]\n",
      " [ 34  65  44]\n",
      " [ 15  45 110]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection \n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_RandomForestClassifier = RandomForestClassifier(random_state=42)\n",
    "model_RandomForestClassifier .fit(X_train, y_train)\n",
    "\n",
    "# Now you can use the model to predict on your test set\n",
    "y_pred = model_RandomForestClassifier.predict(X_test)\n",
    "\n",
    "#  assess the performance of your model  using classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484ed0d",
   "metadata": {},
   "source": [
    "<h3 style=\"color:navy;\"> Prediction on the selected validation data (Model-RandomForestClassifier) :  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "796b6dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29         7\n",
      "           1       0.33      0.33      0.33        15\n",
      "           2       0.61      0.61      0.61        28\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.41      0.41      0.41        50\n",
      "weighted avg       0.48      0.48      0.48        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           1\n",
      "1678      0           1\n",
      "1780      0           0\n",
      "1633      0           2\n",
      "1961      0           0\n",
      "1874      0           2\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           1\n",
      "1253      1           1\n",
      "1601      1           0\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           0\n",
      "1239      1           1\n",
      "950       1           1\n",
      "1274      1           2\n",
      "941       1           2\n",
      "1505      1           1\n",
      "331       2           0\n",
      "247       2           1\n",
      "789       2           2\n",
      "316       2           1\n",
      "215       2           1\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           1\n",
      "814       2           1\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           0\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           1\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           1\n",
      "728       2           1\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_RandomForestClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b40da8",
   "metadata": {},
   "source": [
    "<h3 style=\"color: blue;\"> StratifiedKFold for cross-validation (Model-RandomForestClassifier) :  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc2de8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.21      0.26        42\n",
      "           1       0.41      0.38      0.39        71\n",
      "           2       0.58      0.72      0.64        85\n",
      "\n",
      "    accuracy                           0.49       198\n",
      "   macro avg       0.44      0.44      0.43       198\n",
      "weighted avg       0.47      0.49      0.47       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9 21 12]\n",
      " [11 27 33]\n",
      " [ 6 18 61]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.31      0.34        42\n",
      "           1       0.32      0.30      0.31        71\n",
      "           2       0.58      0.67      0.62        85\n",
      "\n",
      "    accuracy                           0.46       198\n",
      "   macro avg       0.43      0.43      0.42       198\n",
      "weighted avg       0.44      0.46      0.45       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13 23  6]\n",
      " [15 21 35]\n",
      " [ 6 22 57]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.43      0.45        42\n",
      "           1       0.49      0.44      0.46        71\n",
      "           2       0.59      0.67      0.63        85\n",
      "\n",
      "    accuracy                           0.54       198\n",
      "   macro avg       0.52      0.51      0.51       198\n",
      "weighted avg       0.53      0.54      0.53       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18 14 10]\n",
      " [10 31 30]\n",
      " [10 18 57]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.31      0.35        42\n",
      "           1       0.43      0.44      0.43        71\n",
      "           2       0.55      0.61      0.58        85\n",
      "\n",
      "    accuracy                           0.48       198\n",
      "   macro avg       0.46      0.45      0.46       198\n",
      "weighted avg       0.48      0.48      0.48       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13 15 14]\n",
      " [12 31 28]\n",
      " [ 7 26 52]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.49        42\n",
      "           1       0.45      0.44      0.44        71\n",
      "           2       0.60      0.64      0.62        85\n",
      "\n",
      "    accuracy                           0.53       198\n",
      "   macro avg       0.52      0.52      0.52       198\n",
      "weighted avg       0.53      0.53      0.53       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20 14  8]\n",
      " [12 31 28]\n",
      " [ 7 24 54]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.33      0.34        42\n",
      "           1       0.41      0.41      0.41        71\n",
      "           2       0.61      0.62      0.62        85\n",
      "\n",
      "    accuracy                           0.48       198\n",
      "   macro avg       0.45      0.46      0.45       198\n",
      "weighted avg       0.48      0.48      0.48       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14 23  5]\n",
      " [13 29 29]\n",
      " [14 18 53]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.38      0.36        42\n",
      "           1       0.34      0.35      0.34        71\n",
      "           2       0.56      0.52      0.54        85\n",
      "\n",
      "    accuracy                           0.43       198\n",
      "   macro avg       0.42      0.42      0.42       198\n",
      "weighted avg       0.44      0.43      0.43       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16 16 10]\n",
      " [22 25 24]\n",
      " [ 8 33 44]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.21      0.22        42\n",
      "           1       0.37      0.38      0.38        71\n",
      "           2       0.49      0.49      0.49        85\n",
      "\n",
      "    accuracy                           0.39       198\n",
      "   macro avg       0.36      0.36      0.36       198\n",
      "weighted avg       0.39      0.39      0.39       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9 17 16]\n",
      " [17 27 27]\n",
      " [14 29 42]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.50      0.46        42\n",
      "           1       0.46      0.39      0.42        71\n",
      "           2       0.59      0.60      0.59        85\n",
      "\n",
      "    accuracy                           0.51       198\n",
      "   macro avg       0.49      0.50      0.49       198\n",
      "weighted avg       0.51      0.51      0.50       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21  9 12]\n",
      " [19 28 24]\n",
      " [10 24 51]]\n",
      "-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.24      0.25        42\n",
      "           1       0.39      0.48      0.43        71\n",
      "           2       0.50      0.44      0.47        85\n",
      "\n",
      "    accuracy                           0.41       198\n",
      "   macro avg       0.39      0.38      0.38       198\n",
      "weighted avg       0.41      0.41      0.41       198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10 15 17]\n",
      " [17 34 20]\n",
      " [10 38 37]]\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create and train the model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the performance of the model\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-----------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100caf5c",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-2 : GradientBoostingClassifier  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1e00dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.28      0.31        83\n",
      "           1       0.44      0.41      0.43       143\n",
      "           2       0.56      0.65      0.60       170\n",
      "\n",
      "    accuracy                           0.49       396\n",
      "   macro avg       0.45      0.45      0.45       396\n",
      "weighted avg       0.48      0.49      0.48       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 23  28  32]\n",
      " [ 30  59  54]\n",
      " [ 12  47 111]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Gradient Boosting model\n",
    "model_GradientBoostingClassifier = GradientBoostingClassifier(random_state=42)\n",
    "model_GradientBoostingClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use the model to predict on your test set\n",
    "y_pred = model_GradientBoostingClassifier.predict(X_test)\n",
    "\n",
    "# Assess the performance of your model using classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ce839",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba33aa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.29      0.27         7\n",
      "           1       0.46      0.40      0.43        15\n",
      "           2       0.66      0.68      0.67        28\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.46      0.45      0.45        50\n",
      "weighted avg       0.54      0.54      0.54        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           2\n",
      "1678      0           1\n",
      "1780      0           0\n",
      "1633      0           2\n",
      "1961      0           0\n",
      "1874      0           2\n",
      "1758      0           1\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           1\n",
      "1253      1           1\n",
      "1601      1           0\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           0\n",
      "1239      1           1\n",
      "950       1           1\n",
      "1274      1           1\n",
      "941       1           2\n",
      "1505      1           1\n",
      "331       2           0\n",
      "247       2           1\n",
      "789       2           2\n",
      "316       2           1\n",
      "215       2           2\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           2\n",
      "814       2           1\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           0\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           2\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           1\n",
      "728       2           0\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           1\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_GradientBoostingClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53e539",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-3 : Support Vector Machine (SVM)   </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffd463da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.04      0.07        83\n",
      "           1       0.00      0.00      0.00       143\n",
      "           2       0.44      1.00      0.61       170\n",
      "\n",
      "    accuracy                           0.44       396\n",
      "   macro avg       0.29      0.35      0.22       396\n",
      "weighted avg       0.28      0.44      0.28       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  3   0  80]\n",
      " [  4   0 139]\n",
      " [  0   0 170]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Target and feature selection \n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM model\n",
    "model_SVM = SVC(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use the model to predict on your test set\n",
    "y_pred = model_SVM.predict(X_test)\n",
    "\n",
    "#  Assess the performance of your model using classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13fd471",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28377120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.56      1.00      0.72        28\n",
      "\n",
      "    accuracy                           0.56        50\n",
      "   macro avg       0.19      0.33      0.24        50\n",
      "weighted avg       0.31      0.56      0.40        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           2\n",
      "1678      0           2\n",
      "1780      0           2\n",
      "1633      0           2\n",
      "1961      0           2\n",
      "1874      0           2\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           2\n",
      "1253      1           2\n",
      "1601      1           2\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           2\n",
      "1239      1           2\n",
      "950       1           2\n",
      "1274      1           2\n",
      "941       1           2\n",
      "1505      1           2\n",
      "331       2           2\n",
      "247       2           2\n",
      "789       2           2\n",
      "316       2           2\n",
      "215       2           2\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           2\n",
      "814       2           2\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           2\n",
      "873       2           2\n",
      "328       2           2\n",
      "611       2           2\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           2\n",
      "728       2           2\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           2\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred =  model_SVM.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad258b",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-4 : KNeighborsClassifier  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "015e4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.34      0.30        83\n",
      "           1       0.41      0.38      0.40       143\n",
      "           2       0.51      0.48      0.50       170\n",
      "\n",
      "    accuracy                           0.42       396\n",
      "   macro avg       0.40      0.40      0.40       396\n",
      "weighted avg       0.43      0.42      0.42       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[28 24 31]\n",
      " [41 55 47]\n",
      " [34 54 82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_KNeighborsClassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "model_KNeighborsClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_KNeighborsClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55292a2",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20057c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.14      0.10         7\n",
      "           1       0.33      0.27      0.30        15\n",
      "           2       0.58      0.50      0.54        28\n",
      "\n",
      "    accuracy                           0.38        50\n",
      "   macro avg       0.33      0.30      0.31        50\n",
      "weighted avg       0.44      0.38      0.40        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           1\n",
      "1678      0           1\n",
      "1780      0           0\n",
      "1633      0           2\n",
      "1961      0           2\n",
      "1874      0           2\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           2\n",
      "1253      1           0\n",
      "1601      1           0\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           0\n",
      "1365      1           0\n",
      "1239      1           1\n",
      "950       1           1\n",
      "1274      1           0\n",
      "941       1           1\n",
      "1505      1           1\n",
      "331       2           2\n",
      "247       2           0\n",
      "789       2           0\n",
      "316       2           1\n",
      "215       2           2\n",
      "680       2           1\n",
      "585       2           1\n",
      "462       2           0\n",
      "814       2           1\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           0\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           1\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           2\n",
      "728       2           1\n",
      "673       2           0\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           0\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           0\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred =  model_KNeighborsClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55238a14",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-5 : DecisionTreeClassifier </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40b8ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.30      0.30        83\n",
      "           1       0.41      0.43      0.42       143\n",
      "           2       0.54      0.52      0.53       170\n",
      "\n",
      "    accuracy                           0.44       396\n",
      "   macro avg       0.42      0.42      0.42       396\n",
      "weighted avg       0.44      0.44      0.44       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25 30 28]\n",
      " [36 61 46]\n",
      " [24 58 88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_DecisionTreeClassifier = DecisionTreeClassifier(random_state=42)\n",
    "model_DecisionTreeClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_DecisionTreeClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a65b05",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ff56883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.29      0.24         7\n",
      "           1       0.35      0.40      0.38        15\n",
      "           2       0.65      0.54      0.59        28\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.40      0.41      0.40        50\n",
      "weighted avg       0.50      0.46      0.47        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           1\n",
      "1678      0           2\n",
      "1780      0           1\n",
      "1633      0           2\n",
      "1961      0           0\n",
      "1874      0           0\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           1\n",
      "911       1           1\n",
      "1253      1           1\n",
      "1601      1           1\n",
      "943       1           2\n",
      "987       1           1\n",
      "1132      1           1\n",
      "1365      1           0\n",
      "1239      1           2\n",
      "950       1           2\n",
      "1274      1           0\n",
      "941       1           0\n",
      "1505      1           0\n",
      "331       2           1\n",
      "247       2           0\n",
      "789       2           2\n",
      "316       2           2\n",
      "215       2           1\n",
      "680       2           0\n",
      "585       2           2\n",
      "462       2           1\n",
      "814       2           2\n",
      "39        2           1\n",
      "430       2           2\n",
      "696       2           2\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           2\n",
      "23        2           2\n",
      "501       2           1\n",
      "198       2           2\n",
      "110       2           1\n",
      "728       2           2\n",
      "673       2           1\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           1\n",
      "44        2           2\n",
      "684       2           1\n",
      "774       2           2\n",
      "76        2           0\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_DecisionTreeClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013084f1",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-6 : LogisticRegression  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaa3c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02        83\n",
      "           1       0.00      0.00      0.00       143\n",
      "           2       0.43      0.99      0.60       170\n",
      "\n",
      "    accuracy                           0.43       396\n",
      "   macro avg       0.25      0.33      0.21       396\n",
      "weighted avg       0.25      0.43      0.26       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  1   0  82]\n",
      " [  0   0 143]\n",
      " [  2   0 168]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_LogisticRegression = LogisticRegression(random_state=42)\n",
    "model_LogisticRegression.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_LogisticRegression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a126fac",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3889c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.56      1.00      0.72        28\n",
      "\n",
      "    accuracy                           0.56        50\n",
      "   macro avg       0.19      0.33      0.24        50\n",
      "weighted avg       0.31      0.56      0.40        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           2\n",
      "1678      0           2\n",
      "1780      0           2\n",
      "1633      0           2\n",
      "1961      0           2\n",
      "1874      0           2\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           2\n",
      "1253      1           2\n",
      "1601      1           2\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           2\n",
      "1239      1           2\n",
      "950       1           2\n",
      "1274      1           2\n",
      "941       1           2\n",
      "1505      1           2\n",
      "331       2           2\n",
      "247       2           2\n",
      "789       2           2\n",
      "316       2           2\n",
      "215       2           2\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           2\n",
      "814       2           2\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           2\n",
      "873       2           2\n",
      "328       2           2\n",
      "611       2           2\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           2\n",
      "728       2           2\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           2\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_LogisticRegression.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6fa693",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-7 : XGBoost (Extreme Gradient Boosting)  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147c1ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.36      0.38        83\n",
      "           1       0.47      0.47      0.47       143\n",
      "           2       0.65      0.67      0.66       170\n",
      "\n",
      "    accuracy                           0.53       396\n",
      "   macro avg       0.50      0.50      0.50       396\n",
      "weighted avg       0.53      0.53      0.53       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 30  33  20]\n",
      " [ 34  67  42]\n",
      " [ 13  43 114]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_XGBoost = xgb.XGBClassifier(random_state=42)\n",
    "model_XGBoost.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_XGBoost.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296008ea",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f502b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15         7\n",
      "           1       0.32      0.40      0.35        15\n",
      "           2       0.60      0.54      0.57        28\n",
      "\n",
      "    accuracy                           0.44        50\n",
      "   macro avg       0.36      0.36      0.36        50\n",
      "weighted avg       0.45      0.44      0.44        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           1\n",
      "1678      0           1\n",
      "1780      0           1\n",
      "1633      0           2\n",
      "1961      0           0\n",
      "1874      0           2\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           1\n",
      "1253      1           1\n",
      "1601      1           0\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           0\n",
      "1239      1           1\n",
      "950       1           1\n",
      "1274      1           1\n",
      "941       1           2\n",
      "1505      1           1\n",
      "331       2           0\n",
      "247       2           1\n",
      "789       2           2\n",
      "316       2           1\n",
      "215       2           1\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           1\n",
      "814       2           1\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           0\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           1\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           1\n",
      "728       2           1\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           1\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           1\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_XGBoost.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b743e8c",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-8 : AdaBoostClassifier </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fa55cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.27      0.30        83\n",
      "           1       0.43      0.43      0.43       143\n",
      "           2       0.53      0.60      0.57       170\n",
      "\n",
      "    accuracy                           0.47       396\n",
      "   macro avg       0.44      0.43      0.43       396\n",
      "weighted avg       0.46      0.47      0.46       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 22  29  32]\n",
      " [ 25  61  57]\n",
      " [ 15  53 102]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_AdaBoostClassifier = AdaBoostClassifier(random_state=42)\n",
    "model_AdaBoostClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_AdaBoostClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbf287",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae0ec6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.29      0.25         7\n",
      "           1       0.45      0.33      0.38        15\n",
      "           2       0.63      0.68      0.66        28\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.44      0.43      0.43        50\n",
      "weighted avg       0.52      0.52      0.52        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           2\n",
      "1678      0           2\n",
      "1780      0           0\n",
      "1633      0           2\n",
      "1961      0           0\n",
      "1874      0           1\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           1\n",
      "1432      1           1\n",
      "911       1           0\n",
      "1253      1           2\n",
      "1601      1           1\n",
      "943       1           0\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           0\n",
      "1239      1           1\n",
      "950       1           2\n",
      "1274      1           1\n",
      "941       1           2\n",
      "1505      1           2\n",
      "331       2           0\n",
      "247       2           1\n",
      "789       2           0\n",
      "316       2           2\n",
      "215       2           2\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           2\n",
      "814       2           2\n",
      "39        2           2\n",
      "430       2           1\n",
      "696       2           0\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           2\n",
      "23        2           2\n",
      "501       2           1\n",
      "198       2           1\n",
      "110       2           2\n",
      "728       2           2\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           1\n",
      "76        2           2\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_AdaBoostClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5a9fc",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-9 : Gaussian Naive Bayes </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bafdea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.06      0.10        83\n",
      "           1       0.36      0.88      0.52       143\n",
      "           2       0.38      0.06      0.11       170\n",
      "\n",
      "    accuracy                           0.36       396\n",
      "   macro avg       0.33      0.34      0.24       396\n",
      "weighted avg       0.34      0.36      0.25       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  5  69   9]\n",
      " [  8 126   9]\n",
      " [  8 151  11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_GaussianNB = GaussianNB()\n",
    "model_GaussianNB.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_GaussianNB.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a9669",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26d0a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.28      0.87      0.43        15\n",
      "           2       0.67      0.07      0.13        28\n",
      "\n",
      "    accuracy                           0.30        50\n",
      "   macro avg       0.32      0.31      0.19        50\n",
      "weighted avg       0.46      0.30      0.20        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           1\n",
      "1678      0           1\n",
      "1780      0           1\n",
      "1633      0           1\n",
      "1961      0           1\n",
      "1874      0           1\n",
      "1758      0           1\n",
      "1204      1           1\n",
      "1396      1           1\n",
      "1432      1           2\n",
      "911       1           1\n",
      "1253      1           1\n",
      "1601      1           1\n",
      "943       1           1\n",
      "987       1           1\n",
      "1132      1           1\n",
      "1365      1           1\n",
      "1239      1           1\n",
      "950       1           1\n",
      "1274      1           1\n",
      "941       1           1\n",
      "1505      1           0\n",
      "331       2           2\n",
      "247       2           1\n",
      "789       2           1\n",
      "316       2           1\n",
      "215       2           1\n",
      "680       2           1\n",
      "585       2           1\n",
      "462       2           1\n",
      "814       2           1\n",
      "39        2           1\n",
      "430       2           1\n",
      "696       2           1\n",
      "873       2           1\n",
      "328       2           1\n",
      "611       2           1\n",
      "23        2           1\n",
      "501       2           1\n",
      "198       2           1\n",
      "110       2           1\n",
      "728       2           1\n",
      "673       2           1\n",
      "426       2           1\n",
      "785       2           1\n",
      "66        2           1\n",
      "44        2           2\n",
      "684       2           1\n",
      "774       2           1\n",
      "76        2           1\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_GaussianNB.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517fcb9",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model-10 : MLPClassifier </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "9cd956b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.11      0.16        83\n",
      "           1       0.41      0.17      0.25       143\n",
      "           2       0.44      0.79      0.57       170\n",
      "\n",
      "    accuracy                           0.43       396\n",
      "   macro avg       0.38      0.36      0.32       396\n",
      "weighted avg       0.40      0.43      0.37       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  9   9  65]\n",
      " [ 13  25 105]\n",
      " [  8  27 135]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model_MLPClassifier = MLPClassifier(random_state=42)\n",
    "model_MLPClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_MLPClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079458f",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "568bad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.40      0.13      0.20        15\n",
      "           2       0.56      0.86      0.68        28\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.32      0.33      0.29        50\n",
      "weighted avg       0.43      0.52      0.44        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           1\n",
      "1678      0           2\n",
      "1780      0           2\n",
      "1633      0           2\n",
      "1961      0           2\n",
      "1874      0           2\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           2\n",
      "1253      1           2\n",
      "1601      1           2\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           2\n",
      "1239      1           2\n",
      "950       1           1\n",
      "1274      1           2\n",
      "941       1           2\n",
      "1505      1           1\n",
      "331       2           0\n",
      "247       2           2\n",
      "789       2           2\n",
      "316       2           0\n",
      "215       2           2\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           2\n",
      "814       2           2\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           2\n",
      "873       2           2\n",
      "328       2           2\n",
      "611       2           2\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           1\n",
      "728       2           2\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           1\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           2\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_MLPClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a8878",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Model-11 : LightGBM Classifier: LightGBM is a gradient boosting framework that uses tree-based learning algorithms. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96de85fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.37      0.38        83\n",
      "           1       0.44      0.41      0.42       143\n",
      "           2       0.62      0.66      0.64       170\n",
      "\n",
      "    accuracy                           0.51       396\n",
      "   macro avg       0.48      0.48      0.48       396\n",
      "weighted avg       0.51      0.51      0.51       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 31  33  19]\n",
      " [ 35  59  49]\n",
      " [ 14  43 113]]\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_LGBMClassifier = LGBMClassifier(random_state=42)\n",
    "model_LGBMClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_LGBMClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8402d",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f06ab3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15         7\n",
      "           1       0.37      0.47      0.41        15\n",
      "           2       0.64      0.57      0.60        28\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.39      0.39      0.39        50\n",
      "weighted avg       0.49      0.48      0.48        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           1\n",
      "1678      0           1\n",
      "1780      0           1\n",
      "1633      0           2\n",
      "1961      0           0\n",
      "1874      0           2\n",
      "1758      0           2\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           1\n",
      "1253      1           1\n",
      "1601      1           0\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           0\n",
      "1239      1           1\n",
      "950       1           1\n",
      "1274      1           1\n",
      "941       1           1\n",
      "1505      1           1\n",
      "331       2           0\n",
      "247       2           1\n",
      "789       2           2\n",
      "316       2           1\n",
      "215       2           1\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           1\n",
      "814       2           1\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           0\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           1\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           1\n",
      "728       2           1\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           1\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           2\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_LGBMClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b9521",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Model-12 : CatBoost Classifier: CatBoost is a gradient boosting algorithm that handles categorical features efficiently. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6335d46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.081005\n",
      "0:\tlearn: 1.0861618\ttotal: 175ms\tremaining: 2m 54s\n",
      "1:\tlearn: 1.0764879\ttotal: 210ms\tremaining: 1m 45s\n",
      "2:\tlearn: 1.0652338\ttotal: 249ms\tremaining: 1m 22s\n",
      "3:\tlearn: 1.0569402\ttotal: 284ms\tremaining: 1m 10s\n",
      "4:\tlearn: 1.0487255\ttotal: 320ms\tremaining: 1m 3s\n",
      "5:\tlearn: 1.0400183\ttotal: 356ms\tremaining: 59s\n",
      "6:\tlearn: 1.0345802\ttotal: 392ms\tremaining: 55.7s\n",
      "7:\tlearn: 1.0304727\ttotal: 428ms\tremaining: 53.1s\n",
      "8:\tlearn: 1.0231798\ttotal: 465ms\tremaining: 51.2s\n",
      "9:\tlearn: 1.0192997\ttotal: 499ms\tremaining: 49.4s\n",
      "10:\tlearn: 1.0155998\ttotal: 535ms\tremaining: 48.1s\n",
      "11:\tlearn: 1.0092958\ttotal: 569ms\tremaining: 46.9s\n",
      "12:\tlearn: 1.0042684\ttotal: 604ms\tremaining: 45.9s\n",
      "13:\tlearn: 0.9983388\ttotal: 639ms\tremaining: 45s\n",
      "14:\tlearn: 0.9927882\ttotal: 676ms\tremaining: 44.4s\n",
      "15:\tlearn: 0.9897743\ttotal: 710ms\tremaining: 43.7s\n",
      "16:\tlearn: 0.9853474\ttotal: 744ms\tremaining: 43s\n",
      "17:\tlearn: 0.9828347\ttotal: 779ms\tremaining: 42.5s\n",
      "18:\tlearn: 0.9804721\ttotal: 813ms\tremaining: 42s\n",
      "19:\tlearn: 0.9781316\ttotal: 847ms\tremaining: 41.5s\n",
      "20:\tlearn: 0.9752902\ttotal: 884ms\tremaining: 41.2s\n",
      "21:\tlearn: 0.9739447\ttotal: 918ms\tremaining: 40.8s\n",
      "22:\tlearn: 0.9696804\ttotal: 954ms\tremaining: 40.5s\n",
      "23:\tlearn: 0.9684611\ttotal: 988ms\tremaining: 40.2s\n",
      "24:\tlearn: 0.9670545\ttotal: 1.02s\tremaining: 39.9s\n",
      "25:\tlearn: 0.9646580\ttotal: 1.06s\tremaining: 39.7s\n",
      "26:\tlearn: 0.9620337\ttotal: 1.09s\tremaining: 39.5s\n",
      "27:\tlearn: 0.9579913\ttotal: 1.13s\tremaining: 39.3s\n",
      "28:\tlearn: 0.9559348\ttotal: 1.17s\tremaining: 39s\n",
      "29:\tlearn: 0.9531494\ttotal: 1.2s\tremaining: 38.8s\n",
      "30:\tlearn: 0.9513180\ttotal: 1.23s\tremaining: 38.6s\n",
      "31:\tlearn: 0.9487668\ttotal: 1.27s\tremaining: 38.4s\n",
      "32:\tlearn: 0.9468110\ttotal: 1.3s\tremaining: 38.2s\n",
      "33:\tlearn: 0.9432650\ttotal: 1.34s\tremaining: 38.1s\n",
      "34:\tlearn: 0.9422002\ttotal: 1.37s\tremaining: 37.9s\n",
      "35:\tlearn: 0.9404756\ttotal: 1.41s\tremaining: 37.7s\n",
      "36:\tlearn: 0.9374526\ttotal: 1.44s\tremaining: 37.5s\n",
      "37:\tlearn: 0.9344348\ttotal: 1.48s\tremaining: 37.3s\n",
      "38:\tlearn: 0.9328746\ttotal: 1.51s\tremaining: 37.2s\n",
      "39:\tlearn: 0.9314579\ttotal: 1.54s\tremaining: 37.1s\n",
      "40:\tlearn: 0.9296320\ttotal: 1.58s\tremaining: 37s\n",
      "41:\tlearn: 0.9274456\ttotal: 1.61s\tremaining: 36.8s\n",
      "42:\tlearn: 0.9253128\ttotal: 1.65s\tremaining: 36.7s\n",
      "43:\tlearn: 0.9229550\ttotal: 1.68s\tremaining: 36.6s\n",
      "44:\tlearn: 0.9207927\ttotal: 1.72s\tremaining: 36.5s\n",
      "45:\tlearn: 0.9186274\ttotal: 1.75s\tremaining: 36.4s\n",
      "46:\tlearn: 0.9162758\ttotal: 1.79s\tremaining: 36.4s\n",
      "47:\tlearn: 0.9142860\ttotal: 1.83s\tremaining: 36.3s\n",
      "48:\tlearn: 0.9130079\ttotal: 1.87s\tremaining: 36.3s\n",
      "49:\tlearn: 0.9114229\ttotal: 1.91s\tremaining: 36.2s\n",
      "50:\tlearn: 0.9084663\ttotal: 1.94s\tremaining: 36.1s\n",
      "51:\tlearn: 0.9069477\ttotal: 1.98s\tremaining: 36.2s\n",
      "52:\tlearn: 0.9031490\ttotal: 2.02s\tremaining: 36.2s\n",
      "53:\tlearn: 0.9008327\ttotal: 2.06s\tremaining: 36.1s\n",
      "54:\tlearn: 0.8987120\ttotal: 2.1s\tremaining: 36.1s\n",
      "55:\tlearn: 0.8980773\ttotal: 2.13s\tremaining: 36s\n",
      "56:\tlearn: 0.8947970\ttotal: 2.17s\tremaining: 35.9s\n",
      "57:\tlearn: 0.8922534\ttotal: 2.21s\tremaining: 35.9s\n",
      "58:\tlearn: 0.8897966\ttotal: 2.25s\tremaining: 35.9s\n",
      "59:\tlearn: 0.8885701\ttotal: 2.29s\tremaining: 35.9s\n",
      "60:\tlearn: 0.8851752\ttotal: 2.33s\tremaining: 35.9s\n",
      "61:\tlearn: 0.8820443\ttotal: 2.37s\tremaining: 35.9s\n",
      "62:\tlearn: 0.8799182\ttotal: 2.41s\tremaining: 35.9s\n",
      "63:\tlearn: 0.8785484\ttotal: 2.45s\tremaining: 35.9s\n",
      "64:\tlearn: 0.8770912\ttotal: 2.49s\tremaining: 35.8s\n",
      "65:\tlearn: 0.8755841\ttotal: 2.53s\tremaining: 35.8s\n",
      "66:\tlearn: 0.8728397\ttotal: 2.56s\tremaining: 35.7s\n",
      "67:\tlearn: 0.8717193\ttotal: 2.6s\tremaining: 35.6s\n",
      "68:\tlearn: 0.8707165\ttotal: 2.64s\tremaining: 35.6s\n",
      "69:\tlearn: 0.8696313\ttotal: 2.68s\tremaining: 35.6s\n",
      "70:\tlearn: 0.8683978\ttotal: 2.71s\tremaining: 35.5s\n",
      "71:\tlearn: 0.8670614\ttotal: 2.75s\tremaining: 35.5s\n",
      "72:\tlearn: 0.8655455\ttotal: 2.79s\tremaining: 35.5s\n",
      "73:\tlearn: 0.8644228\ttotal: 2.83s\tremaining: 35.4s\n",
      "74:\tlearn: 0.8636065\ttotal: 2.86s\tremaining: 35.3s\n",
      "75:\tlearn: 0.8623973\ttotal: 2.9s\tremaining: 35.3s\n",
      "76:\tlearn: 0.8605457\ttotal: 2.94s\tremaining: 35.3s\n",
      "77:\tlearn: 0.8583230\ttotal: 2.98s\tremaining: 35.3s\n",
      "78:\tlearn: 0.8562646\ttotal: 3.02s\tremaining: 35.2s\n",
      "79:\tlearn: 0.8548029\ttotal: 3.06s\tremaining: 35.2s\n",
      "80:\tlearn: 0.8534782\ttotal: 3.09s\tremaining: 35.1s\n",
      "81:\tlearn: 0.8520772\ttotal: 3.13s\tremaining: 35s\n",
      "82:\tlearn: 0.8502929\ttotal: 3.17s\tremaining: 35s\n",
      "83:\tlearn: 0.8484042\ttotal: 3.2s\tremaining: 34.9s\n",
      "84:\tlearn: 0.8475385\ttotal: 3.24s\tremaining: 34.9s\n",
      "85:\tlearn: 0.8462662\ttotal: 3.28s\tremaining: 34.8s\n",
      "86:\tlearn: 0.8451022\ttotal: 3.31s\tremaining: 34.7s\n",
      "87:\tlearn: 0.8424542\ttotal: 3.35s\tremaining: 34.7s\n",
      "88:\tlearn: 0.8409319\ttotal: 3.38s\tremaining: 34.6s\n",
      "89:\tlearn: 0.8392471\ttotal: 3.42s\tremaining: 34.6s\n",
      "90:\tlearn: 0.8379793\ttotal: 3.46s\tremaining: 34.5s\n",
      "91:\tlearn: 0.8359652\ttotal: 3.49s\tremaining: 34.4s\n",
      "92:\tlearn: 0.8334046\ttotal: 3.53s\tremaining: 34.4s\n",
      "93:\tlearn: 0.8315617\ttotal: 3.56s\tremaining: 34.4s\n",
      "94:\tlearn: 0.8297187\ttotal: 3.6s\tremaining: 34.3s\n",
      "95:\tlearn: 0.8281377\ttotal: 3.63s\tremaining: 34.2s\n",
      "96:\tlearn: 0.8269303\ttotal: 3.67s\tremaining: 34.1s\n",
      "97:\tlearn: 0.8246712\ttotal: 3.7s\tremaining: 34.1s\n",
      "98:\tlearn: 0.8236845\ttotal: 3.74s\tremaining: 34.1s\n",
      "99:\tlearn: 0.8224236\ttotal: 3.78s\tremaining: 34.1s\n",
      "100:\tlearn: 0.8211842\ttotal: 3.82s\tremaining: 34s\n",
      "101:\tlearn: 0.8195973\ttotal: 3.85s\tremaining: 33.9s\n",
      "102:\tlearn: 0.8180007\ttotal: 3.89s\tremaining: 33.9s\n",
      "103:\tlearn: 0.8164869\ttotal: 3.93s\tremaining: 33.8s\n",
      "104:\tlearn: 0.8151519\ttotal: 3.97s\tremaining: 33.8s\n",
      "105:\tlearn: 0.8145445\ttotal: 4.01s\tremaining: 33.8s\n",
      "106:\tlearn: 0.8127682\ttotal: 4.04s\tremaining: 33.8s\n",
      "107:\tlearn: 0.8105900\ttotal: 4.08s\tremaining: 33.7s\n",
      "108:\tlearn: 0.8085360\ttotal: 4.12s\tremaining: 33.6s\n",
      "109:\tlearn: 0.8066404\ttotal: 4.15s\tremaining: 33.6s\n",
      "110:\tlearn: 0.8049279\ttotal: 4.19s\tremaining: 33.6s\n",
      "111:\tlearn: 0.8028334\ttotal: 4.23s\tremaining: 33.5s\n",
      "112:\tlearn: 0.8012129\ttotal: 4.27s\tremaining: 33.5s\n",
      "113:\tlearn: 0.7994520\ttotal: 4.3s\tremaining: 33.4s\n",
      "114:\tlearn: 0.7978120\ttotal: 4.34s\tremaining: 33.4s\n",
      "115:\tlearn: 0.7959344\ttotal: 4.37s\tremaining: 33.3s\n",
      "116:\tlearn: 0.7932102\ttotal: 4.41s\tremaining: 33.3s\n",
      "117:\tlearn: 0.7914866\ttotal: 4.45s\tremaining: 33.2s\n",
      "118:\tlearn: 0.7888055\ttotal: 4.48s\tremaining: 33.2s\n",
      "119:\tlearn: 0.7876116\ttotal: 4.52s\tremaining: 33.2s\n",
      "120:\tlearn: 0.7856670\ttotal: 4.56s\tremaining: 33.1s\n",
      "121:\tlearn: 0.7829577\ttotal: 4.6s\tremaining: 33.1s\n",
      "122:\tlearn: 0.7819029\ttotal: 4.64s\tremaining: 33.1s\n",
      "123:\tlearn: 0.7795629\ttotal: 4.68s\tremaining: 33.1s\n",
      "124:\tlearn: 0.7778386\ttotal: 4.72s\tremaining: 33s\n",
      "125:\tlearn: 0.7753301\ttotal: 4.76s\tremaining: 33s\n",
      "126:\tlearn: 0.7737396\ttotal: 4.79s\tremaining: 32.9s\n",
      "127:\tlearn: 0.7719479\ttotal: 4.83s\tremaining: 32.9s\n",
      "128:\tlearn: 0.7702362\ttotal: 4.87s\tremaining: 32.9s\n",
      "129:\tlearn: 0.7691097\ttotal: 4.9s\tremaining: 32.8s\n",
      "130:\tlearn: 0.7652014\ttotal: 4.94s\tremaining: 32.7s\n",
      "131:\tlearn: 0.7636409\ttotal: 4.97s\tremaining: 32.7s\n",
      "132:\tlearn: 0.7625949\ttotal: 5s\tremaining: 32.6s\n",
      "133:\tlearn: 0.7609991\ttotal: 5.04s\tremaining: 32.6s\n",
      "134:\tlearn: 0.7597634\ttotal: 5.07s\tremaining: 32.5s\n",
      "135:\tlearn: 0.7581496\ttotal: 5.1s\tremaining: 32.4s\n",
      "136:\tlearn: 0.7566646\ttotal: 5.14s\tremaining: 32.4s\n",
      "137:\tlearn: 0.7554567\ttotal: 5.17s\tremaining: 32.3s\n",
      "138:\tlearn: 0.7533103\ttotal: 5.2s\tremaining: 32.2s\n",
      "139:\tlearn: 0.7503706\ttotal: 5.24s\tremaining: 32.2s\n",
      "140:\tlearn: 0.7482546\ttotal: 5.27s\tremaining: 32.1s\n",
      "141:\tlearn: 0.7460356\ttotal: 5.31s\tremaining: 32.1s\n",
      "142:\tlearn: 0.7448135\ttotal: 5.35s\tremaining: 32.1s\n",
      "143:\tlearn: 0.7431681\ttotal: 5.39s\tremaining: 32s\n",
      "144:\tlearn: 0.7412519\ttotal: 5.42s\tremaining: 32s\n",
      "145:\tlearn: 0.7399782\ttotal: 5.45s\tremaining: 31.9s\n",
      "146:\tlearn: 0.7388695\ttotal: 5.49s\tremaining: 31.8s\n",
      "147:\tlearn: 0.7380959\ttotal: 5.52s\tremaining: 31.8s\n",
      "148:\tlearn: 0.7361699\ttotal: 5.55s\tremaining: 31.7s\n",
      "149:\tlearn: 0.7341409\ttotal: 5.59s\tremaining: 31.7s\n",
      "150:\tlearn: 0.7333104\ttotal: 5.63s\tremaining: 31.6s\n",
      "151:\tlearn: 0.7312115\ttotal: 5.66s\tremaining: 31.6s\n",
      "152:\tlearn: 0.7295981\ttotal: 5.7s\tremaining: 31.6s\n",
      "153:\tlearn: 0.7283415\ttotal: 5.74s\tremaining: 31.5s\n",
      "154:\tlearn: 0.7275839\ttotal: 5.77s\tremaining: 31.5s\n",
      "155:\tlearn: 0.7255500\ttotal: 5.81s\tremaining: 31.4s\n",
      "156:\tlearn: 0.7237327\ttotal: 5.84s\tremaining: 31.4s\n",
      "157:\tlearn: 0.7215140\ttotal: 5.88s\tremaining: 31.3s\n",
      "158:\tlearn: 0.7205982\ttotal: 5.92s\tremaining: 31.3s\n",
      "159:\tlearn: 0.7190162\ttotal: 5.96s\tremaining: 31.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160:\tlearn: 0.7183129\ttotal: 5.99s\tremaining: 31.2s\n",
      "161:\tlearn: 0.7170219\ttotal: 6.02s\tremaining: 31.2s\n",
      "162:\tlearn: 0.7153932\ttotal: 6.06s\tremaining: 31.1s\n",
      "163:\tlearn: 0.7147523\ttotal: 6.09s\tremaining: 31s\n",
      "164:\tlearn: 0.7135832\ttotal: 6.12s\tremaining: 31s\n",
      "165:\tlearn: 0.7129657\ttotal: 6.16s\tremaining: 30.9s\n",
      "166:\tlearn: 0.7117811\ttotal: 6.2s\tremaining: 30.9s\n",
      "167:\tlearn: 0.7103035\ttotal: 6.23s\tremaining: 30.9s\n",
      "168:\tlearn: 0.7087288\ttotal: 6.27s\tremaining: 30.8s\n",
      "169:\tlearn: 0.7067649\ttotal: 6.31s\tremaining: 30.8s\n",
      "170:\tlearn: 0.7051721\ttotal: 6.34s\tremaining: 30.8s\n",
      "171:\tlearn: 0.7042717\ttotal: 6.38s\tremaining: 30.7s\n",
      "172:\tlearn: 0.7023815\ttotal: 6.42s\tremaining: 30.7s\n",
      "173:\tlearn: 0.7011137\ttotal: 6.45s\tremaining: 30.6s\n",
      "174:\tlearn: 0.6994115\ttotal: 6.49s\tremaining: 30.6s\n",
      "175:\tlearn: 0.6984096\ttotal: 6.53s\tremaining: 30.6s\n",
      "176:\tlearn: 0.6968316\ttotal: 6.56s\tremaining: 30.5s\n",
      "177:\tlearn: 0.6953114\ttotal: 6.6s\tremaining: 30.5s\n",
      "178:\tlearn: 0.6937538\ttotal: 6.64s\tremaining: 30.4s\n",
      "179:\tlearn: 0.6920742\ttotal: 6.67s\tremaining: 30.4s\n",
      "180:\tlearn: 0.6911910\ttotal: 6.71s\tremaining: 30.4s\n",
      "181:\tlearn: 0.6902344\ttotal: 6.75s\tremaining: 30.3s\n",
      "182:\tlearn: 0.6885731\ttotal: 6.78s\tremaining: 30.3s\n",
      "183:\tlearn: 0.6870867\ttotal: 6.82s\tremaining: 30.2s\n",
      "184:\tlearn: 0.6848275\ttotal: 6.85s\tremaining: 30.2s\n",
      "185:\tlearn: 0.6835774\ttotal: 6.89s\tremaining: 30.1s\n",
      "186:\tlearn: 0.6818418\ttotal: 6.92s\tremaining: 30.1s\n",
      "187:\tlearn: 0.6814996\ttotal: 6.95s\tremaining: 30s\n",
      "188:\tlearn: 0.6803767\ttotal: 6.99s\tremaining: 30s\n",
      "189:\tlearn: 0.6791495\ttotal: 7.02s\tremaining: 29.9s\n",
      "190:\tlearn: 0.6784432\ttotal: 7.05s\tremaining: 29.9s\n",
      "191:\tlearn: 0.6766660\ttotal: 7.09s\tremaining: 29.8s\n",
      "192:\tlearn: 0.6758023\ttotal: 7.12s\tremaining: 29.8s\n",
      "193:\tlearn: 0.6753567\ttotal: 7.16s\tremaining: 29.7s\n",
      "194:\tlearn: 0.6747283\ttotal: 7.19s\tremaining: 29.7s\n",
      "195:\tlearn: 0.6734958\ttotal: 7.22s\tremaining: 29.6s\n",
      "196:\tlearn: 0.6714528\ttotal: 7.25s\tremaining: 29.6s\n",
      "197:\tlearn: 0.6701426\ttotal: 7.29s\tremaining: 29.5s\n",
      "198:\tlearn: 0.6692626\ttotal: 7.33s\tremaining: 29.5s\n",
      "199:\tlearn: 0.6678303\ttotal: 7.37s\tremaining: 29.5s\n",
      "200:\tlearn: 0.6668393\ttotal: 7.4s\tremaining: 29.4s\n",
      "201:\tlearn: 0.6654073\ttotal: 7.44s\tremaining: 29.4s\n",
      "202:\tlearn: 0.6637449\ttotal: 7.47s\tremaining: 29.3s\n",
      "203:\tlearn: 0.6625302\ttotal: 7.51s\tremaining: 29.3s\n",
      "204:\tlearn: 0.6603176\ttotal: 7.55s\tremaining: 29.3s\n",
      "205:\tlearn: 0.6591002\ttotal: 7.58s\tremaining: 29.2s\n",
      "206:\tlearn: 0.6587715\ttotal: 7.62s\tremaining: 29.2s\n",
      "207:\tlearn: 0.6578777\ttotal: 7.66s\tremaining: 29.1s\n",
      "208:\tlearn: 0.6565343\ttotal: 7.69s\tremaining: 29.1s\n",
      "209:\tlearn: 0.6557439\ttotal: 7.72s\tremaining: 29s\n",
      "210:\tlearn: 0.6544384\ttotal: 7.75s\tremaining: 29s\n",
      "211:\tlearn: 0.6537944\ttotal: 7.79s\tremaining: 28.9s\n",
      "212:\tlearn: 0.6528749\ttotal: 7.82s\tremaining: 28.9s\n",
      "213:\tlearn: 0.6518031\ttotal: 7.85s\tremaining: 28.8s\n",
      "214:\tlearn: 0.6502424\ttotal: 7.88s\tremaining: 28.8s\n",
      "215:\tlearn: 0.6487768\ttotal: 7.92s\tremaining: 28.7s\n",
      "216:\tlearn: 0.6478631\ttotal: 7.95s\tremaining: 28.7s\n",
      "217:\tlearn: 0.6468363\ttotal: 7.98s\tremaining: 28.6s\n",
      "218:\tlearn: 0.6455704\ttotal: 8.02s\tremaining: 28.6s\n",
      "219:\tlearn: 0.6442436\ttotal: 8.05s\tremaining: 28.6s\n",
      "220:\tlearn: 0.6434724\ttotal: 8.09s\tremaining: 28.5s\n",
      "221:\tlearn: 0.6419496\ttotal: 8.12s\tremaining: 28.5s\n",
      "222:\tlearn: 0.6405865\ttotal: 8.15s\tremaining: 28.4s\n",
      "223:\tlearn: 0.6392750\ttotal: 8.19s\tremaining: 28.4s\n",
      "224:\tlearn: 0.6380096\ttotal: 8.22s\tremaining: 28.3s\n",
      "225:\tlearn: 0.6371968\ttotal: 8.26s\tremaining: 28.3s\n",
      "226:\tlearn: 0.6363026\ttotal: 8.29s\tremaining: 28.2s\n",
      "227:\tlearn: 0.6355602\ttotal: 8.32s\tremaining: 28.2s\n",
      "228:\tlearn: 0.6340801\ttotal: 8.35s\tremaining: 28.1s\n",
      "229:\tlearn: 0.6337536\ttotal: 8.39s\tremaining: 28.1s\n",
      "230:\tlearn: 0.6328232\ttotal: 8.42s\tremaining: 28s\n",
      "231:\tlearn: 0.6311740\ttotal: 8.45s\tremaining: 28s\n",
      "232:\tlearn: 0.6299447\ttotal: 8.49s\tremaining: 27.9s\n",
      "233:\tlearn: 0.6290789\ttotal: 8.52s\tremaining: 27.9s\n",
      "234:\tlearn: 0.6281505\ttotal: 8.56s\tremaining: 27.9s\n",
      "235:\tlearn: 0.6271318\ttotal: 8.59s\tremaining: 27.8s\n",
      "236:\tlearn: 0.6262164\ttotal: 8.62s\tremaining: 27.8s\n",
      "237:\tlearn: 0.6251335\ttotal: 8.66s\tremaining: 27.7s\n",
      "238:\tlearn: 0.6244592\ttotal: 8.69s\tremaining: 27.7s\n",
      "239:\tlearn: 0.6236953\ttotal: 8.72s\tremaining: 27.6s\n",
      "240:\tlearn: 0.6229082\ttotal: 8.76s\tremaining: 27.6s\n",
      "241:\tlearn: 0.6217071\ttotal: 8.79s\tremaining: 27.5s\n",
      "242:\tlearn: 0.6199800\ttotal: 8.82s\tremaining: 27.5s\n",
      "243:\tlearn: 0.6194037\ttotal: 8.86s\tremaining: 27.4s\n",
      "244:\tlearn: 0.6185974\ttotal: 8.89s\tremaining: 27.4s\n",
      "245:\tlearn: 0.6171470\ttotal: 8.93s\tremaining: 27.4s\n",
      "246:\tlearn: 0.6159366\ttotal: 8.96s\tremaining: 27.3s\n",
      "247:\tlearn: 0.6145316\ttotal: 9s\tremaining: 27.3s\n",
      "248:\tlearn: 0.6134478\ttotal: 9.03s\tremaining: 27.2s\n",
      "249:\tlearn: 0.6124689\ttotal: 9.06s\tremaining: 27.2s\n",
      "250:\tlearn: 0.6113728\ttotal: 9.1s\tremaining: 27.2s\n",
      "251:\tlearn: 0.6104095\ttotal: 9.13s\tremaining: 27.1s\n",
      "252:\tlearn: 0.6095162\ttotal: 9.17s\tremaining: 27.1s\n",
      "253:\tlearn: 0.6085624\ttotal: 9.21s\tremaining: 27s\n",
      "254:\tlearn: 0.6073445\ttotal: 9.24s\tremaining: 27s\n",
      "255:\tlearn: 0.6066614\ttotal: 9.28s\tremaining: 27s\n",
      "256:\tlearn: 0.6055476\ttotal: 9.31s\tremaining: 26.9s\n",
      "257:\tlearn: 0.6046887\ttotal: 9.34s\tremaining: 26.9s\n",
      "258:\tlearn: 0.6034229\ttotal: 9.38s\tremaining: 26.8s\n",
      "259:\tlearn: 0.6019632\ttotal: 9.42s\tremaining: 26.8s\n",
      "260:\tlearn: 0.6002019\ttotal: 9.45s\tremaining: 26.8s\n",
      "261:\tlearn: 0.5993342\ttotal: 9.49s\tremaining: 26.7s\n",
      "262:\tlearn: 0.5981291\ttotal: 9.53s\tremaining: 26.7s\n",
      "263:\tlearn: 0.5967712\ttotal: 9.56s\tremaining: 26.7s\n",
      "264:\tlearn: 0.5953881\ttotal: 9.6s\tremaining: 26.6s\n",
      "265:\tlearn: 0.5947436\ttotal: 9.64s\tremaining: 26.6s\n",
      "266:\tlearn: 0.5938508\ttotal: 9.68s\tremaining: 26.6s\n",
      "267:\tlearn: 0.5928589\ttotal: 9.71s\tremaining: 26.5s\n",
      "268:\tlearn: 0.5916925\ttotal: 9.75s\tremaining: 26.5s\n",
      "269:\tlearn: 0.5905157\ttotal: 9.78s\tremaining: 26.4s\n",
      "270:\tlearn: 0.5894744\ttotal: 9.82s\tremaining: 26.4s\n",
      "271:\tlearn: 0.5885291\ttotal: 9.85s\tremaining: 26.4s\n",
      "272:\tlearn: 0.5879311\ttotal: 9.89s\tremaining: 26.3s\n",
      "273:\tlearn: 0.5873053\ttotal: 9.92s\tremaining: 26.3s\n",
      "274:\tlearn: 0.5862890\ttotal: 9.96s\tremaining: 26.3s\n",
      "275:\tlearn: 0.5848784\ttotal: 9.99s\tremaining: 26.2s\n",
      "276:\tlearn: 0.5832584\ttotal: 10s\tremaining: 26.2s\n",
      "277:\tlearn: 0.5822665\ttotal: 10.1s\tremaining: 26.1s\n",
      "278:\tlearn: 0.5809902\ttotal: 10.1s\tremaining: 26.1s\n",
      "279:\tlearn: 0.5801767\ttotal: 10.1s\tremaining: 26.1s\n",
      "280:\tlearn: 0.5795074\ttotal: 10.2s\tremaining: 26s\n",
      "281:\tlearn: 0.5782697\ttotal: 10.2s\tremaining: 26s\n",
      "282:\tlearn: 0.5772655\ttotal: 10.2s\tremaining: 25.9s\n",
      "283:\tlearn: 0.5759308\ttotal: 10.3s\tremaining: 25.9s\n",
      "284:\tlearn: 0.5747610\ttotal: 10.3s\tremaining: 25.9s\n",
      "285:\tlearn: 0.5740006\ttotal: 10.3s\tremaining: 25.8s\n",
      "286:\tlearn: 0.5733133\ttotal: 10.4s\tremaining: 25.8s\n",
      "287:\tlearn: 0.5728271\ttotal: 10.4s\tremaining: 25.7s\n",
      "288:\tlearn: 0.5718686\ttotal: 10.4s\tremaining: 25.7s\n",
      "289:\tlearn: 0.5710002\ttotal: 10.5s\tremaining: 25.7s\n",
      "290:\tlearn: 0.5694451\ttotal: 10.5s\tremaining: 25.6s\n",
      "291:\tlearn: 0.5686830\ttotal: 10.5s\tremaining: 25.6s\n",
      "292:\tlearn: 0.5682900\ttotal: 10.6s\tremaining: 25.5s\n",
      "293:\tlearn: 0.5673509\ttotal: 10.6s\tremaining: 25.5s\n",
      "294:\tlearn: 0.5657581\ttotal: 10.7s\tremaining: 25.5s\n",
      "295:\tlearn: 0.5647578\ttotal: 10.7s\tremaining: 25.4s\n",
      "296:\tlearn: 0.5635633\ttotal: 10.7s\tremaining: 25.4s\n",
      "297:\tlearn: 0.5625820\ttotal: 10.8s\tremaining: 25.3s\n",
      "298:\tlearn: 0.5619026\ttotal: 10.8s\tremaining: 25.3s\n",
      "299:\tlearn: 0.5608563\ttotal: 10.8s\tremaining: 25.3s\n",
      "300:\tlearn: 0.5595782\ttotal: 10.9s\tremaining: 25.2s\n",
      "301:\tlearn: 0.5586963\ttotal: 10.9s\tremaining: 25.2s\n",
      "302:\tlearn: 0.5578897\ttotal: 10.9s\tremaining: 25.2s\n",
      "303:\tlearn: 0.5572285\ttotal: 11s\tremaining: 25.1s\n",
      "304:\tlearn: 0.5567847\ttotal: 11s\tremaining: 25.1s\n",
      "305:\tlearn: 0.5555528\ttotal: 11.1s\tremaining: 25.1s\n",
      "306:\tlearn: 0.5548763\ttotal: 11.1s\tremaining: 25s\n",
      "307:\tlearn: 0.5537357\ttotal: 11.1s\tremaining: 25s\n",
      "308:\tlearn: 0.5524344\ttotal: 11.2s\tremaining: 25s\n",
      "309:\tlearn: 0.5517055\ttotal: 11.2s\tremaining: 24.9s\n",
      "310:\tlearn: 0.5509686\ttotal: 11.2s\tremaining: 24.9s\n",
      "311:\tlearn: 0.5500020\ttotal: 11.3s\tremaining: 24.8s\n",
      "312:\tlearn: 0.5487199\ttotal: 11.3s\tremaining: 24.8s\n",
      "313:\tlearn: 0.5479597\ttotal: 11.3s\tremaining: 24.8s\n",
      "314:\tlearn: 0.5469807\ttotal: 11.4s\tremaining: 24.7s\n",
      "315:\tlearn: 0.5460746\ttotal: 11.4s\tremaining: 24.7s\n",
      "316:\tlearn: 0.5450278\ttotal: 11.4s\tremaining: 24.6s\n",
      "317:\tlearn: 0.5440540\ttotal: 11.5s\tremaining: 24.6s\n",
      "318:\tlearn: 0.5429959\ttotal: 11.5s\tremaining: 24.6s\n",
      "319:\tlearn: 0.5421916\ttotal: 11.5s\tremaining: 24.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320:\tlearn: 0.5409535\ttotal: 11.6s\tremaining: 24.5s\n",
      "321:\tlearn: 0.5401629\ttotal: 11.6s\tremaining: 24.5s\n",
      "322:\tlearn: 0.5386890\ttotal: 11.6s\tremaining: 24.4s\n",
      "323:\tlearn: 0.5381836\ttotal: 11.7s\tremaining: 24.4s\n",
      "324:\tlearn: 0.5374836\ttotal: 11.7s\tremaining: 24.3s\n",
      "325:\tlearn: 0.5368025\ttotal: 11.8s\tremaining: 24.3s\n",
      "326:\tlearn: 0.5356891\ttotal: 11.8s\tremaining: 24.3s\n",
      "327:\tlearn: 0.5349100\ttotal: 11.8s\tremaining: 24.2s\n",
      "328:\tlearn: 0.5343611\ttotal: 11.9s\tremaining: 24.2s\n",
      "329:\tlearn: 0.5333845\ttotal: 11.9s\tremaining: 24.1s\n",
      "330:\tlearn: 0.5327783\ttotal: 11.9s\tremaining: 24.1s\n",
      "331:\tlearn: 0.5322757\ttotal: 12s\tremaining: 24.1s\n",
      "332:\tlearn: 0.5311456\ttotal: 12s\tremaining: 24s\n",
      "333:\tlearn: 0.5301208\ttotal: 12s\tremaining: 24s\n",
      "334:\tlearn: 0.5291172\ttotal: 12.1s\tremaining: 24s\n",
      "335:\tlearn: 0.5283950\ttotal: 12.1s\tremaining: 23.9s\n",
      "336:\tlearn: 0.5274624\ttotal: 12.1s\tremaining: 23.9s\n",
      "337:\tlearn: 0.5270191\ttotal: 12.2s\tremaining: 23.9s\n",
      "338:\tlearn: 0.5255212\ttotal: 12.2s\tremaining: 23.8s\n",
      "339:\tlearn: 0.5251478\ttotal: 12.3s\tremaining: 23.8s\n",
      "340:\tlearn: 0.5236745\ttotal: 12.3s\tremaining: 23.8s\n",
      "341:\tlearn: 0.5232008\ttotal: 12.3s\tremaining: 23.7s\n",
      "342:\tlearn: 0.5221834\ttotal: 12.4s\tremaining: 23.7s\n",
      "343:\tlearn: 0.5215789\ttotal: 12.4s\tremaining: 23.6s\n",
      "344:\tlearn: 0.5204362\ttotal: 12.4s\tremaining: 23.6s\n",
      "345:\tlearn: 0.5195251\ttotal: 12.5s\tremaining: 23.6s\n",
      "346:\tlearn: 0.5185973\ttotal: 12.5s\tremaining: 23.5s\n",
      "347:\tlearn: 0.5180034\ttotal: 12.5s\tremaining: 23.5s\n",
      "348:\tlearn: 0.5171990\ttotal: 12.6s\tremaining: 23.5s\n",
      "349:\tlearn: 0.5168682\ttotal: 12.6s\tremaining: 23.4s\n",
      "350:\tlearn: 0.5157723\ttotal: 12.6s\tremaining: 23.4s\n",
      "351:\tlearn: 0.5146153\ttotal: 12.7s\tremaining: 23.4s\n",
      "352:\tlearn: 0.5138133\ttotal: 12.7s\tremaining: 23.3s\n",
      "353:\tlearn: 0.5129249\ttotal: 12.8s\tremaining: 23.3s\n",
      "354:\tlearn: 0.5123140\ttotal: 12.8s\tremaining: 23.3s\n",
      "355:\tlearn: 0.5116897\ttotal: 12.9s\tremaining: 23.3s\n",
      "356:\tlearn: 0.5109022\ttotal: 12.9s\tremaining: 23.2s\n",
      "357:\tlearn: 0.5096585\ttotal: 12.9s\tremaining: 23.2s\n",
      "358:\tlearn: 0.5093157\ttotal: 13s\tremaining: 23.2s\n",
      "359:\tlearn: 0.5087164\ttotal: 13s\tremaining: 23.2s\n",
      "360:\tlearn: 0.5083987\ttotal: 13.1s\tremaining: 23.1s\n",
      "361:\tlearn: 0.5073993\ttotal: 13.1s\tremaining: 23.1s\n",
      "362:\tlearn: 0.5065118\ttotal: 13.2s\tremaining: 23.1s\n",
      "363:\tlearn: 0.5058687\ttotal: 13.2s\tremaining: 23.1s\n",
      "364:\tlearn: 0.5055472\ttotal: 13.2s\tremaining: 23.1s\n",
      "365:\tlearn: 0.5041404\ttotal: 13.3s\tremaining: 23s\n",
      "366:\tlearn: 0.5024474\ttotal: 13.3s\tremaining: 23s\n",
      "367:\tlearn: 0.5016991\ttotal: 13.4s\tremaining: 23s\n",
      "368:\tlearn: 0.5005838\ttotal: 13.4s\tremaining: 22.9s\n",
      "369:\tlearn: 0.5000847\ttotal: 13.4s\tremaining: 22.9s\n",
      "370:\tlearn: 0.4993323\ttotal: 13.5s\tremaining: 22.8s\n",
      "371:\tlearn: 0.4985002\ttotal: 13.5s\tremaining: 22.8s\n",
      "372:\tlearn: 0.4976134\ttotal: 13.6s\tremaining: 22.8s\n",
      "373:\tlearn: 0.4971127\ttotal: 13.6s\tremaining: 22.8s\n",
      "374:\tlearn: 0.4959515\ttotal: 13.6s\tremaining: 22.7s\n",
      "375:\tlearn: 0.4945281\ttotal: 13.7s\tremaining: 22.7s\n",
      "376:\tlearn: 0.4936609\ttotal: 13.7s\tremaining: 22.7s\n",
      "377:\tlearn: 0.4931405\ttotal: 13.8s\tremaining: 22.7s\n",
      "378:\tlearn: 0.4927582\ttotal: 13.8s\tremaining: 22.6s\n",
      "379:\tlearn: 0.4922880\ttotal: 13.8s\tremaining: 22.6s\n",
      "380:\tlearn: 0.4908082\ttotal: 13.9s\tremaining: 22.6s\n",
      "381:\tlearn: 0.4900688\ttotal: 13.9s\tremaining: 22.5s\n",
      "382:\tlearn: 0.4896547\ttotal: 14s\tremaining: 22.5s\n",
      "383:\tlearn: 0.4886760\ttotal: 14s\tremaining: 22.5s\n",
      "384:\tlearn: 0.4882241\ttotal: 14s\tremaining: 22.4s\n",
      "385:\tlearn: 0.4871647\ttotal: 14.1s\tremaining: 22.4s\n",
      "386:\tlearn: 0.4862344\ttotal: 14.1s\tremaining: 22.4s\n",
      "387:\tlearn: 0.4854818\ttotal: 14.2s\tremaining: 22.3s\n",
      "388:\tlearn: 0.4850666\ttotal: 14.2s\tremaining: 22.3s\n",
      "389:\tlearn: 0.4842796\ttotal: 14.2s\tremaining: 22.3s\n",
      "390:\tlearn: 0.4835879\ttotal: 14.3s\tremaining: 22.2s\n",
      "391:\tlearn: 0.4825683\ttotal: 14.3s\tremaining: 22.2s\n",
      "392:\tlearn: 0.4823073\ttotal: 14.4s\tremaining: 22.2s\n",
      "393:\tlearn: 0.4817945\ttotal: 14.4s\tremaining: 22.1s\n",
      "394:\tlearn: 0.4815285\ttotal: 14.4s\tremaining: 22.1s\n",
      "395:\tlearn: 0.4806044\ttotal: 14.5s\tremaining: 22.1s\n",
      "396:\tlearn: 0.4795553\ttotal: 14.5s\tremaining: 22s\n",
      "397:\tlearn: 0.4788558\ttotal: 14.5s\tremaining: 22s\n",
      "398:\tlearn: 0.4784797\ttotal: 14.6s\tremaining: 22s\n",
      "399:\tlearn: 0.4780787\ttotal: 14.6s\tremaining: 21.9s\n",
      "400:\tlearn: 0.4771900\ttotal: 14.7s\tremaining: 21.9s\n",
      "401:\tlearn: 0.4763867\ttotal: 14.7s\tremaining: 21.9s\n",
      "402:\tlearn: 0.4755572\ttotal: 14.7s\tremaining: 21.8s\n",
      "403:\tlearn: 0.4746543\ttotal: 14.8s\tremaining: 21.8s\n",
      "404:\tlearn: 0.4735546\ttotal: 14.8s\tremaining: 21.8s\n",
      "405:\tlearn: 0.4731021\ttotal: 14.9s\tremaining: 21.7s\n",
      "406:\tlearn: 0.4725849\ttotal: 14.9s\tremaining: 21.7s\n",
      "407:\tlearn: 0.4706372\ttotal: 14.9s\tremaining: 21.7s\n",
      "408:\tlearn: 0.4695677\ttotal: 15s\tremaining: 21.6s\n",
      "409:\tlearn: 0.4684774\ttotal: 15s\tremaining: 21.6s\n",
      "410:\tlearn: 0.4673937\ttotal: 15s\tremaining: 21.6s\n",
      "411:\tlearn: 0.4666076\ttotal: 15.1s\tremaining: 21.5s\n",
      "412:\tlearn: 0.4660128\ttotal: 15.1s\tremaining: 21.5s\n",
      "413:\tlearn: 0.4654894\ttotal: 15.2s\tremaining: 21.5s\n",
      "414:\tlearn: 0.4647863\ttotal: 15.2s\tremaining: 21.4s\n",
      "415:\tlearn: 0.4640775\ttotal: 15.2s\tremaining: 21.4s\n",
      "416:\tlearn: 0.4632666\ttotal: 15.3s\tremaining: 21.4s\n",
      "417:\tlearn: 0.4624375\ttotal: 15.3s\tremaining: 21.3s\n",
      "418:\tlearn: 0.4614622\ttotal: 15.4s\tremaining: 21.3s\n",
      "419:\tlearn: 0.4609728\ttotal: 15.4s\tremaining: 21.3s\n",
      "420:\tlearn: 0.4596136\ttotal: 15.4s\tremaining: 21.2s\n",
      "421:\tlearn: 0.4593894\ttotal: 15.5s\tremaining: 21.2s\n",
      "422:\tlearn: 0.4590072\ttotal: 15.5s\tremaining: 21.2s\n",
      "423:\tlearn: 0.4581791\ttotal: 15.5s\tremaining: 21.1s\n",
      "424:\tlearn: 0.4575624\ttotal: 15.6s\tremaining: 21.1s\n",
      "425:\tlearn: 0.4567634\ttotal: 15.6s\tremaining: 21s\n",
      "426:\tlearn: 0.4559569\ttotal: 15.7s\tremaining: 21s\n",
      "427:\tlearn: 0.4554188\ttotal: 15.7s\tremaining: 21s\n",
      "428:\tlearn: 0.4538609\ttotal: 15.7s\tremaining: 21s\n",
      "429:\tlearn: 0.4533902\ttotal: 15.8s\tremaining: 20.9s\n",
      "430:\tlearn: 0.4530133\ttotal: 15.8s\tremaining: 20.9s\n",
      "431:\tlearn: 0.4525218\ttotal: 15.9s\tremaining: 20.9s\n",
      "432:\tlearn: 0.4508632\ttotal: 15.9s\tremaining: 20.8s\n",
      "433:\tlearn: 0.4500390\ttotal: 15.9s\tremaining: 20.8s\n",
      "434:\tlearn: 0.4492668\ttotal: 16s\tremaining: 20.8s\n",
      "435:\tlearn: 0.4487311\ttotal: 16s\tremaining: 20.7s\n",
      "436:\tlearn: 0.4479924\ttotal: 16.1s\tremaining: 20.7s\n",
      "437:\tlearn: 0.4473845\ttotal: 16.1s\tremaining: 20.7s\n",
      "438:\tlearn: 0.4464874\ttotal: 16.1s\tremaining: 20.6s\n",
      "439:\tlearn: 0.4453882\ttotal: 16.2s\tremaining: 20.6s\n",
      "440:\tlearn: 0.4449149\ttotal: 16.2s\tremaining: 20.5s\n",
      "441:\tlearn: 0.4444305\ttotal: 16.2s\tremaining: 20.5s\n",
      "442:\tlearn: 0.4435967\ttotal: 16.3s\tremaining: 20.5s\n",
      "443:\tlearn: 0.4422149\ttotal: 16.3s\tremaining: 20.4s\n",
      "444:\tlearn: 0.4412143\ttotal: 16.4s\tremaining: 20.4s\n",
      "445:\tlearn: 0.4401644\ttotal: 16.4s\tremaining: 20.4s\n",
      "446:\tlearn: 0.4391258\ttotal: 16.4s\tremaining: 20.3s\n",
      "447:\tlearn: 0.4387051\ttotal: 16.5s\tremaining: 20.3s\n",
      "448:\tlearn: 0.4378971\ttotal: 16.5s\tremaining: 20.3s\n",
      "449:\tlearn: 0.4372720\ttotal: 16.6s\tremaining: 20.2s\n",
      "450:\tlearn: 0.4369283\ttotal: 16.6s\tremaining: 20.2s\n",
      "451:\tlearn: 0.4362873\ttotal: 16.6s\tremaining: 20.2s\n",
      "452:\tlearn: 0.4356832\ttotal: 16.7s\tremaining: 20.1s\n",
      "453:\tlearn: 0.4349157\ttotal: 16.7s\tremaining: 20.1s\n",
      "454:\tlearn: 0.4341561\ttotal: 16.8s\tremaining: 20.1s\n",
      "455:\tlearn: 0.4336224\ttotal: 16.8s\tremaining: 20s\n",
      "456:\tlearn: 0.4331478\ttotal: 16.8s\tremaining: 20s\n",
      "457:\tlearn: 0.4323206\ttotal: 16.9s\tremaining: 20s\n",
      "458:\tlearn: 0.4317247\ttotal: 16.9s\tremaining: 19.9s\n",
      "459:\tlearn: 0.4311205\ttotal: 17s\tremaining: 19.9s\n",
      "460:\tlearn: 0.4302331\ttotal: 17s\tremaining: 19.9s\n",
      "461:\tlearn: 0.4297306\ttotal: 17s\tremaining: 19.8s\n",
      "462:\tlearn: 0.4290956\ttotal: 17.1s\tremaining: 19.8s\n",
      "463:\tlearn: 0.4287431\ttotal: 17.1s\tremaining: 19.8s\n",
      "464:\tlearn: 0.4281863\ttotal: 17.1s\tremaining: 19.7s\n",
      "465:\tlearn: 0.4274613\ttotal: 17.2s\tremaining: 19.7s\n",
      "466:\tlearn: 0.4267120\ttotal: 17.2s\tremaining: 19.7s\n",
      "467:\tlearn: 0.4260940\ttotal: 17.3s\tremaining: 19.6s\n",
      "468:\tlearn: 0.4258101\ttotal: 17.3s\tremaining: 19.6s\n",
      "469:\tlearn: 0.4252839\ttotal: 17.3s\tremaining: 19.6s\n",
      "470:\tlearn: 0.4245267\ttotal: 17.4s\tremaining: 19.5s\n",
      "471:\tlearn: 0.4239180\ttotal: 17.4s\tremaining: 19.5s\n",
      "472:\tlearn: 0.4234371\ttotal: 17.5s\tremaining: 19.5s\n",
      "473:\tlearn: 0.4230705\ttotal: 17.5s\tremaining: 19.4s\n",
      "474:\tlearn: 0.4222341\ttotal: 17.5s\tremaining: 19.4s\n",
      "475:\tlearn: 0.4214866\ttotal: 17.6s\tremaining: 19.4s\n",
      "476:\tlearn: 0.4210854\ttotal: 17.6s\tremaining: 19.3s\n",
      "477:\tlearn: 0.4206732\ttotal: 17.7s\tremaining: 19.3s\n",
      "478:\tlearn: 0.4196659\ttotal: 17.7s\tremaining: 19.2s\n",
      "479:\tlearn: 0.4193901\ttotal: 17.7s\tremaining: 19.2s\n",
      "480:\tlearn: 0.4185717\ttotal: 17.8s\tremaining: 19.2s\n",
      "481:\tlearn: 0.4179484\ttotal: 17.8s\tremaining: 19.1s\n",
      "482:\tlearn: 0.4177231\ttotal: 17.8s\tremaining: 19.1s\n",
      "483:\tlearn: 0.4170536\ttotal: 17.9s\tremaining: 19.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484:\tlearn: 0.4162913\ttotal: 17.9s\tremaining: 19s\n",
      "485:\tlearn: 0.4157114\ttotal: 18s\tremaining: 19s\n",
      "486:\tlearn: 0.4150043\ttotal: 18s\tremaining: 19s\n",
      "487:\tlearn: 0.4145747\ttotal: 18s\tremaining: 18.9s\n",
      "488:\tlearn: 0.4141538\ttotal: 18.1s\tremaining: 18.9s\n",
      "489:\tlearn: 0.4138340\ttotal: 18.1s\tremaining: 18.9s\n",
      "490:\tlearn: 0.4133025\ttotal: 18.2s\tremaining: 18.8s\n",
      "491:\tlearn: 0.4128393\ttotal: 18.2s\tremaining: 18.8s\n",
      "492:\tlearn: 0.4121155\ttotal: 18.2s\tremaining: 18.7s\n",
      "493:\tlearn: 0.4115168\ttotal: 18.3s\tremaining: 18.7s\n",
      "494:\tlearn: 0.4112527\ttotal: 18.3s\tremaining: 18.7s\n",
      "495:\tlearn: 0.4107155\ttotal: 18.3s\tremaining: 18.6s\n",
      "496:\tlearn: 0.4099963\ttotal: 18.4s\tremaining: 18.6s\n",
      "497:\tlearn: 0.4097265\ttotal: 18.4s\tremaining: 18.5s\n",
      "498:\tlearn: 0.4094560\ttotal: 18.4s\tremaining: 18.5s\n",
      "499:\tlearn: 0.4092081\ttotal: 18.5s\tremaining: 18.5s\n",
      "500:\tlearn: 0.4081869\ttotal: 18.5s\tremaining: 18.4s\n",
      "501:\tlearn: 0.4075945\ttotal: 18.5s\tremaining: 18.4s\n",
      "502:\tlearn: 0.4070388\ttotal: 18.6s\tremaining: 18.3s\n",
      "503:\tlearn: 0.4067943\ttotal: 18.6s\tremaining: 18.3s\n",
      "504:\tlearn: 0.4062215\ttotal: 18.6s\tremaining: 18.3s\n",
      "505:\tlearn: 0.4057781\ttotal: 18.7s\tremaining: 18.2s\n",
      "506:\tlearn: 0.4050660\ttotal: 18.7s\tremaining: 18.2s\n",
      "507:\tlearn: 0.4045117\ttotal: 18.7s\tremaining: 18.2s\n",
      "508:\tlearn: 0.4040153\ttotal: 18.8s\tremaining: 18.1s\n",
      "509:\tlearn: 0.4035133\ttotal: 18.8s\tremaining: 18.1s\n",
      "510:\tlearn: 0.4033002\ttotal: 18.8s\tremaining: 18s\n",
      "511:\tlearn: 0.4025519\ttotal: 18.9s\tremaining: 18s\n",
      "512:\tlearn: 0.4021615\ttotal: 18.9s\tremaining: 18s\n",
      "513:\tlearn: 0.4016453\ttotal: 19s\tremaining: 17.9s\n",
      "514:\tlearn: 0.4011958\ttotal: 19s\tremaining: 17.9s\n",
      "515:\tlearn: 0.4002152\ttotal: 19s\tremaining: 17.8s\n",
      "516:\tlearn: 0.3997733\ttotal: 19.1s\tremaining: 17.8s\n",
      "517:\tlearn: 0.3993712\ttotal: 19.1s\tremaining: 17.8s\n",
      "518:\tlearn: 0.3989141\ttotal: 19.1s\tremaining: 17.7s\n",
      "519:\tlearn: 0.3987204\ttotal: 19.2s\tremaining: 17.7s\n",
      "520:\tlearn: 0.3980832\ttotal: 19.2s\tremaining: 17.6s\n",
      "521:\tlearn: 0.3974498\ttotal: 19.2s\tremaining: 17.6s\n",
      "522:\tlearn: 0.3970768\ttotal: 19.3s\tremaining: 17.6s\n",
      "523:\tlearn: 0.3967756\ttotal: 19.3s\tremaining: 17.5s\n",
      "524:\tlearn: 0.3961742\ttotal: 19.3s\tremaining: 17.5s\n",
      "525:\tlearn: 0.3957863\ttotal: 19.4s\tremaining: 17.5s\n",
      "526:\tlearn: 0.3954225\ttotal: 19.4s\tremaining: 17.4s\n",
      "527:\tlearn: 0.3948123\ttotal: 19.4s\tremaining: 17.4s\n",
      "528:\tlearn: 0.3942389\ttotal: 19.5s\tremaining: 17.3s\n",
      "529:\tlearn: 0.3938244\ttotal: 19.5s\tremaining: 17.3s\n",
      "530:\tlearn: 0.3933892\ttotal: 19.5s\tremaining: 17.3s\n",
      "531:\tlearn: 0.3930547\ttotal: 19.6s\tremaining: 17.2s\n",
      "532:\tlearn: 0.3923246\ttotal: 19.6s\tremaining: 17.2s\n",
      "533:\tlearn: 0.3920356\ttotal: 19.6s\tremaining: 17.1s\n",
      "534:\tlearn: 0.3912634\ttotal: 19.7s\tremaining: 17.1s\n",
      "535:\tlearn: 0.3909083\ttotal: 19.7s\tremaining: 17.1s\n",
      "536:\tlearn: 0.3907919\ttotal: 19.8s\tremaining: 17s\n",
      "537:\tlearn: 0.3900165\ttotal: 19.8s\tremaining: 17s\n",
      "538:\tlearn: 0.3896553\ttotal: 19.8s\tremaining: 17s\n",
      "539:\tlearn: 0.3895534\ttotal: 19.9s\tremaining: 16.9s\n",
      "540:\tlearn: 0.3888334\ttotal: 19.9s\tremaining: 16.9s\n",
      "541:\tlearn: 0.3882414\ttotal: 19.9s\tremaining: 16.8s\n",
      "542:\tlearn: 0.3877711\ttotal: 20s\tremaining: 16.8s\n",
      "543:\tlearn: 0.3870964\ttotal: 20s\tremaining: 16.8s\n",
      "544:\tlearn: 0.3862953\ttotal: 20s\tremaining: 16.7s\n",
      "545:\tlearn: 0.3859697\ttotal: 20.1s\tremaining: 16.7s\n",
      "546:\tlearn: 0.3855351\ttotal: 20.1s\tremaining: 16.7s\n",
      "547:\tlearn: 0.3848370\ttotal: 20.2s\tremaining: 16.6s\n",
      "548:\tlearn: 0.3844020\ttotal: 20.2s\tremaining: 16.6s\n",
      "549:\tlearn: 0.3837574\ttotal: 20.2s\tremaining: 16.6s\n",
      "550:\tlearn: 0.3829720\ttotal: 20.3s\tremaining: 16.5s\n",
      "551:\tlearn: 0.3827584\ttotal: 20.3s\tremaining: 16.5s\n",
      "552:\tlearn: 0.3819742\ttotal: 20.3s\tremaining: 16.4s\n",
      "553:\tlearn: 0.3815890\ttotal: 20.4s\tremaining: 16.4s\n",
      "554:\tlearn: 0.3811366\ttotal: 20.4s\tremaining: 16.4s\n",
      "555:\tlearn: 0.3808882\ttotal: 20.5s\tremaining: 16.3s\n",
      "556:\tlearn: 0.3803341\ttotal: 20.5s\tremaining: 16.3s\n",
      "557:\tlearn: 0.3797065\ttotal: 20.5s\tremaining: 16.3s\n",
      "558:\tlearn: 0.3791706\ttotal: 20.6s\tremaining: 16.2s\n",
      "559:\tlearn: 0.3789133\ttotal: 20.6s\tremaining: 16.2s\n",
      "560:\tlearn: 0.3783454\ttotal: 20.6s\tremaining: 16.1s\n",
      "561:\tlearn: 0.3782647\ttotal: 20.7s\tremaining: 16.1s\n",
      "562:\tlearn: 0.3780689\ttotal: 20.7s\tremaining: 16.1s\n",
      "563:\tlearn: 0.3777870\ttotal: 20.8s\tremaining: 16s\n",
      "564:\tlearn: 0.3772911\ttotal: 20.8s\tremaining: 16s\n",
      "565:\tlearn: 0.3764084\ttotal: 20.9s\tremaining: 16s\n",
      "566:\tlearn: 0.3761235\ttotal: 20.9s\tremaining: 16s\n",
      "567:\tlearn: 0.3756264\ttotal: 20.9s\tremaining: 15.9s\n",
      "568:\tlearn: 0.3752330\ttotal: 21s\tremaining: 15.9s\n",
      "569:\tlearn: 0.3749613\ttotal: 21s\tremaining: 15.9s\n",
      "570:\tlearn: 0.3745711\ttotal: 21.1s\tremaining: 15.8s\n",
      "571:\tlearn: 0.3742353\ttotal: 21.1s\tremaining: 15.8s\n",
      "572:\tlearn: 0.3737439\ttotal: 21.1s\tremaining: 15.8s\n",
      "573:\tlearn: 0.3735244\ttotal: 21.2s\tremaining: 15.7s\n",
      "574:\tlearn: 0.3728680\ttotal: 21.2s\tremaining: 15.7s\n",
      "575:\tlearn: 0.3724396\ttotal: 21.3s\tremaining: 15.6s\n",
      "576:\tlearn: 0.3721638\ttotal: 21.3s\tremaining: 15.6s\n",
      "577:\tlearn: 0.3712978\ttotal: 21.3s\tremaining: 15.6s\n",
      "578:\tlearn: 0.3709174\ttotal: 21.4s\tremaining: 15.6s\n",
      "579:\tlearn: 0.3705279\ttotal: 21.4s\tremaining: 15.5s\n",
      "580:\tlearn: 0.3701956\ttotal: 21.5s\tremaining: 15.5s\n",
      "581:\tlearn: 0.3691336\ttotal: 21.5s\tremaining: 15.4s\n",
      "582:\tlearn: 0.3687109\ttotal: 21.5s\tremaining: 15.4s\n",
      "583:\tlearn: 0.3684329\ttotal: 21.6s\tremaining: 15.4s\n",
      "584:\tlearn: 0.3677893\ttotal: 21.6s\tremaining: 15.3s\n",
      "585:\tlearn: 0.3674330\ttotal: 21.6s\tremaining: 15.3s\n",
      "586:\tlearn: 0.3671380\ttotal: 21.7s\tremaining: 15.2s\n",
      "587:\tlearn: 0.3667790\ttotal: 21.7s\tremaining: 15.2s\n",
      "588:\tlearn: 0.3661437\ttotal: 21.7s\tremaining: 15.2s\n",
      "589:\tlearn: 0.3658267\ttotal: 21.8s\tremaining: 15.1s\n",
      "590:\tlearn: 0.3647801\ttotal: 21.8s\tremaining: 15.1s\n",
      "591:\tlearn: 0.3641437\ttotal: 21.9s\tremaining: 15.1s\n",
      "592:\tlearn: 0.3634745\ttotal: 21.9s\tremaining: 15s\n",
      "593:\tlearn: 0.3631290\ttotal: 21.9s\tremaining: 15s\n",
      "594:\tlearn: 0.3625016\ttotal: 22s\tremaining: 15s\n",
      "595:\tlearn: 0.3620609\ttotal: 22s\tremaining: 14.9s\n",
      "596:\tlearn: 0.3616323\ttotal: 22s\tremaining: 14.9s\n",
      "597:\tlearn: 0.3613774\ttotal: 22.1s\tremaining: 14.8s\n",
      "598:\tlearn: 0.3610431\ttotal: 22.1s\tremaining: 14.8s\n",
      "599:\tlearn: 0.3606096\ttotal: 22.2s\tremaining: 14.8s\n",
      "600:\tlearn: 0.3601813\ttotal: 22.2s\tremaining: 14.7s\n",
      "601:\tlearn: 0.3598147\ttotal: 22.2s\tremaining: 14.7s\n",
      "602:\tlearn: 0.3593332\ttotal: 22.3s\tremaining: 14.7s\n",
      "603:\tlearn: 0.3589481\ttotal: 22.3s\tremaining: 14.6s\n",
      "604:\tlearn: 0.3584067\ttotal: 22.4s\tremaining: 14.6s\n",
      "605:\tlearn: 0.3579971\ttotal: 22.4s\tremaining: 14.6s\n",
      "606:\tlearn: 0.3577598\ttotal: 22.5s\tremaining: 14.5s\n",
      "607:\tlearn: 0.3571526\ttotal: 22.5s\tremaining: 14.5s\n",
      "608:\tlearn: 0.3568224\ttotal: 22.6s\tremaining: 14.5s\n",
      "609:\tlearn: 0.3563148\ttotal: 22.6s\tremaining: 14.5s\n",
      "610:\tlearn: 0.3558648\ttotal: 22.6s\tremaining: 14.4s\n",
      "611:\tlearn: 0.3554259\ttotal: 22.7s\tremaining: 14.4s\n",
      "612:\tlearn: 0.3549100\ttotal: 22.7s\tremaining: 14.4s\n",
      "613:\tlearn: 0.3545972\ttotal: 22.8s\tremaining: 14.3s\n",
      "614:\tlearn: 0.3539432\ttotal: 22.8s\tremaining: 14.3s\n",
      "615:\tlearn: 0.3536392\ttotal: 22.9s\tremaining: 14.3s\n",
      "616:\tlearn: 0.3532884\ttotal: 23s\tremaining: 14.3s\n",
      "617:\tlearn: 0.3529624\ttotal: 23s\tremaining: 14.2s\n",
      "618:\tlearn: 0.3524045\ttotal: 23.1s\tremaining: 14.2s\n",
      "619:\tlearn: 0.3517450\ttotal: 23.1s\tremaining: 14.2s\n",
      "620:\tlearn: 0.3513088\ttotal: 23.2s\tremaining: 14.1s\n",
      "621:\tlearn: 0.3507651\ttotal: 23.2s\tremaining: 14.1s\n",
      "622:\tlearn: 0.3500398\ttotal: 23.3s\tremaining: 14.1s\n",
      "623:\tlearn: 0.3496607\ttotal: 23.3s\tremaining: 14s\n",
      "624:\tlearn: 0.3489318\ttotal: 23.4s\tremaining: 14s\n",
      "625:\tlearn: 0.3484516\ttotal: 23.4s\tremaining: 14s\n",
      "626:\tlearn: 0.3481880\ttotal: 23.5s\tremaining: 14s\n",
      "627:\tlearn: 0.3474762\ttotal: 23.5s\tremaining: 13.9s\n",
      "628:\tlearn: 0.3470646\ttotal: 23.5s\tremaining: 13.9s\n",
      "629:\tlearn: 0.3465689\ttotal: 23.6s\tremaining: 13.9s\n",
      "630:\tlearn: 0.3461382\ttotal: 23.6s\tremaining: 13.8s\n",
      "631:\tlearn: 0.3457112\ttotal: 23.7s\tremaining: 13.8s\n",
      "632:\tlearn: 0.3450755\ttotal: 23.7s\tremaining: 13.7s\n",
      "633:\tlearn: 0.3446725\ttotal: 23.7s\tremaining: 13.7s\n",
      "634:\tlearn: 0.3444875\ttotal: 23.8s\tremaining: 13.7s\n",
      "635:\tlearn: 0.3440270\ttotal: 23.8s\tremaining: 13.6s\n",
      "636:\tlearn: 0.3437367\ttotal: 23.8s\tremaining: 13.6s\n",
      "637:\tlearn: 0.3434162\ttotal: 23.9s\tremaining: 13.6s\n",
      "638:\tlearn: 0.3430581\ttotal: 23.9s\tremaining: 13.5s\n",
      "639:\tlearn: 0.3429223\ttotal: 24s\tremaining: 13.5s\n",
      "640:\tlearn: 0.3425247\ttotal: 24s\tremaining: 13.5s\n",
      "641:\tlearn: 0.3414645\ttotal: 24.1s\tremaining: 13.4s\n",
      "642:\tlearn: 0.3410771\ttotal: 24.1s\tremaining: 13.4s\n",
      "643:\tlearn: 0.3405795\ttotal: 24.1s\tremaining: 13.3s\n",
      "644:\tlearn: 0.3402854\ttotal: 24.2s\tremaining: 13.3s\n",
      "645:\tlearn: 0.3399950\ttotal: 24.2s\tremaining: 13.3s\n",
      "646:\tlearn: 0.3397120\ttotal: 24.2s\tremaining: 13.2s\n",
      "647:\tlearn: 0.3391824\ttotal: 24.3s\tremaining: 13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648:\tlearn: 0.3389095\ttotal: 24.3s\tremaining: 13.1s\n",
      "649:\tlearn: 0.3384103\ttotal: 24.3s\tremaining: 13.1s\n",
      "650:\tlearn: 0.3380769\ttotal: 24.4s\tremaining: 13.1s\n",
      "651:\tlearn: 0.3379897\ttotal: 24.4s\tremaining: 13s\n",
      "652:\tlearn: 0.3377802\ttotal: 24.5s\tremaining: 13s\n",
      "653:\tlearn: 0.3371769\ttotal: 24.5s\tremaining: 13s\n",
      "654:\tlearn: 0.3368958\ttotal: 24.5s\tremaining: 12.9s\n",
      "655:\tlearn: 0.3364468\ttotal: 24.6s\tremaining: 12.9s\n",
      "656:\tlearn: 0.3362238\ttotal: 24.6s\tremaining: 12.9s\n",
      "657:\tlearn: 0.3361471\ttotal: 24.7s\tremaining: 12.8s\n",
      "658:\tlearn: 0.3357532\ttotal: 24.7s\tremaining: 12.8s\n",
      "659:\tlearn: 0.3352620\ttotal: 24.7s\tremaining: 12.7s\n",
      "660:\tlearn: 0.3348582\ttotal: 24.8s\tremaining: 12.7s\n",
      "661:\tlearn: 0.3345724\ttotal: 24.8s\tremaining: 12.7s\n",
      "662:\tlearn: 0.3341576\ttotal: 24.9s\tremaining: 12.6s\n",
      "663:\tlearn: 0.3340580\ttotal: 24.9s\tremaining: 12.6s\n",
      "664:\tlearn: 0.3334460\ttotal: 24.9s\tremaining: 12.6s\n",
      "665:\tlearn: 0.3330144\ttotal: 25s\tremaining: 12.5s\n",
      "666:\tlearn: 0.3326675\ttotal: 25s\tremaining: 12.5s\n",
      "667:\tlearn: 0.3325699\ttotal: 25s\tremaining: 12.4s\n",
      "668:\tlearn: 0.3322855\ttotal: 25.1s\tremaining: 12.4s\n",
      "669:\tlearn: 0.3320936\ttotal: 25.1s\tremaining: 12.4s\n",
      "670:\tlearn: 0.3316373\ttotal: 25.1s\tremaining: 12.3s\n",
      "671:\tlearn: 0.3309644\ttotal: 25.2s\tremaining: 12.3s\n",
      "672:\tlearn: 0.3306357\ttotal: 25.2s\tremaining: 12.2s\n",
      "673:\tlearn: 0.3302933\ttotal: 25.2s\tremaining: 12.2s\n",
      "674:\tlearn: 0.3299840\ttotal: 25.3s\tremaining: 12.2s\n",
      "675:\tlearn: 0.3295110\ttotal: 25.3s\tremaining: 12.1s\n",
      "676:\tlearn: 0.3294371\ttotal: 25.4s\tremaining: 12.1s\n",
      "677:\tlearn: 0.3292634\ttotal: 25.4s\tremaining: 12.1s\n",
      "678:\tlearn: 0.3288343\ttotal: 25.4s\tremaining: 12s\n",
      "679:\tlearn: 0.3285204\ttotal: 25.5s\tremaining: 12s\n",
      "680:\tlearn: 0.3281866\ttotal: 25.5s\tremaining: 11.9s\n",
      "681:\tlearn: 0.3279336\ttotal: 25.5s\tremaining: 11.9s\n",
      "682:\tlearn: 0.3274446\ttotal: 25.6s\tremaining: 11.9s\n",
      "683:\tlearn: 0.3268589\ttotal: 25.6s\tremaining: 11.8s\n",
      "684:\tlearn: 0.3264427\ttotal: 25.6s\tremaining: 11.8s\n",
      "685:\tlearn: 0.3263583\ttotal: 25.7s\tremaining: 11.8s\n",
      "686:\tlearn: 0.3259590\ttotal: 25.7s\tremaining: 11.7s\n",
      "687:\tlearn: 0.3256080\ttotal: 25.8s\tremaining: 11.7s\n",
      "688:\tlearn: 0.3252585\ttotal: 25.8s\tremaining: 11.6s\n",
      "689:\tlearn: 0.3248080\ttotal: 25.8s\tremaining: 11.6s\n",
      "690:\tlearn: 0.3245864\ttotal: 25.9s\tremaining: 11.6s\n",
      "691:\tlearn: 0.3241970\ttotal: 25.9s\tremaining: 11.5s\n",
      "692:\tlearn: 0.3238956\ttotal: 25.9s\tremaining: 11.5s\n",
      "693:\tlearn: 0.3234254\ttotal: 26s\tremaining: 11.4s\n",
      "694:\tlearn: 0.3229516\ttotal: 26s\tremaining: 11.4s\n",
      "695:\tlearn: 0.3225370\ttotal: 26s\tremaining: 11.4s\n",
      "696:\tlearn: 0.3222811\ttotal: 26.1s\tremaining: 11.3s\n",
      "697:\tlearn: 0.3218225\ttotal: 26.1s\tremaining: 11.3s\n",
      "698:\tlearn: 0.3212330\ttotal: 26.1s\tremaining: 11.3s\n",
      "699:\tlearn: 0.3210428\ttotal: 26.2s\tremaining: 11.2s\n",
      "700:\tlearn: 0.3207775\ttotal: 26.2s\tremaining: 11.2s\n",
      "701:\tlearn: 0.3203577\ttotal: 26.3s\tremaining: 11.1s\n",
      "702:\tlearn: 0.3199713\ttotal: 26.3s\tremaining: 11.1s\n",
      "703:\tlearn: 0.3196242\ttotal: 26.3s\tremaining: 11.1s\n",
      "704:\tlearn: 0.3191720\ttotal: 26.4s\tremaining: 11s\n",
      "705:\tlearn: 0.3188827\ttotal: 26.4s\tremaining: 11s\n",
      "706:\tlearn: 0.3185267\ttotal: 26.4s\tremaining: 11s\n",
      "707:\tlearn: 0.3182476\ttotal: 26.5s\tremaining: 10.9s\n",
      "708:\tlearn: 0.3180419\ttotal: 26.5s\tremaining: 10.9s\n",
      "709:\tlearn: 0.3176022\ttotal: 26.5s\tremaining: 10.8s\n",
      "710:\tlearn: 0.3172176\ttotal: 26.6s\tremaining: 10.8s\n",
      "711:\tlearn: 0.3169841\ttotal: 26.6s\tremaining: 10.8s\n",
      "712:\tlearn: 0.3164787\ttotal: 26.7s\tremaining: 10.7s\n",
      "713:\tlearn: 0.3162242\ttotal: 26.7s\tremaining: 10.7s\n",
      "714:\tlearn: 0.3158285\ttotal: 26.7s\tremaining: 10.7s\n",
      "715:\tlearn: 0.3154584\ttotal: 26.8s\tremaining: 10.6s\n",
      "716:\tlearn: 0.3146913\ttotal: 26.8s\tremaining: 10.6s\n",
      "717:\tlearn: 0.3145211\ttotal: 26.8s\tremaining: 10.5s\n",
      "718:\tlearn: 0.3139863\ttotal: 26.9s\tremaining: 10.5s\n",
      "719:\tlearn: 0.3137900\ttotal: 26.9s\tremaining: 10.5s\n",
      "720:\tlearn: 0.3134143\ttotal: 26.9s\tremaining: 10.4s\n",
      "721:\tlearn: 0.3131757\ttotal: 27s\tremaining: 10.4s\n",
      "722:\tlearn: 0.3127736\ttotal: 27s\tremaining: 10.3s\n",
      "723:\tlearn: 0.3123151\ttotal: 27.1s\tremaining: 10.3s\n",
      "724:\tlearn: 0.3120507\ttotal: 27.1s\tremaining: 10.3s\n",
      "725:\tlearn: 0.3116155\ttotal: 27.1s\tremaining: 10.2s\n",
      "726:\tlearn: 0.3112454\ttotal: 27.2s\tremaining: 10.2s\n",
      "727:\tlearn: 0.3110502\ttotal: 27.2s\tremaining: 10.2s\n",
      "728:\tlearn: 0.3109316\ttotal: 27.2s\tremaining: 10.1s\n",
      "729:\tlearn: 0.3105065\ttotal: 27.3s\tremaining: 10.1s\n",
      "730:\tlearn: 0.3099544\ttotal: 27.3s\tremaining: 10s\n",
      "731:\tlearn: 0.3095651\ttotal: 27.3s\tremaining: 10s\n",
      "732:\tlearn: 0.3093631\ttotal: 27.4s\tremaining: 9.97s\n",
      "733:\tlearn: 0.3089984\ttotal: 27.4s\tremaining: 9.93s\n",
      "734:\tlearn: 0.3087951\ttotal: 27.4s\tremaining: 9.89s\n",
      "735:\tlearn: 0.3085407\ttotal: 27.5s\tremaining: 9.86s\n",
      "736:\tlearn: 0.3080704\ttotal: 27.5s\tremaining: 9.82s\n",
      "737:\tlearn: 0.3078676\ttotal: 27.6s\tremaining: 9.78s\n",
      "738:\tlearn: 0.3073907\ttotal: 27.6s\tremaining: 9.74s\n",
      "739:\tlearn: 0.3067072\ttotal: 27.6s\tremaining: 9.71s\n",
      "740:\tlearn: 0.3064560\ttotal: 27.7s\tremaining: 9.67s\n",
      "741:\tlearn: 0.3061929\ttotal: 27.7s\tremaining: 9.63s\n",
      "742:\tlearn: 0.3060452\ttotal: 27.7s\tremaining: 9.59s\n",
      "743:\tlearn: 0.3055729\ttotal: 27.8s\tremaining: 9.56s\n",
      "744:\tlearn: 0.3054893\ttotal: 27.8s\tremaining: 9.52s\n",
      "745:\tlearn: 0.3051875\ttotal: 27.8s\tremaining: 9.48s\n",
      "746:\tlearn: 0.3047370\ttotal: 27.9s\tremaining: 9.44s\n",
      "747:\tlearn: 0.3045022\ttotal: 27.9s\tremaining: 9.4s\n",
      "748:\tlearn: 0.3041702\ttotal: 27.9s\tremaining: 9.37s\n",
      "749:\tlearn: 0.3037409\ttotal: 28s\tremaining: 9.33s\n",
      "750:\tlearn: 0.3034356\ttotal: 28s\tremaining: 9.29s\n",
      "751:\tlearn: 0.3030403\ttotal: 28.1s\tremaining: 9.25s\n",
      "752:\tlearn: 0.3027835\ttotal: 28.1s\tremaining: 9.21s\n",
      "753:\tlearn: 0.3024753\ttotal: 28.1s\tremaining: 9.18s\n",
      "754:\tlearn: 0.3022873\ttotal: 28.2s\tremaining: 9.14s\n",
      "755:\tlearn: 0.3018395\ttotal: 28.2s\tremaining: 9.1s\n",
      "756:\tlearn: 0.3015468\ttotal: 28.2s\tremaining: 9.06s\n",
      "757:\tlearn: 0.3011426\ttotal: 28.3s\tremaining: 9.03s\n",
      "758:\tlearn: 0.3006509\ttotal: 28.3s\tremaining: 8.99s\n",
      "759:\tlearn: 0.3001415\ttotal: 28.3s\tremaining: 8.95s\n",
      "760:\tlearn: 0.3000536\ttotal: 28.4s\tremaining: 8.91s\n",
      "761:\tlearn: 0.2997120\ttotal: 28.4s\tremaining: 8.88s\n",
      "762:\tlearn: 0.2992433\ttotal: 28.5s\tremaining: 8.84s\n",
      "763:\tlearn: 0.2990083\ttotal: 28.5s\tremaining: 8.8s\n",
      "764:\tlearn: 0.2987573\ttotal: 28.5s\tremaining: 8.76s\n",
      "765:\tlearn: 0.2985534\ttotal: 28.6s\tremaining: 8.72s\n",
      "766:\tlearn: 0.2982505\ttotal: 28.6s\tremaining: 8.69s\n",
      "767:\tlearn: 0.2981860\ttotal: 28.6s\tremaining: 8.65s\n",
      "768:\tlearn: 0.2980945\ttotal: 28.7s\tremaining: 8.61s\n",
      "769:\tlearn: 0.2978365\ttotal: 28.7s\tremaining: 8.57s\n",
      "770:\tlearn: 0.2973996\ttotal: 28.7s\tremaining: 8.54s\n",
      "771:\tlearn: 0.2969684\ttotal: 28.8s\tremaining: 8.5s\n",
      "772:\tlearn: 0.2965417\ttotal: 28.8s\tremaining: 8.47s\n",
      "773:\tlearn: 0.2962054\ttotal: 28.9s\tremaining: 8.43s\n",
      "774:\tlearn: 0.2958530\ttotal: 28.9s\tremaining: 8.39s\n",
      "775:\tlearn: 0.2956627\ttotal: 29s\tremaining: 8.36s\n",
      "776:\tlearn: 0.2955718\ttotal: 29s\tremaining: 8.32s\n",
      "777:\tlearn: 0.2952645\ttotal: 29s\tremaining: 8.28s\n",
      "778:\tlearn: 0.2948767\ttotal: 29.1s\tremaining: 8.25s\n",
      "779:\tlearn: 0.2945593\ttotal: 29.1s\tremaining: 8.21s\n",
      "780:\tlearn: 0.2942033\ttotal: 29.2s\tremaining: 8.18s\n",
      "781:\tlearn: 0.2938323\ttotal: 29.2s\tremaining: 8.14s\n",
      "782:\tlearn: 0.2933962\ttotal: 29.2s\tremaining: 8.1s\n",
      "783:\tlearn: 0.2932833\ttotal: 29.3s\tremaining: 8.07s\n",
      "784:\tlearn: 0.2931158\ttotal: 29.3s\tremaining: 8.03s\n",
      "785:\tlearn: 0.2926508\ttotal: 29.4s\tremaining: 8s\n",
      "786:\tlearn: 0.2923220\ttotal: 29.4s\tremaining: 7.96s\n",
      "787:\tlearn: 0.2919368\ttotal: 29.4s\tremaining: 7.92s\n",
      "788:\tlearn: 0.2916478\ttotal: 29.5s\tremaining: 7.88s\n",
      "789:\tlearn: 0.2912119\ttotal: 29.5s\tremaining: 7.85s\n",
      "790:\tlearn: 0.2909639\ttotal: 29.6s\tremaining: 7.81s\n",
      "791:\tlearn: 0.2907339\ttotal: 29.6s\tremaining: 7.77s\n",
      "792:\tlearn: 0.2905303\ttotal: 29.6s\tremaining: 7.74s\n",
      "793:\tlearn: 0.2902787\ttotal: 29.7s\tremaining: 7.7s\n",
      "794:\tlearn: 0.2899872\ttotal: 29.7s\tremaining: 7.66s\n",
      "795:\tlearn: 0.2895988\ttotal: 29.8s\tremaining: 7.63s\n",
      "796:\tlearn: 0.2894903\ttotal: 29.8s\tremaining: 7.59s\n",
      "797:\tlearn: 0.2891046\ttotal: 29.8s\tremaining: 7.55s\n",
      "798:\tlearn: 0.2888807\ttotal: 29.9s\tremaining: 7.52s\n",
      "799:\tlearn: 0.2884052\ttotal: 29.9s\tremaining: 7.48s\n",
      "800:\tlearn: 0.2883358\ttotal: 30s\tremaining: 7.44s\n",
      "801:\tlearn: 0.2879253\ttotal: 30s\tremaining: 7.41s\n",
      "802:\tlearn: 0.2875619\ttotal: 30s\tremaining: 7.37s\n",
      "803:\tlearn: 0.2872264\ttotal: 30.1s\tremaining: 7.33s\n",
      "804:\tlearn: 0.2868215\ttotal: 30.1s\tremaining: 7.3s\n",
      "805:\tlearn: 0.2864987\ttotal: 30.2s\tremaining: 7.26s\n",
      "806:\tlearn: 0.2863254\ttotal: 30.2s\tremaining: 7.22s\n",
      "807:\tlearn: 0.2862162\ttotal: 30.2s\tremaining: 7.19s\n",
      "808:\tlearn: 0.2857490\ttotal: 30.3s\tremaining: 7.15s\n",
      "809:\tlearn: 0.2853242\ttotal: 30.3s\tremaining: 7.11s\n",
      "810:\tlearn: 0.2850691\ttotal: 30.4s\tremaining: 7.08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811:\tlearn: 0.2849202\ttotal: 30.4s\tremaining: 7.04s\n",
      "812:\tlearn: 0.2845629\ttotal: 30.5s\tremaining: 7s\n",
      "813:\tlearn: 0.2844164\ttotal: 30.5s\tremaining: 6.97s\n",
      "814:\tlearn: 0.2840921\ttotal: 30.5s\tremaining: 6.93s\n",
      "815:\tlearn: 0.2837122\ttotal: 30.6s\tremaining: 6.9s\n",
      "816:\tlearn: 0.2833338\ttotal: 30.6s\tremaining: 6.86s\n",
      "817:\tlearn: 0.2831194\ttotal: 30.7s\tremaining: 6.83s\n",
      "818:\tlearn: 0.2827167\ttotal: 30.7s\tremaining: 6.79s\n",
      "819:\tlearn: 0.2823571\ttotal: 30.8s\tremaining: 6.75s\n",
      "820:\tlearn: 0.2821000\ttotal: 30.8s\tremaining: 6.72s\n",
      "821:\tlearn: 0.2816595\ttotal: 30.9s\tremaining: 6.68s\n",
      "822:\tlearn: 0.2814081\ttotal: 30.9s\tremaining: 6.64s\n",
      "823:\tlearn: 0.2808027\ttotal: 30.9s\tremaining: 6.61s\n",
      "824:\tlearn: 0.2804732\ttotal: 31s\tremaining: 6.57s\n",
      "825:\tlearn: 0.2800281\ttotal: 31s\tremaining: 6.53s\n",
      "826:\tlearn: 0.2796664\ttotal: 31.1s\tremaining: 6.5s\n",
      "827:\tlearn: 0.2792931\ttotal: 31.1s\tremaining: 6.46s\n",
      "828:\tlearn: 0.2789629\ttotal: 31.1s\tremaining: 6.42s\n",
      "829:\tlearn: 0.2788743\ttotal: 31.2s\tremaining: 6.39s\n",
      "830:\tlearn: 0.2785204\ttotal: 31.2s\tremaining: 6.35s\n",
      "831:\tlearn: 0.2782289\ttotal: 31.3s\tremaining: 6.31s\n",
      "832:\tlearn: 0.2777280\ttotal: 31.3s\tremaining: 6.28s\n",
      "833:\tlearn: 0.2773307\ttotal: 31.4s\tremaining: 6.24s\n",
      "834:\tlearn: 0.2769344\ttotal: 31.4s\tremaining: 6.2s\n",
      "835:\tlearn: 0.2767454\ttotal: 31.4s\tremaining: 6.17s\n",
      "836:\tlearn: 0.2764328\ttotal: 31.5s\tremaining: 6.13s\n",
      "837:\tlearn: 0.2761041\ttotal: 31.5s\tremaining: 6.09s\n",
      "838:\tlearn: 0.2757429\ttotal: 31.6s\tremaining: 6.06s\n",
      "839:\tlearn: 0.2754072\ttotal: 31.6s\tremaining: 6.02s\n",
      "840:\tlearn: 0.2752854\ttotal: 31.6s\tremaining: 5.98s\n",
      "841:\tlearn: 0.2749790\ttotal: 31.7s\tremaining: 5.95s\n",
      "842:\tlearn: 0.2747124\ttotal: 31.7s\tremaining: 5.91s\n",
      "843:\tlearn: 0.2743283\ttotal: 31.8s\tremaining: 5.87s\n",
      "844:\tlearn: 0.2740002\ttotal: 31.8s\tremaining: 5.83s\n",
      "845:\tlearn: 0.2737201\ttotal: 31.8s\tremaining: 5.8s\n",
      "846:\tlearn: 0.2735754\ttotal: 31.9s\tremaining: 5.76s\n",
      "847:\tlearn: 0.2734096\ttotal: 31.9s\tremaining: 5.72s\n",
      "848:\tlearn: 0.2730171\ttotal: 32s\tremaining: 5.68s\n",
      "849:\tlearn: 0.2727627\ttotal: 32s\tremaining: 5.65s\n",
      "850:\tlearn: 0.2724068\ttotal: 32s\tremaining: 5.61s\n",
      "851:\tlearn: 0.2721461\ttotal: 32.1s\tremaining: 5.57s\n",
      "852:\tlearn: 0.2718774\ttotal: 32.1s\tremaining: 5.54s\n",
      "853:\tlearn: 0.2714391\ttotal: 32.2s\tremaining: 5.5s\n",
      "854:\tlearn: 0.2711378\ttotal: 32.2s\tremaining: 5.46s\n",
      "855:\tlearn: 0.2708856\ttotal: 32.2s\tremaining: 5.42s\n",
      "856:\tlearn: 0.2704865\ttotal: 32.3s\tremaining: 5.39s\n",
      "857:\tlearn: 0.2701142\ttotal: 32.3s\tremaining: 5.35s\n",
      "858:\tlearn: 0.2699540\ttotal: 32.4s\tremaining: 5.31s\n",
      "859:\tlearn: 0.2697089\ttotal: 32.4s\tremaining: 5.28s\n",
      "860:\tlearn: 0.2693751\ttotal: 32.5s\tremaining: 5.24s\n",
      "861:\tlearn: 0.2691643\ttotal: 32.5s\tremaining: 5.2s\n",
      "862:\tlearn: 0.2687758\ttotal: 32.5s\tremaining: 5.16s\n",
      "863:\tlearn: 0.2685155\ttotal: 32.6s\tremaining: 5.13s\n",
      "864:\tlearn: 0.2679460\ttotal: 32.6s\tremaining: 5.09s\n",
      "865:\tlearn: 0.2676931\ttotal: 32.7s\tremaining: 5.05s\n",
      "866:\tlearn: 0.2674349\ttotal: 32.7s\tremaining: 5.01s\n",
      "867:\tlearn: 0.2672474\ttotal: 32.7s\tremaining: 4.98s\n",
      "868:\tlearn: 0.2670324\ttotal: 32.8s\tremaining: 4.94s\n",
      "869:\tlearn: 0.2667533\ttotal: 32.8s\tremaining: 4.9s\n",
      "870:\tlearn: 0.2665191\ttotal: 32.9s\tremaining: 4.87s\n",
      "871:\tlearn: 0.2660303\ttotal: 32.9s\tremaining: 4.83s\n",
      "872:\tlearn: 0.2656064\ttotal: 32.9s\tremaining: 4.79s\n",
      "873:\tlearn: 0.2653910\ttotal: 33s\tremaining: 4.75s\n",
      "874:\tlearn: 0.2649963\ttotal: 33s\tremaining: 4.72s\n",
      "875:\tlearn: 0.2648085\ttotal: 33.1s\tremaining: 4.68s\n",
      "876:\tlearn: 0.2646014\ttotal: 33.1s\tremaining: 4.64s\n",
      "877:\tlearn: 0.2644014\ttotal: 33.2s\tremaining: 4.61s\n",
      "878:\tlearn: 0.2641883\ttotal: 33.2s\tremaining: 4.57s\n",
      "879:\tlearn: 0.2639049\ttotal: 33.2s\tremaining: 4.53s\n",
      "880:\tlearn: 0.2637040\ttotal: 33.3s\tremaining: 4.5s\n",
      "881:\tlearn: 0.2634038\ttotal: 33.3s\tremaining: 4.46s\n",
      "882:\tlearn: 0.2629278\ttotal: 33.4s\tremaining: 4.42s\n",
      "883:\tlearn: 0.2627045\ttotal: 33.4s\tremaining: 4.38s\n",
      "884:\tlearn: 0.2624976\ttotal: 33.4s\tremaining: 4.34s\n",
      "885:\tlearn: 0.2623867\ttotal: 33.5s\tremaining: 4.31s\n",
      "886:\tlearn: 0.2620885\ttotal: 33.5s\tremaining: 4.27s\n",
      "887:\tlearn: 0.2619095\ttotal: 33.6s\tremaining: 4.23s\n",
      "888:\tlearn: 0.2616878\ttotal: 33.6s\tremaining: 4.2s\n",
      "889:\tlearn: 0.2615960\ttotal: 33.6s\tremaining: 4.16s\n",
      "890:\tlearn: 0.2611545\ttotal: 33.7s\tremaining: 4.12s\n",
      "891:\tlearn: 0.2610430\ttotal: 33.7s\tremaining: 4.08s\n",
      "892:\tlearn: 0.2608884\ttotal: 33.8s\tremaining: 4.04s\n",
      "893:\tlearn: 0.2606406\ttotal: 33.8s\tremaining: 4.01s\n",
      "894:\tlearn: 0.2602203\ttotal: 33.8s\tremaining: 3.97s\n",
      "895:\tlearn: 0.2597905\ttotal: 33.9s\tremaining: 3.93s\n",
      "896:\tlearn: 0.2594299\ttotal: 33.9s\tremaining: 3.89s\n",
      "897:\tlearn: 0.2591966\ttotal: 33.9s\tremaining: 3.85s\n",
      "898:\tlearn: 0.2588116\ttotal: 34s\tremaining: 3.82s\n",
      "899:\tlearn: 0.2584934\ttotal: 34s\tremaining: 3.78s\n",
      "900:\tlearn: 0.2581790\ttotal: 34s\tremaining: 3.74s\n",
      "901:\tlearn: 0.2578583\ttotal: 34.1s\tremaining: 3.7s\n",
      "902:\tlearn: 0.2577201\ttotal: 34.1s\tremaining: 3.66s\n",
      "903:\tlearn: 0.2575545\ttotal: 34.2s\tremaining: 3.63s\n",
      "904:\tlearn: 0.2573582\ttotal: 34.2s\tremaining: 3.59s\n",
      "905:\tlearn: 0.2572820\ttotal: 34.2s\tremaining: 3.55s\n",
      "906:\tlearn: 0.2569909\ttotal: 34.3s\tremaining: 3.51s\n",
      "907:\tlearn: 0.2566260\ttotal: 34.3s\tremaining: 3.48s\n",
      "908:\tlearn: 0.2561224\ttotal: 34.3s\tremaining: 3.44s\n",
      "909:\tlearn: 0.2557409\ttotal: 34.4s\tremaining: 3.4s\n",
      "910:\tlearn: 0.2554661\ttotal: 34.4s\tremaining: 3.36s\n",
      "911:\tlearn: 0.2552229\ttotal: 34.5s\tremaining: 3.32s\n",
      "912:\tlearn: 0.2549926\ttotal: 34.5s\tremaining: 3.29s\n",
      "913:\tlearn: 0.2548909\ttotal: 34.5s\tremaining: 3.25s\n",
      "914:\tlearn: 0.2547255\ttotal: 34.6s\tremaining: 3.21s\n",
      "915:\tlearn: 0.2544963\ttotal: 34.6s\tremaining: 3.17s\n",
      "916:\tlearn: 0.2543371\ttotal: 34.6s\tremaining: 3.13s\n",
      "917:\tlearn: 0.2540098\ttotal: 34.7s\tremaining: 3.1s\n",
      "918:\tlearn: 0.2538105\ttotal: 34.7s\tremaining: 3.06s\n",
      "919:\tlearn: 0.2536883\ttotal: 34.7s\tremaining: 3.02s\n",
      "920:\tlearn: 0.2533510\ttotal: 34.8s\tremaining: 2.98s\n",
      "921:\tlearn: 0.2531788\ttotal: 34.8s\tremaining: 2.94s\n",
      "922:\tlearn: 0.2525794\ttotal: 34.9s\tremaining: 2.91s\n",
      "923:\tlearn: 0.2524717\ttotal: 34.9s\tremaining: 2.87s\n",
      "924:\tlearn: 0.2521784\ttotal: 34.9s\tremaining: 2.83s\n",
      "925:\tlearn: 0.2520148\ttotal: 35s\tremaining: 2.79s\n",
      "926:\tlearn: 0.2515258\ttotal: 35s\tremaining: 2.76s\n",
      "927:\tlearn: 0.2512311\ttotal: 35s\tremaining: 2.72s\n",
      "928:\tlearn: 0.2509558\ttotal: 35.1s\tremaining: 2.68s\n",
      "929:\tlearn: 0.2508451\ttotal: 35.1s\tremaining: 2.64s\n",
      "930:\tlearn: 0.2507245\ttotal: 35.1s\tremaining: 2.6s\n",
      "931:\tlearn: 0.2504631\ttotal: 35.2s\tremaining: 2.57s\n",
      "932:\tlearn: 0.2501249\ttotal: 35.2s\tremaining: 2.53s\n",
      "933:\tlearn: 0.2498071\ttotal: 35.3s\tremaining: 2.49s\n",
      "934:\tlearn: 0.2496688\ttotal: 35.3s\tremaining: 2.45s\n",
      "935:\tlearn: 0.2494725\ttotal: 35.3s\tremaining: 2.42s\n",
      "936:\tlearn: 0.2492726\ttotal: 35.4s\tremaining: 2.38s\n",
      "937:\tlearn: 0.2487895\ttotal: 35.4s\tremaining: 2.34s\n",
      "938:\tlearn: 0.2485971\ttotal: 35.4s\tremaining: 2.3s\n",
      "939:\tlearn: 0.2485135\ttotal: 35.5s\tremaining: 2.26s\n",
      "940:\tlearn: 0.2482833\ttotal: 35.5s\tremaining: 2.23s\n",
      "941:\tlearn: 0.2481703\ttotal: 35.5s\tremaining: 2.19s\n",
      "942:\tlearn: 0.2479673\ttotal: 35.6s\tremaining: 2.15s\n",
      "943:\tlearn: 0.2479320\ttotal: 35.6s\tremaining: 2.11s\n",
      "944:\tlearn: 0.2477974\ttotal: 35.7s\tremaining: 2.08s\n",
      "945:\tlearn: 0.2475628\ttotal: 35.7s\tremaining: 2.04s\n",
      "946:\tlearn: 0.2473283\ttotal: 35.7s\tremaining: 2s\n",
      "947:\tlearn: 0.2470838\ttotal: 35.8s\tremaining: 1.96s\n",
      "948:\tlearn: 0.2469860\ttotal: 35.8s\tremaining: 1.92s\n",
      "949:\tlearn: 0.2468032\ttotal: 35.8s\tremaining: 1.89s\n",
      "950:\tlearn: 0.2466087\ttotal: 35.9s\tremaining: 1.85s\n",
      "951:\tlearn: 0.2465611\ttotal: 35.9s\tremaining: 1.81s\n",
      "952:\tlearn: 0.2463006\ttotal: 35.9s\tremaining: 1.77s\n",
      "953:\tlearn: 0.2460446\ttotal: 36s\tremaining: 1.74s\n",
      "954:\tlearn: 0.2459241\ttotal: 36s\tremaining: 1.7s\n",
      "955:\tlearn: 0.2457860\ttotal: 36.1s\tremaining: 1.66s\n",
      "956:\tlearn: 0.2455071\ttotal: 36.1s\tremaining: 1.62s\n",
      "957:\tlearn: 0.2454337\ttotal: 36.1s\tremaining: 1.58s\n",
      "958:\tlearn: 0.2453303\ttotal: 36.2s\tremaining: 1.55s\n",
      "959:\tlearn: 0.2450799\ttotal: 36.2s\tremaining: 1.51s\n",
      "960:\tlearn: 0.2448727\ttotal: 36.2s\tremaining: 1.47s\n",
      "961:\tlearn: 0.2447280\ttotal: 36.3s\tremaining: 1.43s\n",
      "962:\tlearn: 0.2444283\ttotal: 36.3s\tremaining: 1.39s\n",
      "963:\tlearn: 0.2443341\ttotal: 36.3s\tremaining: 1.36s\n",
      "964:\tlearn: 0.2440922\ttotal: 36.4s\tremaining: 1.32s\n",
      "965:\tlearn: 0.2436220\ttotal: 36.4s\tremaining: 1.28s\n",
      "966:\tlearn: 0.2434378\ttotal: 36.5s\tremaining: 1.24s\n",
      "967:\tlearn: 0.2433599\ttotal: 36.5s\tremaining: 1.21s\n",
      "968:\tlearn: 0.2429558\ttotal: 36.5s\tremaining: 1.17s\n",
      "969:\tlearn: 0.2428725\ttotal: 36.6s\tremaining: 1.13s\n",
      "970:\tlearn: 0.2426348\ttotal: 36.6s\tremaining: 1.09s\n",
      "971:\tlearn: 0.2425204\ttotal: 36.6s\tremaining: 1.05s\n",
      "972:\tlearn: 0.2423738\ttotal: 36.7s\tremaining: 1.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973:\tlearn: 0.2423018\ttotal: 36.7s\tremaining: 980ms\n",
      "974:\tlearn: 0.2419566\ttotal: 36.7s\tremaining: 942ms\n",
      "975:\tlearn: 0.2416649\ttotal: 36.8s\tremaining: 904ms\n",
      "976:\tlearn: 0.2415249\ttotal: 36.8s\tremaining: 867ms\n",
      "977:\tlearn: 0.2413910\ttotal: 36.9s\tremaining: 829ms\n",
      "978:\tlearn: 0.2413000\ttotal: 36.9s\tremaining: 791ms\n",
      "979:\tlearn: 0.2411307\ttotal: 36.9s\tremaining: 754ms\n",
      "980:\tlearn: 0.2408575\ttotal: 37s\tremaining: 716ms\n",
      "981:\tlearn: 0.2404971\ttotal: 37s\tremaining: 678ms\n",
      "982:\tlearn: 0.2402055\ttotal: 37s\tremaining: 640ms\n",
      "983:\tlearn: 0.2400881\ttotal: 37.1s\tremaining: 603ms\n",
      "984:\tlearn: 0.2399393\ttotal: 37.1s\tremaining: 565ms\n",
      "985:\tlearn: 0.2396758\ttotal: 37.1s\tremaining: 527ms\n",
      "986:\tlearn: 0.2391147\ttotal: 37.2s\tremaining: 490ms\n",
      "987:\tlearn: 0.2388548\ttotal: 37.2s\tremaining: 452ms\n",
      "988:\tlearn: 0.2384871\ttotal: 37.3s\tremaining: 414ms\n",
      "989:\tlearn: 0.2382728\ttotal: 37.3s\tremaining: 377ms\n",
      "990:\tlearn: 0.2379143\ttotal: 37.3s\tremaining: 339ms\n",
      "991:\tlearn: 0.2376144\ttotal: 37.4s\tremaining: 301ms\n",
      "992:\tlearn: 0.2371983\ttotal: 37.4s\tremaining: 264ms\n",
      "993:\tlearn: 0.2370148\ttotal: 37.4s\tremaining: 226ms\n",
      "994:\tlearn: 0.2366632\ttotal: 37.5s\tremaining: 188ms\n",
      "995:\tlearn: 0.2363205\ttotal: 37.5s\tremaining: 151ms\n",
      "996:\tlearn: 0.2358736\ttotal: 37.5s\tremaining: 113ms\n",
      "997:\tlearn: 0.2357691\ttotal: 37.6s\tremaining: 75.3ms\n",
      "998:\tlearn: 0.2355806\ttotal: 37.6s\tremaining: 37.7ms\n",
      "999:\tlearn: 0.2352914\ttotal: 37.7s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.40      0.42        83\n",
      "           1       0.48      0.44      0.46       143\n",
      "           2       0.61      0.69      0.65       170\n",
      "\n",
      "    accuracy                           0.54       396\n",
      "   macro avg       0.51      0.51      0.51       396\n",
      "weighted avg       0.53      0.54      0.53       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 33  26  24]\n",
      " [ 30  63  50]\n",
      " [ 11  42 117]]\n"
     ]
    }
   ],
   "source": [
    "#!pip install catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_CatBoostClassifier = CatBoostClassifier(random_state=42)\n",
    "model_CatBoostClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_CatBoostClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f5163",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6512efaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15         7\n",
      "           1       0.41      0.47      0.44        15\n",
      "           2       0.67      0.64      0.65        28\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.42      0.42      0.42        50\n",
      "weighted avg       0.52      0.52      0.52        50\n",
      "\n",
      "    y_val  y_val_pred\n",
      "0       0           1\n",
      "1       0           1\n",
      "2       0           1\n",
      "3       0           2\n",
      "4       0           0\n",
      "5       0           2\n",
      "6       0           2\n",
      "7       1           2\n",
      "8       1           2\n",
      "9       1           2\n",
      "10      1           1\n",
      "11      1           1\n",
      "12      1           0\n",
      "13      1           2\n",
      "14      1           2\n",
      "15      1           1\n",
      "16      1           0\n",
      "17      1           1\n",
      "18      1           1\n",
      "19      1           1\n",
      "20      1           2\n",
      "21      1           1\n",
      "22      2           0\n",
      "23      2           1\n",
      "24      2           2\n",
      "25      2           2\n",
      "26      2           2\n",
      "27      2           2\n",
      "28      2           2\n",
      "29      2           1\n",
      "30      2           1\n",
      "31      2           2\n",
      "32      2           2\n",
      "33      2           0\n",
      "34      2           0\n",
      "35      2           2\n",
      "36      2           1\n",
      "37      2           2\n",
      "38      2           2\n",
      "39      2           2\n",
      "40      2           1\n",
      "41      2           1\n",
      "42      2           2\n",
      "43      2           2\n",
      "44      2           1\n",
      "45      2           2\n",
      "46      2           2\n",
      "47      2           2\n",
      "48      2           2\n",
      "49      2           2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15         7\n",
      "           1       0.41      0.47      0.44        15\n",
      "           2       0.67      0.64      0.65        28\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.42      0.42      0.42        50\n",
      "weighted avg       0.52      0.52      0.52        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_CatBoostClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "#results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "results_df = pd.DataFrame({'y_val': y_val.values.ravel(), 'y_val_pred': y_val_pred.ravel()})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "# Assess the performance of the model using classification report\n",
    "print(classification_report(y_val.values.ravel(), y_val_pred.ravel()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfdd6ab",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Model-13 : LGBMClassifier </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95423eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.37      0.38        83\n",
      "           1       0.44      0.41      0.42       143\n",
      "           2       0.62      0.66      0.64       170\n",
      "\n",
      "    accuracy                           0.51       396\n",
      "   macro avg       0.48      0.48      0.48       396\n",
      "weighted avg       0.51      0.51      0.51       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 31  33  19]\n",
      " [ 35  59  49]\n",
      " [ 14  43 113]]\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_LGBMClassifier = LGBMClassifier(random_state=42)\n",
    "model_LGBMClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_LGBMClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eea412",
   "metadata": {},
   "source": [
    "# Prediction on the selected validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d6e0d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_val  y_val_pred\n",
      "0       0           1\n",
      "1       0           1\n",
      "2       0           1\n",
      "3       0           2\n",
      "4       0           0\n",
      "5       0           2\n",
      "6       0           2\n",
      "7       1           2\n",
      "8       1           2\n",
      "9       1           2\n",
      "10      1           1\n",
      "11      1           1\n",
      "12      1           0\n",
      "13      1           2\n",
      "14      1           2\n",
      "15      1           2\n",
      "16      1           0\n",
      "17      1           1\n",
      "18      1           1\n",
      "19      1           1\n",
      "20      1           1\n",
      "21      1           1\n",
      "22      2           0\n",
      "23      2           1\n",
      "24      2           2\n",
      "25      2           1\n",
      "26      2           1\n",
      "27      2           2\n",
      "28      2           2\n",
      "29      2           1\n",
      "30      2           1\n",
      "31      2           2\n",
      "32      2           2\n",
      "33      2           0\n",
      "34      2           0\n",
      "35      2           2\n",
      "36      2           1\n",
      "37      2           2\n",
      "38      2           2\n",
      "39      2           2\n",
      "40      2           1\n",
      "41      2           1\n",
      "42      2           2\n",
      "43      2           2\n",
      "44      2           1\n",
      "45      2           2\n",
      "46      2           2\n",
      "47      2           2\n",
      "48      2           2\n",
      "49      2           2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15         7\n",
      "           1       0.37      0.47      0.41        15\n",
      "           2       0.64      0.57      0.60        28\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.39      0.39      0.39        50\n",
      "weighted avg       0.49      0.48      0.48        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, you can assess the performance\n",
    "y_val_true = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on the validation set\n",
    "y_val_pred = model_LGBMClassifier.predict(X_val)\n",
    "\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val_true.values.ravel(), 'y_val_pred': y_val_pred.ravel()})\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)\n",
    "\n",
    "# Assess the performance of the model on the validation set using classification report\n",
    "print(classification_report(y_val_true.values.ravel(), y_val_pred.ravel()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3402a3",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Model-14 : ExtraTreesClassifier </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "881276ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38        83\n",
      "           1       0.46      0.45      0.46       143\n",
      "           2       0.62      0.66      0.64       170\n",
      "\n",
      "    accuracy                           0.52       396\n",
      "   macro avg       0.50      0.49      0.49       396\n",
      "weighted avg       0.52      0.52      0.52       396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38        83\n",
      "           1       0.46      0.45      0.46       143\n",
      "           2       0.62      0.66      0.64       170\n",
      "\n",
      "    accuracy                           0.52       396\n",
      "   macro avg       0.50      0.49      0.49       396\n",
      "weighted avg       0.52      0.52      0.52       396\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 30  33  20]\n",
      " [ 30  65  48]\n",
      " [ 14  44 112]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the ExtraTreesClassifier model\n",
    "model_ExtraTreesClassifier = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "model_ExtraTreesClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_ExtraTreesClassifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f627cdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.29      0.27         7\n",
      "           1       0.33      0.33      0.33        15\n",
      "           2       0.63      0.61      0.62        28\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.40      0.41      0.41        50\n",
      "weighted avg       0.49      0.48      0.48        50\n",
      "\n",
      "      y_val  y_val_pred\n",
      "2022      0           2\n",
      "1678      0           1\n",
      "1780      0           0\n",
      "1633      0           2\n",
      "1961      0           0\n",
      "1874      0           2\n",
      "1758      0           1\n",
      "1204      1           2\n",
      "1396      1           2\n",
      "1432      1           2\n",
      "911       1           1\n",
      "1253      1           1\n",
      "1601      1           0\n",
      "943       1           2\n",
      "987       1           2\n",
      "1132      1           2\n",
      "1365      1           0\n",
      "1239      1           1\n",
      "950       1           1\n",
      "1274      1           0\n",
      "941       1           2\n",
      "1505      1           1\n",
      "331       2           0\n",
      "247       2           1\n",
      "789       2           2\n",
      "316       2           1\n",
      "215       2           1\n",
      "680       2           2\n",
      "585       2           2\n",
      "462       2           1\n",
      "814       2           1\n",
      "39        2           2\n",
      "430       2           2\n",
      "696       2           0\n",
      "873       2           0\n",
      "328       2           2\n",
      "611       2           1\n",
      "23        2           2\n",
      "501       2           2\n",
      "198       2           2\n",
      "110       2           1\n",
      "728       2           1\n",
      "673       2           2\n",
      "426       2           2\n",
      "785       2           2\n",
      "66        2           2\n",
      "44        2           2\n",
      "684       2           2\n",
      "774       2           2\n",
      "76        2           2\n"
     ]
    }
   ],
   "source": [
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# If you have the true target values for your validation set, assign them to y_val\n",
    "y_val = df2_validation['Target']\n",
    "\n",
    "# Use the model to predict on validation set\n",
    "y_val_pred = model_ExtraTreesClassifier.predict(X_val)\n",
    "\n",
    "# Create a dataframe with 'y_val' and 'y_val_pred' as columns\n",
    "results_df = pd.DataFrame({'y_val': y_val, 'y_val_pred': y_val_pred})\n",
    "\n",
    "# Assess the performance if you have the true target values\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Print out the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20c16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f9b8c87",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Automatic ML Model Building Packages </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a5d1a",
   "metadata": {},
   "source": [
    "<h1 style = \"color : blue\"> LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e17bfeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
      "Model                                                                          \n",
      "ExtraTreesClassifier               0.52               0.50    None      0.52   \n",
      "RandomForestClassifier             0.51               0.48    None      0.51   \n",
      "LabelSpreading                     0.49               0.48    None      0.49   \n",
      "LabelPropagation                   0.49               0.48    None      0.49   \n",
      "XGBClassifier                      0.51               0.47    None      0.50   \n",
      "LGBMClassifier                     0.50               0.47    None      0.50   \n",
      "NuSVC                              0.47               0.46    None      0.47   \n",
      "BaggingClassifier                  0.48               0.46    None      0.48   \n",
      "KNeighborsClassifier               0.45               0.43    None      0.46   \n",
      "AdaBoostClassifier                 0.47               0.43    None      0.46   \n",
      "RidgeClassifier                    0.47               0.43    None      0.45   \n",
      "LogisticRegression                 0.46               0.42    None      0.45   \n",
      "LinearSVC                          0.45               0.41    None      0.43   \n",
      "DecisionTreeClassifier             0.43               0.41    None      0.44   \n",
      "NearestCentroid                    0.41               0.41    None      0.41   \n",
      "RidgeClassifierCV                  0.45               0.40    None      0.43   \n",
      "QuadraticDiscriminantAnalysis      0.36               0.40    None      0.34   \n",
      "ExtraTreeClassifier                0.42               0.40    None      0.42   \n",
      "LinearDiscriminantAnalysis         0.42               0.40    None      0.42   \n",
      "SVC                                0.46               0.40    None      0.42   \n",
      "BernoulliNB                        0.39               0.39    None      0.39   \n",
      "SGDClassifier                      0.40               0.38    None      0.40   \n",
      "CalibratedClassifierCV             0.45               0.37    None      0.36   \n",
      "PassiveAggressiveClassifier        0.39               0.36    None      0.39   \n",
      "Perceptron                         0.38               0.34    None      0.36   \n",
      "DummyClassifier                    0.43               0.33    None      0.26   \n",
      "GaussianNB                         0.35               0.33    None      0.22   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "ExtraTreesClassifier                 0.38  \n",
      "RandomForestClassifier               0.81  \n",
      "LabelSpreading                       0.15  \n",
      "LabelPropagation                     0.13  \n",
      "XGBClassifier                        1.79  \n",
      "LGBMClassifier                       0.87  \n",
      "NuSVC                                0.35  \n",
      "BaggingClassifier                    0.90  \n",
      "KNeighborsClassifier                 0.03  \n",
      "AdaBoostClassifier                   0.77  \n",
      "RidgeClassifier                      0.03  \n",
      "LogisticRegression                   0.13  \n",
      "LinearSVC                            2.52  \n",
      "DecisionTreeClassifier               0.15  \n",
      "NearestCentroid                      0.02  \n",
      "RidgeClassifierCV                    0.05  \n",
      "QuadraticDiscriminantAnalysis        0.10  \n",
      "ExtraTreeClassifier                  0.01  \n",
      "LinearDiscriminantAnalysis           0.05  \n",
      "SVC                                  0.29  \n",
      "BernoulliNB                          0.03  \n",
      "SGDClassifier                        0.12  \n",
      "CalibratedClassifierCV              10.27  \n",
      "PassiveAggressiveClassifier          0.06  \n",
      "Perceptron                           0.04  \n",
      "DummyClassifier                      0.02  \n",
      "GaussianNB                           0.05  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.57      0.50         7\n",
      "           1       0.47      0.47      0.47        15\n",
      "           2       0.69      0.64      0.67        28\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.53      0.56      0.54        50\n",
      "weighted avg       0.59      0.58      0.58        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import the required model class\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit LazyClassifier\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print model performance\n",
    "print(models)\n",
    "\n",
    "# Get the best performing model based on the accuracy metric\n",
    "best_model_name = models.index[0]\n",
    "\n",
    "# Instantiate the best model based on the selected name\n",
    "best_model = RandomForestClassifier()  # Replace with the appropriate model class and its respective parameters\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# Use the model to predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# If you have the true target values for your validation set, you can assess the performance\n",
    "y_val_true = df2_validation['Target']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b20ac724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
      "Model                                                                          \n",
      "ExtraTreesClassifier               0.52               0.50    None      0.52   \n",
      "RandomForestClassifier             0.51               0.48    None      0.51   \n",
      "LabelSpreading                     0.49               0.48    None      0.49   \n",
      "LabelPropagation                   0.49               0.48    None      0.49   \n",
      "XGBClassifier                      0.51               0.47    None      0.50   \n",
      "LGBMClassifier                     0.50               0.47    None      0.50   \n",
      "NuSVC                              0.47               0.46    None      0.47   \n",
      "BaggingClassifier                  0.48               0.46    None      0.48   \n",
      "KNeighborsClassifier               0.45               0.43    None      0.46   \n",
      "AdaBoostClassifier                 0.47               0.43    None      0.46   \n",
      "RidgeClassifier                    0.47               0.43    None      0.45   \n",
      "LogisticRegression                 0.46               0.42    None      0.45   \n",
      "LinearSVC                          0.45               0.41    None      0.43   \n",
      "DecisionTreeClassifier             0.43               0.41    None      0.44   \n",
      "NearestCentroid                    0.41               0.41    None      0.41   \n",
      "RidgeClassifierCV                  0.45               0.40    None      0.43   \n",
      "QuadraticDiscriminantAnalysis      0.36               0.40    None      0.34   \n",
      "ExtraTreeClassifier                0.42               0.40    None      0.42   \n",
      "LinearDiscriminantAnalysis         0.42               0.40    None      0.42   \n",
      "SVC                                0.46               0.40    None      0.42   \n",
      "BernoulliNB                        0.39               0.39    None      0.39   \n",
      "SGDClassifier                      0.40               0.38    None      0.40   \n",
      "CalibratedClassifierCV             0.45               0.37    None      0.36   \n",
      "PassiveAggressiveClassifier        0.39               0.36    None      0.39   \n",
      "Perceptron                         0.38               0.34    None      0.36   \n",
      "DummyClassifier                    0.43               0.33    None      0.26   \n",
      "GaussianNB                         0.35               0.33    None      0.22   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "ExtraTreesClassifier                 0.38  \n",
      "RandomForestClassifier               0.80  \n",
      "LabelSpreading                       0.17  \n",
      "LabelPropagation                     0.13  \n",
      "XGBClassifier                        1.77  \n",
      "LGBMClassifier                       1.14  \n",
      "NuSVC                                0.34  \n",
      "BaggingClassifier                    0.92  \n",
      "KNeighborsClassifier                 0.04  \n",
      "AdaBoostClassifier                   0.76  \n",
      "RidgeClassifier                      0.03  \n",
      "LogisticRegression                   0.12  \n",
      "LinearSVC                            2.54  \n",
      "DecisionTreeClassifier               0.14  \n",
      "NearestCentroid                      0.04  \n",
      "RidgeClassifierCV                    0.04  \n",
      "QuadraticDiscriminantAnalysis        0.10  \n",
      "ExtraTreeClassifier                  0.02  \n",
      "LinearDiscriminantAnalysis           0.07  \n",
      "SVC                                  0.30  \n",
      "BernoulliNB                          0.02  \n",
      "SGDClassifier                        0.13  \n",
      "CalibratedClassifierCV              10.16  \n",
      "PassiveAggressiveClassifier          0.05  \n",
      "Perceptron                           0.05  \n",
      "DummyClassifier                      0.04  \n",
      "GaussianNB                           0.03  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ExtraTreesClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_27244\\2690330026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Instantiate the best model based on the selected name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Replace with the appropriate model class and its respective parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Train the best model on the entire dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ExtraTreesClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import the required model class\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit LazyClassifier\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print model performance\n",
    "print(models)\n",
    "\n",
    "# Get the best performing model based on the accuracy metric\n",
    "best_model_name = models.index[0]\n",
    "\n",
    "# Instantiate the best model based on the selected name\n",
    "best_model = ExtraTreesClassifier()  # Replace with the appropriate model class and its respective parameters\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Define X_val\n",
    "X_val = df2_validation.drop(columns='Target')\n",
    "\n",
    "# Use the model to predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# If you have the true target values for your validation set, you can assess the performance\n",
    "y_val_true = df2_validation['Target']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65894b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f417c1f",
   "metadata": {},
   "source": [
    "# bagging, boosting, or stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58136d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc175815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c8c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6fba9bb",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\"> Model-14 : TPOT for automatic ML Model Building </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "aaab103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tpot\n",
    "#!pip install -U scikit-learn\n",
    "#!pip install tpot==0.11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "217f2b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/550 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.46717645649482886\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.47474943097871664\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.47474943097871664\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.47474943097871664\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.47727907998243024\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.47727907998243024\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.47727907998243024\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.47727907998243024\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.47727907998243024\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.47727907998243024\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=1.0, min_samples_leaf=3, min_samples_split=7, n_estimators=100)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.35      0.37        83\n",
      "           1       0.45      0.42      0.43       143\n",
      "           2       0.58      0.65      0.61       170\n",
      "\n",
      "    accuracy                           0.50       396\n",
      "   macro avg       0.48      0.47      0.47       396\n",
      "weighted avg       0.49      0.50      0.50       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "# # Target and feature selection\n",
    "# X = df1_model.drop(columns='Target')\n",
    "# y = df1_model['Target']\n",
    "\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a TPOTClassifier object\n",
    "# tpot = TPOTClassifier(generations=10, population_size=50, verbosity=2, random_state=42)  # Adjust the parameters as per your requirement\n",
    "\n",
    "# # Train the model\n",
    "# tpot.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = tpot.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Generation 1 - Current best internal CV score: 0.46717645649482886\n",
    "\n",
    "Generation 2 - Current best internal CV score: 0.47474943097871664\n",
    "\n",
    "Generation 3 - Current best internal CV score: 0.47474943097871664\n",
    "\n",
    "Generation 4 - Current best internal CV score: 0.47474943097871664\n",
    "\n",
    "Generation 5 - Current best internal CV score: 0.47727907998243024\n",
    "\n",
    "Generation 6 - Current best internal CV score: 0.47727907998243024\n",
    "\n",
    "Generation 7 - Current best internal CV score: 0.47727907998243024\n",
    "\n",
    "Generation 8 - Current best internal CV score: 0.47727907998243024\n",
    "\n",
    "Generation 9 - Current best internal CV score: 0.47727907998243024\n",
    "\n",
    "Generation 10 - Current best internal CV score: 0.47727907998243024\n",
    "\n",
    "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=1.0, min_samples_leaf=3, min_samples_split=7, n_estimators=100)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.40      0.35      0.37        83\n",
    "           1       0.45      0.42      0.43       143\n",
    "           2       0.58      0.65      0.61       170\n",
    "\n",
    "    accuracy                           0.50       396\n",
    "   macro avg       0.48      0.47      0.47       396\n",
    "weighted avg       0.49      0.50      0.50       396"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbcdbae",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\"> Model-14 : PyCaret </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a35e9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pycaret[full] in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (3.0.4)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (0.2.1)\n",
      "Requirement already satisfied: pmdarima!=1.8.1,<3.0.0,>=1.8.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (2.0.3)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (0.13.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (5.5.0)\n",
      "Requirement already satisfied: scipy<2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn<1.3.0,>=1.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.2.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (7.31.1)\n",
      "Requirement already satisfied: jinja2>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (2.11.3)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (1.4.4)\n",
      "Requirement already satisfied: pyod>=1.0.8 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (2.28.1)\n",
      "Requirement already satisfied: psutil>=5.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (5.9.0)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (0.3.7)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (4.64.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.2.0)\n",
      "Requirement already satisfied: schemdraw==0.15 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (0.15)\n",
      "Requirement already satisfied: tbats>=1.1.3 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.1.3)\n",
      "Requirement already satisfied: numba>=0.55.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (0.55.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (3.2.0)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.1 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (0.10.1)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (2.6.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (2.0.0)\n",
      "Requirement already satisfied: plotly-resampler>=0.8.3.1 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (0.9.1)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (2.1.0)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.5)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (2.0.1)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (7.6.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (3.5.2)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (3.3.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (6.8.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.21 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.21.6)\n",
      "Requirement already satisfied: sktime!=0.17.1,!=0.17.2,!=0.18.0,>=0.16.1 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (0.20.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (5.9.0)\n",
      "Collecting evidently<0.3,>=0.1.45.dev0\n",
      "  Downloading evidently-0.2.8-py3-none-any.whl (12.1 MB)\n",
      "     --------------------------------------- 12.1/12.1 MB 18.2 MB/s eta 0:00:00\n",
      "Collecting tune-sklearn>=0.2.1\n",
      "  Downloading tune_sklearn-0.4.6-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.9/41.9 kB ? eta 0:00:00\n",
      "Collecting scikit-learn-intelex>=2023.0.1\n",
      "  Downloading scikit_learn_intelex-2023.2.0-py39-none-win_amd64.whl (134 kB)\n",
      "     ---------------------------------------- 134.5/134.5 kB ? eta 0:00:00\n",
      "Collecting mlflow<2.0.0,>=1.24.0\n",
      "  Downloading mlflow-1.30.1-py3-none-any.whl (17.0 MB)\n",
      "     --------------------------------------- 17.0/17.0 MB 21.8 MB/s eta 0:00:00\n",
      "Collecting explainerdashboard>=0.3.8\n",
      "  Downloading explainerdashboard-0.4.2.2-py3-none-any.whl (286 kB)\n",
      "     ------------------------------------- 286.9/286.9 kB 17.3 MB/s eta 0:00:00\n",
      "Collecting boto3>=1.24.56\n",
      "  Downloading boto3-1.28.3-py3-none-any.whl (135 kB)\n",
      "     -------------------------------------- 135.7/135.7 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting shap>=0.38.0\n",
      "  Downloading shap-0.42.0-cp39-cp39-win_amd64.whl (461 kB)\n",
      "     ---------------------------------------- 461.5/461.5 kB ? eta 0:00:00\n",
      "Collecting umap-learn>=0.5.2\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "     ---------------------------------------- 88.2/88.2 kB 4.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fugue[dask]>=0.8.0\n",
      "  Downloading fugue-0.8.5-py3-none-any.whl (273 kB)\n",
      "     ------------------------------------- 273.6/273.6 kB 16.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mlxtend>=0.19.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (0.22.0)\n",
      "Collecting moto>=3.0.7\n",
      "  Downloading moto-4.1.12-py2.py3-none-any.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 32.3 MB/s eta 0:00:00\n",
      "Collecting uvicorn>=0.17.6\n",
      "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Collecting deepchecks>=0.9.2\n",
      "  Downloading deepchecks-0.17.3-py3-none-any.whl (7.8 MB)\n",
      "     ---------------------------------------- 7.8/7.8 MB 27.7 MB/s eta 0:00:00\n",
      "Collecting ray[tune]>=1.0.0\n",
      "  Downloading ray-2.5.1-cp39-cp39-win_amd64.whl (22.0 MB)\n",
      "     --------------------------------------- 22.0/22.0 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting pandas-profiling>=3.1.0\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "     ------------------------------------- 324.4/324.4 kB 20.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: catboost>=0.23.2 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.2)\n",
      "Collecting gradio>=2.8.10\n",
      "  Downloading gradio-3.36.1-py3-none-any.whl (19.8 MB)\n",
      "     --------------------------------------- 19.8/19.8 MB 18.7 MB/s eta 0:00:00\n",
      "Collecting optuna>=3.0.0\n",
      "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
      "     ------------------------------------- 390.6/390.6 kB 23.8 MB/s eta 0:00:00\n",
      "Collecting scikit-optimize>=0.9.0\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "     ---------------------------------------- 100.3/100.3 kB ? eta 0:00:00\n",
      "Collecting statsforecast>=0.5.5\n",
      "  Downloading statsforecast-1.5.0-py3-none-any.whl (99 kB)\n",
      "     -------------------------------------- 100.0/100.0 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting m2cgen>=0.9.0\n",
      "  Downloading m2cgen-0.10.0-py3-none-any.whl (92 kB)\n",
      "     ---------------------------------------- 92.2/92.2 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting interpret>=0.2.7\n",
      "  Downloading interpret-0.4.2-py3-none-any.whl (1.4 kB)\n",
      "Collecting Flask==2.2.3\n",
      "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
      "     ---------------------------------------- 101.8/101.8 kB ? eta 0:00:00\n",
      "Collecting autoviz>=0.1.36\n",
      "  Downloading autoviz-0.1.730-py3-none-any.whl (67 kB)\n",
      "     -------------------------------------- 67.0/67.0 kB 402.8 kB/s eta 0:00:00\n",
      "Collecting fairlearn==0.7.0\n",
      "  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n",
      "     ------------------------------------- 177.5/177.5 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting hyperopt>=0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 33.5 MB/s eta 0:00:00\n",
      "Collecting fastapi>=0.75.0\n",
      "  Downloading fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.7/65.7 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: bokeh<3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (2.4.3)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (1.7.6)\n",
      "Requirement already satisfied: pytest>=7.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret[full]) (7.1.2)\n",
      "Requirement already satisfied: dash[testing] in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from pycaret[full]) (2.11.1)\n",
      "Collecting kmodes>=0.11.1\n",
      "  Downloading kmodes-0.12.2-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask==2.2.3->pycaret[full]) (2.0.1)\n",
      "Collecting jinja2>=1.2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: click>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask==2.2.3->pycaret[full]) (8.0.4)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "     -------------------------------------- 242.5/242.5 kB 7.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec>=0.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from autoviz>=0.1.36->pycaret[full]) (2022.7.1)\n",
      "Collecting pandas-dq==1.28\n",
      "  Downloading pandas_dq-1.28-py3-none-any.whl (25 kB)\n",
      "Collecting hvplot~=0.7.3\n",
      "  Downloading hvplot-0.7.3-py2.py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 3.1/3.1 MB 24.5 MB/s eta 0:00:00\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.2-cp39-cp39-win_amd64.whl (153 kB)\n",
      "     -------------------------------------- 153.3/153.3 kB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autoviz>=0.1.36->pycaret[full]) (4.3.0)\n",
      "Requirement already satisfied: xlrd in c:\\programdata\\anaconda3\\lib\\site-packages (from autoviz>=0.1.36->pycaret[full]) (2.0.1)\n",
      "Collecting pyamg\n",
      "  Downloading pyamg-5.0.1-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 24.8 MB/s eta 0:00:00\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     ------------------------------------- 636.8/636.8 kB 41.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: panel>=0.12.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from autoviz>=0.1.36->pycaret[full]) (0.13.1)\n",
      "Collecting holoviews~=1.14.9\n",
      "  Downloading holoviews-1.14.9-py2.py3-none-any.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 30.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from autoviz>=0.1.36->pycaret[full]) (3.7)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.6.0.tar.gz (356 kB)\n",
      "     ------------------------------------- 356.6/356.6 kB 23.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: seaborn>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autoviz>=0.1.36->pycaret[full]) (0.11.2)\n",
      "Requirement already satisfied: jupyter in c:\\programdata\\anaconda3\\lib\\site-packages (from autoviz>=0.1.36->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from bokeh<3.0.0->pycaret[full]) (21.3)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from bokeh<3.0.0->pycaret[full]) (6.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from bokeh<3.0.0->pycaret[full]) (6.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bokeh<3.0.0->pycaret[full]) (9.2.0)\n",
      "Collecting botocore<1.32.0,>=1.31.3\n",
      "  Downloading botocore-1.31.3-py3-none-any.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 23.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3>=1.24.56->pycaret[full]) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3>=1.24.56->pycaret[full]) (0.6.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from catboost>=0.23.2->pycaret[full]) (0.20.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost>=0.23.2->pycaret[full]) (1.16.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders>=2.4.0->pycaret[full]) (0.5.2)\n",
      "Collecting PyNomaly>=0.3.3\n",
      "  Downloading PyNomaly-0.3.3.tar.gz (8.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepchecks>=0.9.2->pycaret[full]) (4.11.1)\n",
      "Collecting statsmodels>=0.12.1\n",
      "  Downloading statsmodels-0.14.0-cp39-cp39-win_amd64.whl (9.4 MB)\n",
      "     ---------------------------------------- 9.4/9.4 MB 21.3 MB/s eta 0:00:00\n",
      "Collecting plotly>=5.0.0\n",
      "  Downloading plotly-5.15.0-py2.py3-none-any.whl (15.5 MB)\n",
      "     --------------------------------------- 15.5/15.5 MB 19.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyzmq<24.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepchecks>=0.9.2->pycaret[full]) (23.2.0)\n",
      "Requirement already satisfied: ipykernel>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepchecks>=0.9.2->pycaret[full]) (6.15.2)\n",
      "Collecting jsonpickle>=2\n",
      "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.5/40.5 kB ? eta 0:00:00\n",
      "Collecting pydantic<2\n",
      "  Downloading pydantic-1.10.11-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 27.9 MB/s eta 0:00:00\n",
      "Collecting flask-simplelogin\n",
      "  Downloading flask_simplelogin-0.1.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting dash-auth\n",
      "  Downloading dash_auth-2.0.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting oyaml\n",
      "  Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
      "Collecting dash-bootstrap-components>=1\n",
      "  Downloading dash_bootstrap_components-1.4.1-py3-none-any.whl (220 kB)\n",
      "     -------------------------------------- 220.6/220.6 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting Flask-WTF>=1.1\n",
      "  Downloading Flask_WTF-1.1.1-py3-none-any.whl (12 kB)\n",
      "Collecting waitress\n",
      "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.7/57.7 kB ? eta 0:00:00\n",
      "Collecting jupyter-dash>=0.4.1\n",
      "  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
      "Collecting dtreeviz>=2.1\n",
      "  Downloading dtreeviz-2.2.2-py3-none-any.whl (91 kB)\n",
      "     ---------------------------------------- 91.8/91.8 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.1.1\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "     ---------------------------------------- 67.0/67.0 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting sqlglot\n",
      "  Downloading sqlglot-17.4.1-py3-none-any.whl (281 kB)\n",
      "     ------------------------------------- 281.2/281.2 kB 18.1 MB/s eta 0:00:00\n",
      "Collecting adagio>=0.2.4\n",
      "  Downloading adagio-0.2.4-py3-none-any.whl (26 kB)\n",
      "Collecting fugue-sql-antlr>=0.1.6\n",
      "  Downloading fugue-sql-antlr-0.1.6.tar.gz (154 kB)\n",
      "     -------------------------------------- 154.6/154.6 kB 9.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting qpd>=0.4.3\n",
      "  Downloading qpd-0.4.4-py3-none-any.whl (169 kB)\n",
      "     ---------------------------------------- 169.2/169.2 kB ? eta 0:00:00\n",
      "Collecting pyarrow>=0.15.1\n",
      "  Downloading pyarrow-12.0.1-cp39-cp39-win_amd64.whl (21.5 MB)\n",
      "     --------------------------------------- 21.5/21.5 MB 18.2 MB/s eta 0:00:00\n",
      "Collecting triad>=0.9.0\n",
      "  Downloading triad-0.9.1-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.0/57.0 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting dask[dataframe,distributed]>=2022.9.0\n",
      "  Downloading dask-2023.7.0-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 38.0 MB/s eta 0:00:00\n",
      "Collecting altair>=4.2.0\n",
      "  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\n",
      "     ------------------------------------- 471.5/471.5 kB 14.9 MB/s eta 0:00:00\n",
      "Collecting gradio-client>=0.2.7\n",
      "  Downloading gradio_client-0.2.9-py3-none-any.whl (288 kB)\n",
      "     ---------------------------------------- 288.8/288.8 kB ? eta 0:00:00\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.7/45.7 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: orjson in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from gradio>=2.8.10->pycaret[full]) (3.9.2)\n",
      "Collecting pygments>=2.12.0\n",
      "  Using cached Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-11.0.3-cp39-cp39-win_amd64.whl (124 kB)\n",
      "     -------------------------------------- 124.7/124.7 kB 7.2 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 75.4/75.4 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.14.0\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     ------------------------------------- 268.8/268.8 kB 16.2 MB/s eta 0:00:00\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-win_amd64.whl (323 kB)\n",
      "     -------------------------------------- 323.6/323.6 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.5/50.5 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting semantic-version\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     ---------------------------------------- 200.5/200.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->pycaret[full]) (2.8.4)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->pycaret[full]) (0.18.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn>=0.8.1->pycaret[full]) (2.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.12.0->pycaret[full]) (3.8.0)\n",
      "Collecting interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2\n",
      "  Downloading interpret_core-0.4.2-py3-none-any.whl (11.6 MB)\n",
      "     --------------------------------------- 11.6/11.6 MB 22.6 MB/s eta 0:00:00\n",
      "Collecting SALib>=1.3.3\n",
      "  Downloading salib-1.4.7-py3-none-any.whl (757 kB)\n",
      "     ------------------------------------- 758.0/758.0 kB 24.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: dill>=0.2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (0.3.4)\n",
      "Collecting skope-rules>=1.0.1\n",
      "  Downloading skope_rules-1.0.1-py3-none-any.whl (14 kB)\n",
      "Collecting gevent>=1.3.6\n",
      "  Downloading gevent-23.7.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 24.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: dash-core-components>=1.0.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
      "Collecting dash-cytoscape>=0.1.1\n",
      "  Downloading dash_cytoscape-0.3.0-py3-none-any.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 25.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: dash-table>=4.1.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (5.0.0)\n",
      "Requirement already satisfied: dash-html-components>=1.0.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
      "Collecting lime>=0.1.1.33\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "     -------------------------------------- 275.7/275.7 kB 8.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting treeinterpreter>=0.2.2\n",
      "  Downloading treeinterpreter-0.2.3-py2.py3-none-any.whl (6.0 kB)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (63.4.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.4.5)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (5.1.1)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (3.0.20)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.1.6)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.5.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret[full]) (0.2.0)\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm>=3.0.0->pycaret[full]) (0.37.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->pycaret[full]) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->pycaret[full]) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->pycaret[full]) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->pycaret[full]) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->pycaret[full]) (0.11.0)\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow<2.0.0,>=1.24.0->pycaret[full]) (1.4.39)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
      "     ---------------------------------------- 188.5/188.5 kB ? eta 0:00:00\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n",
      "     ---------------------------------------- 83.5/83.5 kB 4.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "     ---------------------------------------- 148.1/148.1 kB ? eta 0:00:00\n",
      "Collecting alembic<2\n",
      "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
      "     ------------------------------------- 224.5/224.5 kB 13.4 MB/s eta 0:00:00\n",
      "Collecting querystring-parser<2\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting importlib-metadata>=4.12.0\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: entrypoints<1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow<2.0.0,>=1.24.0->pycaret[full]) (0.4)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.2/41.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz<2023 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow<2.0.0,>=1.24.0->pycaret[full]) (2022.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from mlflow<2.0.0,>=1.24.0->pycaret[full]) (4.23.3)\n",
      "Collecting prometheus-flask-exporter<1\n",
      "  Downloading prometheus_flask_exporter-0.22.4-py3-none-any.whl (18 kB)\n",
      "Collecting responses>=0.13.0\n",
      "  Downloading responses-0.23.1-py3-none-any.whl (52 kB)\n",
      "     ---------------------------------------- 52.1/52.1 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cryptography>=3.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from moto>=3.0.7->pycaret[full]) (37.0.1)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: jupyter_core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->pycaret[full]) (4.11.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->pycaret[full]) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->pycaret[full]) (4.16.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.55.0->pycaret[full]) (0.38.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting ydata-profiling\n",
      "  Downloading ydata_profiling-4.3.1-py2.py3-none-any.whl (352 kB)\n",
      "     ------------------------------------- 353.0/353.0 kB 22.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->pycaret[full]) (8.0.1)\n",
      "Requirement already satisfied: trace-updater>=0.0.8 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from plotly-resampler>=0.8.3.1->pycaret[full]) (0.0.9.1)\n",
      "Requirement already satisfied: tsdownsample==0.1.2 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from plotly-resampler>=0.8.3.1->pycaret[full]) (0.1.2)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret[full]) (1.26.11)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret[full]) (0.29.32)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=7.0.1->pycaret[full]) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=7.0.1->pycaret[full]) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=7.0.1->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=7.0.1->pycaret[full]) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=7.0.1->pycaret[full]) (2.0.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=7.0.1->pycaret[full]) (1.4.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[tune]>=1.0.0->pycaret[full]) (1.0.3)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "     ---------------------------------------- 44.7/44.7 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting grpcio<=1.51.3,>=1.32.0\n",
      "  Downloading grpcio-1.51.3-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 23.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[tune]>=1.0.0->pycaret[full]) (3.6.0)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting pyarrow>=0.15.1\n",
      "  Downloading pyarrow-6.0.1-cp39-cp39-win_amd64.whl (15.5 MB)\n",
      "     --------------------------------------- 15.5/15.5 MB 19.8 MB/s eta 0:00:00\n",
      "Collecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
      "     -------------------------------------- 101.6/101.6 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27.1->pycaret[full]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27.1->pycaret[full]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27.1->pycaret[full]) (2022.9.14)\n",
      "Collecting daal4py==2023.2.0\n",
      "  Downloading daal4py-2023.2.0-py39-none-win_amd64.whl (11.4 MB)\n",
      "     --------------------------------------- 11.4/11.4 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting daal==2023.2.0\n",
      "  Downloading daal-2023.2.0-py2.py3-none-win_amd64.whl (57.4 MB)\n",
      "     ---------------------------------------- 57.4/57.4 MB 3.5 MB/s eta 0:00:00\n",
      "Collecting tbb==2021.*\n",
      "  Downloading tbb-2021.10.0-py3-none-win_amd64.whl (284 kB)\n",
      "     -------------------------------------- 284.8/284.8 kB 8.9 MB/s eta 0:00:00\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-23.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scikit-base<0.6.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from sktime!=0.17.1,!=0.17.2,!=0.18.0,>=0.16.1->pycaret[full]) (0.5.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from sktime!=0.17.1,!=0.17.2,!=0.18.0,>=0.16.1->pycaret[full]) (1.2.14)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 9.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: ansi2html in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from dash[testing]->pycaret[full]) (1.8.0)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     ------------------------------------- 233.6/233.6 kB 14.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: retrying in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from dash[testing]->pycaret[full]) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\lib\\site-packages (from dash[testing]->pycaret[full]) (1.5.5)\n",
      "Collecting multiprocess>=0.70.12\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.9/132.9 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting dash-testing-stub>=0.0.2\n",
      "  Downloading dash_testing_stub-0.0.2-py3-none-any.whl (2.6 kB)\n",
      "Requirement already satisfied: lxml>=4.6.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dash[testing]->pycaret[full]) (4.9.1)\n",
      "Collecting percy>=2.0.2\n",
      "  Downloading percy-2.0.2-py2.py3-none-any.whl (12 kB)\n",
      "Collecting selenium<=4.2.0,>=3.141.0\n",
      "  Downloading selenium-4.2.0-py3-none-any.whl (983 kB)\n",
      "     -------------------------------------- 983.2/983.2 kB 8.8 MB/s eta 0:00:00\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.7/78.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: toolz in c:\\programdata\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio>=2.8.10->pycaret[full]) (0.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->deepchecks>=0.9.2->pycaret[full]) (2.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=3.3.1->moto>=3.0.7->pycaret[full]) (1.15.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe,distributed]>=2022.9.0->fugue[dask]>=0.8.0->pycaret[full]) (1.2.0)\n",
      "Collecting distributed==2023.7.0\n",
      "  Downloading distributed-2023.7.0-py3-none-any.whl (981 kB)\n",
      "     -------------------------------------- 981.6/981.6 kB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2023.7.0->dask[dataframe,distributed]>=2022.9.0->fugue[dask]>=0.8.0->pycaret[full]) (2.4.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2023.7.0->dask[dataframe,distributed]>=2022.9.0->fugue[dask]>=0.8.0->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2023.7.0->dask[dataframe,distributed]>=2022.9.0->fugue[dask]>=0.8.0->pycaret[full]) (1.7.0)\n",
      "Collecting zict>=2.2.0\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.3/43.3 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow<2.0.0,>=1.24.0->pycaret[full]) (2.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\mdaminulisla.prodhan\\appdata\\roaming\\python\\python39\\site-packages (from databricks-cli<1,>=0.8.7->mlflow<2.0.0,>=1.24.0->pycaret[full]) (3.2.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow<2.0.0,>=1.24.0->pycaret[full]) (0.8.10)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from deprecated>=1.2.13->sktime!=0.17.1,!=0.17.2,!=0.18.0,>=0.16.1->pycaret[full]) (1.14.1)\n",
      "Collecting pywin32>=304\n",
      "  Downloading pywin32-306-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "     ---------------------------------------- 9.3/9.3 MB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from docker<7,>=4.0.0->mlflow<2.0.0,>=1.24.0->pycaret[full]) (0.58.0)\n",
      "Collecting colour\n",
      "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Collecting WTForms\n",
      "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
      "     ---------------------------------------- 136.5/136.5 kB ? eta 0:00:00\n",
      "Collecting antlr4-python3-runtime<4.12,>=4.11.1\n",
      "  Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
      "     ---------------------------------------- 144.2/144.2 kB ? eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorcet in c:\\programdata\\anaconda3\\lib\\site-packages (from holoviews~=1.14.9->autoviz>=0.1.36->pycaret[full]) (3.0.0)\n",
      "Requirement already satisfied: pyviz-comms>=0.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from holoviews~=1.14.9->autoviz>=0.1.36->pycaret[full]) (2.0.2)\n",
      "Requirement already satisfied: param<2.0,>=1.9.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from holoviews~=1.14.9->autoviz>=0.1.36->pycaret[full]) (1.12.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=5.3.0->deepchecks>=0.9.2->pycaret[full]) (7.3.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=5.3.0->deepchecks>=0.9.2->pycaret[full]) (1.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[full]) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.4/50.4 kB 2.5 MB/s eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.5/46.5 kB 2.3 MB/s eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.1 MB/s eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.0/41.0 kB ? eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.0/41.0 kB ? eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
      "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
      "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib-inline to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib-inline\n",
      "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "INFO: pip is looking at multiple versions of markdown-it-py[linkify] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.5/84.5 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting dill>=0.2.5\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     -------------------------------------- 110.5/110.5 kB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->autoviz>=0.1.36->pycaret[full]) (2022.7.9)\n",
      "Requirement already satisfied: markdown in c:\\programdata\\anaconda3\\lib\\site-packages (from panel>=0.12.6->autoviz>=0.1.36->pycaret[full]) (3.3.4)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from panel>=0.12.6->autoviz>=0.1.36->pycaret[full]) (4.1.0)\n",
      "Requirement already satisfied: pyct>=0.4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from panel>=0.12.6->autoviz>=0.1.36->pycaret[full]) (0.4.8)\n",
      "Requirement already satisfied: prometheus-client in c:\\programdata\\anaconda3\\lib\\site-packages (from prometheus-flask-exporter<1->mlflow<2.0.0,>=1.24.0->pycaret[full]) (0.14.1)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret[full]) (0.2.5)\n",
      "Collecting python-utils\n",
      "  Downloading python_utils-3.7.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting types-PyYAML\n",
      "  Downloading types_PyYAML-6.0.12.10-py3-none-any.whl (14 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "     ------------------------------------- 400.2/400.2 kB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy<2,>=1.4.0->mlflow<2.0.0,>=1.24.0->pycaret[full]) (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.75.0->pycaret[full]) (3.5.0)\n",
      "Collecting fs\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "     -------------------------------------- 135.3/135.3 kB 8.3 MB/s eta 0:00:00\n",
      "Collecting markupsafe>=2.0.1\n",
      "  Downloading MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.6.5->pycaret[full]) (6.4.12)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 61.7/61.7 kB ? eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 74.5/74.5 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->gradio>=2.8.10->pycaret[full]) (1.2.0)\n",
      "Requirement already satisfied: jupyter-console in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->autoviz>=0.1.36->pycaret[full]) (6.4.3)\n",
      "Requirement already satisfied: nbconvert in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->autoviz>=0.1.36->pycaret[full]) (6.4.4)\n",
      "Requirement already satisfied: qtconsole in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->autoviz>=0.1.36->pycaret[full]) (5.2.2)\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "     -------------------------------------- 102.7/102.7 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting dacite>=1.8\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Collecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.3-cp39-cp39-win_amd64.whl (663 kB)\n",
      "     ------------------------------------- 663.5/663.5 kB 10.4 MB/s eta 0:00:00\n",
      "Collecting imagehash==4.3.1\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "     -------------------------------------- 296.5/296.5 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting htmlmin==0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting typeguard<3,>=2.13.2\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting multimethod<2,>=1.4\n",
      "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: PyWavelets in c:\\programdata\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling>=3.1.0->pycaret[full]) (1.3.0)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 9.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.3.1->moto>=3.0.7->pycaret[full]) (2.21)\n",
      "Requirement already satisfied: zope.interface in c:\\programdata\\anaconda3\\lib\\site-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (5.4.0)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp39-cp39-win_amd64.whl (192 kB)\n",
      "     ---------------------------------------- 192.1/192.1 kB ? eta 0:00:00\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (0.19.2)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.5->pycaret[full]) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.5->pycaret[full]) (0.13.1)\n",
      "Requirement already satisfied: argon2-cffi in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.5->pycaret[full]) (21.3.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->autoviz>=0.1.36->pycaret[full]) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->autoviz>=0.1.36->pycaret[full]) (0.5.13)\n",
      "Requirement already satisfied: testpath in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->autoviz>=0.1.36->pycaret[full]) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->autoviz>=0.1.36->pycaret[full]) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->autoviz>=0.1.36->pycaret[full]) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->autoviz>=0.1.36->pycaret[full]) (0.1.2)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3->pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret[full]) (1.7.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3->pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret[full]) (22.0.0)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->panel>=0.12.6->autoviz>=0.1.36->pycaret[full]) (0.5.1)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from fs->triad>=0.9.0->fugue[dask]>=0.8.0->pycaret[full]) (1.4.4)\n",
      "Requirement already satisfied: qtpy in c:\\programdata\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->autoviz>=0.1.36->pycaret[full]) (2.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (2021.7.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret>=0.2.7->pycaret[full]) (2.19.3)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.5->pycaret[full]) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\programdata\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.5->pycaret[full]) (21.2.0)\n",
      "Building wheels for collected packages: umap-learn, databricks-cli, fugue-sql-antlr, pynndescent, PyNomaly, emoji, ffmpy, htmlmin, lime\n",
      "  Building wheel for umap-learn (setup.py): started\n",
      "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82814 sha256=b296b5d43b5c357185111250c97277ec5471a485c9f0b54e3a157c6394fad6a6\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\f4\\3e\\1c\\596d0a463d17475af648688443fa4846fef624d1390339e7e9\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143860 sha256=0ed6eef192ebab290b886d19bd2b865d522bfebc02e99a98e1030cd31961ab91\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\b6\\90\\68\\94d223a35a3910c1512a8d42d9f8333ce567ef26e250a56227\n",
      "  Building wheel for fugue-sql-antlr (setup.py): started\n",
      "  Building wheel for fugue-sql-antlr (setup.py): finished with status 'done'\n",
      "  Created wheel for fugue-sql-antlr: filename=fugue_sql_antlr-0.1.6-py3-none-any.whl size=158049 sha256=947b367232530dafb102130223bac7f30b4a950748094566cfbe5e7f8035ecec\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\57\\b3\\01\\795c8a9ccaf9574fc3471b0199731c5526cf7c5e127db42a74\n",
      "  Building wheel for pynndescent (setup.py): started\n",
      "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=2a85205d7a3dfe52a74e7db05f33fbbf463b5b20492f29b1228f294a5a7f264a\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\12\\f9\\4d\\ec5ad1c823c710fcc4473669fdcffc8891f4bc398c841af22e\n",
      "  Building wheel for PyNomaly (setup.py): started\n",
      "  Building wheel for PyNomaly (setup.py): finished with status 'done'\n",
      "  Created wheel for PyNomaly: filename=PyNomaly-0.3.3-py3-none-any.whl size=8481 sha256=250228ef87f6cb40db1c7b866794ac13ffea14ee3d982ff7b214e4a48668b3c8\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\72\\c2\\79\\a077f8b4ef4549086016b0202e61193518262377b6d23318b1\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-2.6.0-py2.py3-none-any.whl size=351311 sha256=1e2efa202621ae74a1b0e7582357c25bc8beed45eaecc5e027dcddeaaa871162\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\a9\\25\\66\\ae46b49b24c976a140abb666a8d84a74062c65cc4de5f78c57\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=509f865f0aaf923a9ffe8b5d0198efa29d60c91851b0934bb4149dc16e46a94d\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\91\\e2\\96\\f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27082 sha256=78a8744bd6fd652d3b705e5988d6bc76cd5b87744052db8e4027889398d0d455\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\1d\\05\\04\\c6d7d3b66539d9e659ac6dfe81e2d0fd4c1a8316cc5a403300\n",
      "  Building wheel for lime (setup.py): started\n",
      "  Building wheel for lime (setup.py): finished with status 'done'\n",
      "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283839 sha256=dc0c6bbd8fba9ec04adbc05c36c0117e07785519820acd29483acc6fbc607fe2\n",
      "  Stored in directory: c:\\users\\mdaminulisla.prodhan\\appdata\\local\\pip\\cache\\wheels\\ed\\d7\\c9\\5a0130d06d6310bc6cbe55220e6e72dcb8c4eff9a478717066\n",
      "Successfully built umap-learn databricks-cli fugue-sql-antlr pynndescent PyNomaly emoji ffmpy htmlmin lime\n",
      "Installing collected packages: types-PyYAML, treeinterpreter, tbb, sqlglot, pywin32, pydub, py4j, interpret-core, htmlmin, ffmpy, dash-testing-stub, colour, antlr4-python3-runtime, zope.event, zict, xmltodict, websockets, waitress, uc-micro-py, typing-extensions, typeguard, tangled-up-in-unicode, sqlparse, smmap, slicer, semantic-version, querystring-parser, python-multipart, pygments, pyarrow, pyaml, oyaml, outcome, multimethod, multidict, mdurl, markupsafe, m2cgen, jsonpickle, importlib-metadata, h11, grpcio, greenlet, fs, frozenlist, exceptiongroup, emoji, dill, dacite, daal, colorlog, cmaes, async-timeout, aiofiles, yarl, WTForms, wsproto, Werkzeug, uvicorn, trio, tensorboardX, starlette, responses, python-utils, pydantic, pyamg, plotly, percy, multiprocess, markdown-it-py, Mako, linkify-it-py, jinja2, imagehash, hyperopt, huggingface-hub, httpcore, gitdb, gevent, docker, databricks-cli, dask, daal4py, botocore, aiosignal, wordcloud, visions, trio-websocket, triad, textblob, statsmodels, skope-rules, shap, scikit-optimize, scikit-learn-intelex, SALib, ray, PyNomaly, pynndescent, phik, pandas-dq, mdit-py-plugins, lime, kmodes, httpx, gitpython, Flask, fastapi, fairlearn, dtreeviz, distributed, altair, alembic, aiohttp, umap-learn, prometheus-flask-exporter, optuna, gradio-client, fugue-sql-antlr, Flask-WTF, evidently, boto3, adagio, ydata-profiling, tune-sklearn, selenium, qpd, moto, mlflow, jupyter-dash, holoviews, gradio, flask-simplelogin, dash-cytoscape, dash-bootstrap-components, dash-auth, pandas-profiling, hvplot, fugue, explainerdashboard, statsforecast, interpret, deepchecks, autoviz\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.8.0\n",
      "    Uninstalling importlib-metadata-6.8.0:\n",
      "      Successfully uninstalled importlib-metadata-6.8.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.54.2\n",
      "    Uninstalling grpcio-1.54.2:\n",
      "      Successfully uninstalled grpcio-1.54.2\n",
      "Successfully installed Flask-2.2.3 Flask-WTF-1.1.1 Mako-1.2.4 PyNomaly-0.3.3 SALib-1.4.7 WTForms-3.0.1 Werkzeug-2.2.3 adagio-0.2.4 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 alembic-1.11.1 altair-5.0.1 antlr4-python3-runtime-4.11.1 async-timeout-4.0.2 autoviz-0.1.730 boto3-1.28.3 botocore-1.31.3 cmaes-0.9.1 colorlog-6.7.0 colour-0.1.5 daal-2023.2.0 daal4py-2023.2.0 dacite-1.8.1 dash-auth-2.0.0 dash-bootstrap-components-1.4.1 dash-cytoscape-0.3.0 dash-testing-stub-0.0.2 dask-2023.7.0 databricks-cli-0.17.7 deepchecks-0.17.3 dill-0.3.6 distributed-2023.7.0 docker-6.1.3 dtreeviz-2.2.2 emoji-2.6.0 evidently-0.2.8 exceptiongroup-1.1.2 explainerdashboard-0.4.2.2 fairlearn-0.7.0 fastapi-0.100.0 ffmpy-0.3.0 flask-simplelogin-0.1.2 frozenlist-1.4.0 fs-2.4.16 fugue-0.8.5 fugue-sql-antlr-0.1.6 gevent-23.7.0 gitdb-4.0.10 gitpython-3.1.32 gradio-3.36.1 gradio-client-0.2.9 greenlet-2.0.2 grpcio-1.51.3 h11-0.14.0 holoviews-1.14.9 htmlmin-0.1.12 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 hvplot-0.7.3 hyperopt-0.2.7 imagehash-4.3.1 importlib-metadata-5.2.0 interpret-0.4.2 interpret-core-0.4.2 jinja2-3.1.2 jsonpickle-3.0.1 jupyter-dash-0.4.2 kmodes-0.12.2 lime-0.2.0.1 linkify-it-py-2.0.2 m2cgen-0.10.0 markdown-it-py-2.2.0 markupsafe-2.1.3 mdit-py-plugins-0.3.3 mdurl-0.1.2 mlflow-1.30.1 moto-4.1.12 multidict-6.0.4 multimethod-1.9.1 multiprocess-0.70.14 optuna-3.2.0 outcome-1.2.0 oyaml-1.0 pandas-dq-1.28 pandas-profiling-3.6.6 percy-2.0.2 phik-0.12.3 plotly-5.15.0 prometheus-flask-exporter-0.22.4 py4j-0.10.9.7 pyamg-5.0.1 pyaml-23.7.0 pyarrow-6.0.1 pydantic-1.10.11 pydub-0.25.1 pygments-2.15.1 pynndescent-0.5.10 python-multipart-0.0.6 python-utils-3.7.0 pywin32-306 qpd-0.4.4 querystring-parser-1.2.4 ray-2.5.1 responses-0.23.1 scikit-learn-intelex-2023.2.0 scikit-optimize-0.9.0 selenium-4.2.0 semantic-version-2.10.0 shap-0.42.0 skope-rules-1.0.1 slicer-0.0.7 smmap-5.0.0 sqlglot-17.4.1 sqlparse-0.4.4 starlette-0.27.0 statsforecast-1.5.0 statsmodels-0.14.0 tangled-up-in-unicode-0.2.0 tbb-2021.10.0 tensorboardX-2.6.1 textblob-0.17.1 treeinterpreter-0.2.3 triad-0.9.1 trio-0.22.2 trio-websocket-0.10.3 tune-sklearn-0.4.6 typeguard-2.13.3 types-PyYAML-6.0.12.10 typing-extensions-4.7.1 uc-micro-py-1.0.2 umap-learn-0.5.3 uvicorn-0.22.0 visions-0.7.5 waitress-2.1.2 websockets-11.0.3 wordcloud-1.9.2 wsproto-1.2.0 xmltodict-0.13.0 yarl-1.9.2 ydata-profiling-4.3.1 zict-3.0.0 zope.event-5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script htmlmin.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pygrun.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script waitress-serve.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script sqlformat.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pygmentize.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script plasma_store.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script m2cgen.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mako-render.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script hyperopt-mongo-worker.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts databricks.exe and dbfs.exe are installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dask.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wordcloud_cli.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script salib.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts ray.exe, rllib.exe, serve.exe and tune.exe are installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script phik_trial.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script flask.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts dask-scheduler.exe, dask-ssh.exe and dask-worker.exe are installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script optuna.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pandas_profiling.exe and ydata_profiling.exe are installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script moto_server.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts mlflow.exe and mlp.exe are installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script holoviews.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts gradio.exe and upload_theme.exe are installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pandas_profiling.exe is installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts explainerdashboard.exe and explainerhub.exe are installed in 'C:\\Users\\mdaminulisla.prodhan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pycaret[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b56f027d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d7ea6_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d7ea6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d7ea6_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_d7ea6_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d7ea6_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_d7ea6_row0_col1\" class=\"data row0 col1\" >6333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d7ea6_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_d7ea6_row1_col1\" class=\"data row1 col1\" >Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d7ea6_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_d7ea6_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d7ea6_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_d7ea6_row3_col1\" class=\"data row3 col1\" >(1980, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d7ea6_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_d7ea6_row4_col1\" class=\"data row4 col1\" >(1980, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d7ea6_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_d7ea6_row5_col1\" class=\"data row5 col1\" >(1386, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d7ea6_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_d7ea6_row6_col1\" class=\"data row6 col1\" >(594, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d7ea6_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_d7ea6_row7_col1\" class=\"data row7 col1\" >199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d7ea6_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_d7ea6_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d7ea6_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_d7ea6_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d7ea6_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_d7ea6_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d7ea6_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_d7ea6_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d7ea6_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_d7ea6_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d7ea6_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_d7ea6_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d7ea6_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_d7ea6_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d7ea6_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_d7ea6_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d7ea6_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_d7ea6_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d7ea6_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_d7ea6_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7ea6_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d7ea6_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_d7ea6_row18_col1\" class=\"data row18 col1\" >a69a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eeb2965af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_08f7e\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eea5b37640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Estimator [] does not have the required fit() method.\n",
      "Please check if the dataset has enough samples or features.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Target and feature selection\n",
    "X = df1_model.drop(columns='Target')\n",
    "y = df1_model['Target']\n",
    "\n",
    "# Setup PyCaret environment\n",
    "setup(data=X, target=y)\n",
    "\n",
    "try:\n",
    "    # Compare and select the best model\n",
    "    best_model = compare_models()\n",
    "\n",
    "    # Train the best model\n",
    "    trained_model = tune_model(best_model)\n",
    "\n",
    "    # Validate the model\n",
    "    predictions = predict_model(trained_model)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(trained_model)\n",
    "\n",
    "    # Save the model\n",
    "    save_model(trained_model, 'saved_model')\n",
    "\n",
    "except ValueError as ve:\n",
    "    print(\"An error occurred:\", ve)\n",
    "    print(\"Please check if the dataset has enough samples or features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d5718",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\"> .........................APPENDIX............................ </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04250e7d",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\"> Combined Model validation </h2>\n",
    "<ul style=\"color:blue;\"> \n",
    "    <li>Prediction on the selected validation data for all Models </LI>\n",
    "   </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79df802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...................................................................................................\n",
    "#...................................................................................................\n",
    "\n",
    "# below mentioned two setp process (creation of the Summary data frame and Grouping for No/Yes Summing ) \n",
    "# can be done by this one step code chunk \n",
    "\n",
    "unique_models = results_df_val1['Models_name'].unique()\n",
    "new_df_summary = pd.DataFrame()\n",
    "\n",
    "for model in unique_models:\n",
    "    model_data = results_df_val1[results_df_val1['Models_name'] == model]\n",
    "    model_summary = model_data['Prediction'].value_counts().reset_index()\n",
    "    model_summary.columns = ['Prediction', 'Count']\n",
    "    model_summary['Models_name'] = model\n",
    "    new_df_summary = pd.concat([new_df_summary, model_summary])\n",
    "\n",
    "new_df_summary = new_df_summary.pivot(index='Models_name', columns='Prediction', values='Count').fillna(0).reset_index()\n",
    "new_df_summary\n",
    "\n",
    "#............................................................................................................\n",
    "#............................................................................................................\n",
    "\n",
    "\n",
    "#creation of the Summary data frame [Method-1]\n",
    "\n",
    "# value_counts provides more flexibility and allows additional operations such as renaming columns and resetting the index.\n",
    "new_df_summary = results_df_val1.groupby(['Models_name', 'y_val'])['Prediction'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Rename the columns\n",
    "#new_df_summary.rename(columns={'No': 'y_val_pred_NO', 'Yes': 'y_val_pred_Yes'}, inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "new_df_summary.reset_index(inplace=True)\n",
    "\n",
    "# Print the data frame\n",
    "print(new_df_summary)\n",
    "\n",
    "# .............................................................................................\n",
    "# creation of the Summary1 data frame [Method-2]\n",
    "\n",
    "# # Rename the columns\n",
    "# #new_df_summary1.rename(columns={'No': 'y_val_pred_NO', 'Yes': 'y_val_pred_Yes'}, inplace=True)\n",
    "\n",
    "# # Group by Models, y_val, and comment and count the occurrences\n",
    "\n",
    "# new_df_summary1 = results_df_val1.groupby(['Models_name', 'y_val', 'Prediction']).size().unstack(fill_value=0)\n",
    "\n",
    "# # Reset the index\n",
    "# new_df_summary1.reset_index(inplace=True)\n",
    "\n",
    "# # print\n",
    "# new_df_summary1 \n",
    "#..............................................................................................\n",
    "\n",
    "# creation of the Summary1 data frame [Method-3]\n",
    "# # alternative code\n",
    "# new_df_summary = results_df_val1.pivot_table(index=['Models_name', 'y_val'], columns='Prediction', aggfunc='size', fill_value=0).reset_index()\n",
    "# #new_df_summary\n",
    "\n",
    "# creation of the Summary1 data frame [Method-4]\n",
    "# # another alternative \n",
    "# new_df_summary = pd.crosstab(index=[results_df_val1['Models_name'], results_df_val1['y_val']], columns=results_df_val1['Prediction']).reset_index()\n",
    "# #new_df_summary\n",
    "#.............................................................................................................\n",
    "\n",
    "## Grouping for No/Yes Summing\n",
    "# Group by Models_name and sum the values in No and Yes columns\n",
    "new_df_grouped = new_df_summary.groupby('Models_name')['No', 'Yes'].sum()\n",
    "\n",
    "# Rename the columns\n",
    "#new_df_grouped.rename(columns={' y_val_pred_NO': 'Sum_NO', 'y_val_pred_Yes': 'Sum_Yes'}, inplace=True)\n",
    "\n",
    "# Reset the index to make 'Models_name' a regular column\n",
    "#new_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(new_df_grouped)\n",
    "\n",
    "\n",
    "# Combined Model validation code...........................................................................\n",
    "#..........................................................................................................\n",
    "\n",
    "# # Simplified Format\n",
    "#...........................................................................................................\n",
    "\n",
    "# # Define X_val and y_val\n",
    "# X_val = df2_validation.drop(columns='Target')\n",
    "# y_val = df2_validation['Target']\n",
    "\n",
    "# # List of models\n",
    "# models = [\n",
    "#     RandomForestClassifier(random_state=42),\n",
    "#     GradientBoostingClassifier(random_state=42),\n",
    "#     SVC(random_state=42),\n",
    "#     KNeighborsClassifier(n_neighbors=5),\n",
    "#     DecisionTreeClassifier(random_state=42),\n",
    "#     LogisticRegression(random_state=42),\n",
    "#     xgb.XGBClassifier(random_state=42),\n",
    "#     AdaBoostClassifier(random_state=42),\n",
    "#     GaussianNB(),\n",
    "#     MLPClassifier(random_state=42),\n",
    "#     LGBMClassifier(random_state=42),\n",
    "#     CatBoostClassifier(random_state=42, verbose=False),\n",
    "#     ExtraTreesClassifier(random_state=42)\n",
    "# ]\n",
    "\n",
    "# # Initialize an empty DataFrame for storing the results\n",
    "# results_dfs = []\n",
    "\n",
    "# # Iterate over the models\n",
    "# for model in models:\n",
    "#     # Train the model and predict on the validation set\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_val_pred = model.predict(X_val)\n",
    "\n",
    "#     # Create a dataframe with 'y_val', 'y_val_pred', and 'Prediction' as columns\n",
    "#     model_results = pd.DataFrame({\n",
    "#         'Models_name': [type(model).__name__] * len(y_val),  # model name\n",
    "#         'y_val': y_val,  # true labels\n",
    "#         'Prediction': ['No' if y_true != y_pred else 'Yes' for y_true, y_pred in zip(y_val, y_val_pred)]  # predictions\n",
    "#     })\n",
    "\n",
    "#     # Append the results DataFrame to the list\n",
    "#     results_dfs.append(model_results)\n",
    "    \n",
    "# # Concatenate the results DataFrames into a single DataFrame\n",
    "# results_df_val = pd.concat(results_dfs)\n",
    "\n",
    "# # Create summary DataFrame\n",
    "# new_df_summary = results_df_val.groupby(['Models_name', 'y_val'])['Prediction'].value_counts().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# # Grouping for No/Yes Summing\n",
    "# new_df_grouped = new_df_summary.groupby('Models_name').sum()\n",
    "\n",
    "# # Print the data frames\n",
    "# print(results_df_val)\n",
    "# print(new_df_summary)\n",
    "# print(new_df_grouped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
