{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69521eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this function with the \"ignore\" argument to ignore all warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # If there is a specific type of warning that you want to ignore, you can specify this type in the filterwarnings function\n",
    "# warnings.filterwarnings('ignore', category=UserWarning) # You would replace UserWarning with the specific warning class\n",
    "#                                                         # you wish to ignore.\n",
    "\n",
    "# # For the case of ignoring warnings from specific libraries, you can add the module parameter:\n",
    "# warnings.filterwarnings('ignore', module='numpy')  # Ignore warnings from numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e268bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the CSV file\n",
    "path = 'C:/Users/mdaminulisla.prodhan/All_My_Miscellenous/QSAR_Modeling_python_gl/s10_binary_target_value/unique_smiles_max_zscore_rat_descriptors_non_zero_edited_binary2.csv'\n",
    "target_binary = pd.read_csv(path)\n",
    "df_tb = target_binary\n",
    "#df_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7756381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the index of the DataFrame\n",
    "index = df_tb.index\n",
    "#index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df390ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the first column by positional index (0-based)\n",
    "# first_column = df_tb.iloc[:, 0]\n",
    "# first_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ee45e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SMILES'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the first column\n",
    "first_column_name = df_tb.columns[0]\n",
    "first_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ec1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first column as the index\n",
    "df_tb.set_index(df_tb.columns[0], inplace=True)\n",
    "\n",
    "# Display the modified DataFrame with the updated index\n",
    "#print(df_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b53a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'target'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the first column\n",
    "first_column_name = df_tb.columns[0]\n",
    "first_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a508e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tb\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd2a563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES\n",
      "[H][C@]12Cc3ccc(Oc4cc(C[C@]5([H])N(C)CCc6cc(OC)c(OC)c(Oc7cc1c(CCN2C)cc7OC)c56)ccc4OC)cc3                 3\n",
      "CC1(C)CC[C@@H](CN1)Nc2ncc(c(n2)-c3c[nH]c4c(c(ccc34)C#N)P(C)(C)=O)C(F)(F)F                                3\n",
      "Nc1ncc(cc1-c2nnc(CC3CC3)o2)-c4cnn(c4)C5CCNCC5                                                            3\n",
      "O=C(OCC(COC(=O)c1ccccc1)OC(=O)c2ccccc2)c3ccccc3                                                          3\n",
      "CC(C)Cc1nn(C)c(C)c1NS(=O)(=O)c2c(Cl)cc(cc2Cl)-c3ccnc(c3)N4CCNCC4                                         3\n",
      "                                                                                                        ..\n",
      "[H][C@@]12CC[C@H](C(=O)Cn3ccnc3)[C@@]1(C)CC[C@@]4([H])[C@@]2([H])CC[C@@]5([H])C[C@@](O)(COC)CC[C@]45C    0\n",
      "COc1cc([C@@H](C)C(=O)N2CC[C@@]3(C2)CCc4cc(c(C)nc4N3)-c5ncccn5)c(F)cn1                                    0\n",
      "CC1(C)COc2ccc(F)cc2CN3[C@@H](COc4cn5ncc(C(=O)N1)c5nc34)C(F)F                                             0\n",
      "[Cl-].Cc1cccc(C)c1NC(=O)C[N+]3(Cc2ccccc2)CCCCCC3                                                         0\n",
      "CCc1c2Cn3c(cc4c(COC(=O)[C@]4(O)CC)c3=O)-c2nc5ccc(O)cc15                                                  0\n",
      "Name: target, Length: 429, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# 'target' cplumn encoding\n",
    "\n",
    "#OrdinalEncoder from sklearn.preprocessing doesn't accept a mapping argument. For ordinal encoding with a custom order,\n",
    "#you can use the OrdinalEncoder class from the category_encoders package instead. Here's how you can do it:\n",
    "#First, install the category_encoders package, if it's not already installed. You can do so by running:\n",
    "\n",
    "#!pip install category_encoders\n",
    "\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Assume we load data from a CSV file named 'data.csv'\n",
    "#df = pd.read_csv('data.csv')\n",
    "\n",
    "# Define an ordinal mapping for your classes\n",
    "ordinal_mapping = {'non_toxic': 0, 'mild_toxic': 1, 'toxic': 2, 'extremely_toxic': 3}\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = ce.OrdinalEncoder(mapping=[{'col': 'target', 'mapping': ordinal_mapping}])\n",
    "\n",
    "# Apply encoder to 'target' column\n",
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "\n",
    "# Now 'target' column is ordinal encoded\n",
    "print(df['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88e39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69dcecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.97      0.58        35\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.00      0.00      0.00        17\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.40        86\n",
      "   macro avg       0.10      0.24      0.15        86\n",
      "weighted avg       0.17      0.40      0.24        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#.................Model-RandomForestClassifier....................................................\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@................................................\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assume 'features' is a list of column names of your features\n",
    "# features = ['feat1', 'feat2', ..., 'featn']\n",
    "\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use the model to predict on your test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# You can assess the performance of your model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#......................................................................................\n",
    "# try techniques like oversampling the minority classes (for example, using SMOTE),\n",
    "# undersampling the majority class, or using a different metric that is more suitable \n",
    "# for imbalanced datasets (for example, AUC-ROC, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "887c9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@.........................oversampling........................................@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "# 1. Oversampling with SMOTE:\n",
    "# First, you'll need to install the imbalanced-learn package if you haven't already done so. You can install it using pip:\n",
    "\n",
    "# \"!pip install imbalanced-learn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d110a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({3: 213, 2: 213, 1: 213, 0: 213})\n"
     ]
    }
   ],
   "source": [
    "# Now, let's apply SMOTE (Synthetic Minority Over-sampling Technique) to oversample the minority classes.\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# X = df.drop(columns='target')\n",
    "# y = df['target']\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "# In this code, X and y are your features and target column respectively. After resampling, you'll \n",
    "# have a balanced dataset, which means there will be an equal number of samples for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d085298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  3  8 10]\n",
      " [ 7 32  1  2]\n",
      " [ 4  2 34  2]\n",
      " [ 4  1  4 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57        45\n",
      "           1       0.84      0.76      0.80        42\n",
      "           2       0.72      0.81      0.76        42\n",
      "           3       0.70      0.79      0.74        42\n",
      "\n",
      "    accuracy                           0.72       171\n",
      "   macro avg       0.72      0.72      0.72       171\n",
      "weighted avg       0.72      0.72      0.72       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#  after you have balanced the classes with SMOTE, you can fit the model using the resampled data.\n",
    "\n",
    "# use the stacked model \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base learners\n",
    "base_learners = [   \n",
    "    ('rf_1', RandomForestClassifier(random_state=42)),\n",
    "    ('rf_2', RandomForestClassifier(random_state=44)),\n",
    "    ('KNN_1', KNeighborsClassifier()),\n",
    "    ('KNN_2', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Initialize StackingClassifier with the Meta-Learner\n",
    "stacked_model = StackingCVClassifier(classifiers=[clf for _, clf in base_learners], \n",
    "                                     meta_classifier=RandomForestClassifier(random_state=42), \n",
    "                                     use_features_in_secondary=True, \n",
    "                                     random_state=42)\n",
    "\n",
    "# Fit the model with the training data\n",
    "stacked_model.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "# Make predictions with the test data\n",
    "y_pred = stacked_model.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e26f3e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (582304273.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\mdaminulisla.prodhan\\AppData\\Local\\Temp\\1\\ipykernel_21672\\582304273.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    Confusion matrix:\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#@@@...........the explanation of the above results............................... \n",
    "# The confusion matrix and the classification report you've shared indicates that the performance of your stacking model\n",
    "# has improved after oversampling with SMOTE. Let's dissect these results:\n",
    "\n",
    "Confusion matrix:\n",
    "\n",
    "The rows of the confusion matrix correspond to the actual classes (from 'non_toxic' to 'extremely_toxic' respectively),\n",
    "and the columns correspond to the predicted classes.\n",
    "\n",
    "Class 0 (non_toxic): Out of 45 true instances, the model correctly predicted 23, but also misclassified 22 \n",
    "instances (5 as class 1, 10 as class 2, and 7 as class 3).\n",
    "\n",
    "Class 1 (mild_toxic): Out of 42 true instances, the model correctly predicted 32 and misclassified 10 \n",
    "instances (3 as class 0, 6 as class 2, and 1 as class 3).\n",
    "\n",
    "Class 2 (toxic): Out of 42 true instances, the model correctly predicted 35, but also misclassified 7 \n",
    "instances (5 as class 0 and 2 as class 1).\n",
    "\n",
    "Class 3 (extremely_toxic): Out of 42 true instances, the model correctly predicted 32, but also misclassified 10\n",
    "instances (5 as class 0, 3 as class 1, and 2 as class 2).\n",
    "\n",
    "Classification report:\n",
    "\n",
    "The precision for each class reflects the ability of the classifier not to label a negative sample as positive.\n",
    "The higher this number is, the better.\n",
    "\n",
    "The recall (or sensitivity) shows how many positive samples were correctly identified by the model.\n",
    "The higher this number is, the better.\n",
    "\n",
    "The f1-score is a harmonic mean of precision and recall, providing a balance between them.\n",
    "\n",
    "The support is the number of occurrences of each class in the actual distribution.\n",
    "\n",
    "\n",
    "Summary:\n",
    "\n",
    "The model's accuracy is 71%, which indicates a decent model fit. However, the model seems to perform best for\n",
    "class 3 (extremely_toxic) with the highest F1-score of 0.78.\n",
    "\n",
    "There is room for improvement, especially for class 0 (non_toxic), where the F1-score is lowest (0.57).\n",
    "\n",
    "You might want to experiment with different models for stacking, tune the hyperparameters of your base learners\n",
    "and meta-learner, or try different techniques to handle class imbalance.\n",
    "\n",
    "In addition, you could also consider focusing on improving specific metrics depending on your problem requirements.\n",
    "For instance, if identifying toxic and extremely toxic comments is of the highest priority, you might want to focus on\n",
    "improving recall for classes 2 and 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27414018",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are several approaches you can take to improve the F1-score for the 'non_toxic' class (class 0) \n",
    "in your multiclass classification problem:\n",
    "\n",
    "Model Tuning: Tune the hyperparameters of your classifiers. Grid search or randomized search can help identify the optimal\n",
    "hyperparameters for your model.\n",
    "\n",
    "Change Base Models: You may want to consider changing your base models in the stacking ensemble.Try using more diverse\n",
    "models as base learners to capture different patterns in the data.\n",
    "\n",
    "    \n",
    "Feature Engineering: You could work on creating more informative features, or removing irrelevant ones. Feature importance\n",
    "can be assessed with techniques like permutation importance, SHAP, or feature importance property of models like RandomForest.\n",
    "\n",
    "\n",
    "Data Preprocessing: Check if your data is cleaned properly - are there any outliers or incorrect values that could be\n",
    "affecting the performance? Are there any additional preprocessing steps you could apply, like normalization or \n",
    "standardization?\n",
    "\n",
    "Handling Class Imbalance: Even though you've used SMOTE to oversample the minority classes, the performance for the\n",
    "'non_toxic' class (majority class before oversampling) might have decreased. You might want to adjust the oversampling\n",
    "rates or try a combination of oversampling and undersampling.\n",
    "\n",
    "Cost-Sensitive Learning: You could make use of cost-sensitive learning where you assign a higher cost to misclassifying\n",
    "'non_toxic' instances. Many models have a class_weight parameter that you can adjust.\n",
    "\n",
    "Evaluate Other Metrics: In multiclass classification, the overall accuracy, macro-averaged F1-score or weighted F1-score\n",
    "are usually more meaningful than the F1-score of a single class. You should also keep these overall metrics in mind while\n",
    "trying to optimize the model.\n",
    "\n",
    "Multi-Model Ensemble: Instead of using a stacking ensemble, you can try a multi-model ensemble technique like bagging or\n",
    "boosting. Different ensemble methods have different strengths and can improve the overall performance of your model.\n",
    "\n",
    "Remember, the best way to find the right approach is to experiment with different techniques, and validate the performance\n",
    "using a validation set or cross-validation to prevent overfitting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1df11f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for the \"\"Random Forest Classifier\"\".... \"\"Grid Search-type-1\"\"\"\"\"\"\".....@@###############\n",
    "\n",
    "# Grid Search parameters : n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "\n",
    "# Firstly, we need to set up a parameter grid - a dictionary of parameters and their potential values. Then, we'll instantiate\n",
    "# a GridSearchCV object with the model and the parameter grid. We'll use cross-validation to get the best set of parameters.\n",
    "# Here's how you would do it:\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize a Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Initialize the GridSearch object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='f1_macro')\n",
    "\n",
    "# Fit the GridSearch object to the data\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Get the optimal parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Please note that hyperparameter tuning can be computationally expensive and take a long time to run,\n",
    "# especially if you have a large parameter grid and a large dataset. Make sure to adjust the parameters accordingly\n",
    "# based on your available computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "370c7917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=400)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once you've found the best parameters, you can use them to train your Random Forest model:\n",
    "# Train a new RandomForest model with the best parameters\n",
    "rf_best = RandomForestClassifier(**best_params)\n",
    "rf_best.fit(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52a885b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0  0]\n",
      " [ 0 42  0  0]\n",
      " [ 0  0 42  0]\n",
      " [ 0  0  0 42]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        42\n",
      "           2       1.00      1.00      1.00        42\n",
      "           3       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00       171\n",
      "   macro avg       1.00      1.00      1.00       171\n",
      "weighted avg       1.00      1.00      1.00       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=400, random_state=42)\n",
    "\n",
    "# Fit the model to the resampled data\n",
    "rf_best.fit(X_res, y_res)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix, accuracy, and classification report \n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eac22400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.6744186  0.72093023 0.69411765 0.74117647 0.83529412 0.85882353\n",
      " 0.87058824 0.84705882 0.85882353 0.90588235]\n",
      "Mean Cross-Validation Accuracy: 0.8007113543091655\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation can provide a better measure of your model's performance.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the Random Forest Classifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(rf_best, X_res, y_res, cv=10)\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
    "\n",
    "# Print the mean accuracy\n",
    "print(\"Mean Cross-Validation Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de1ead4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.6744186  0.72093023 0.69411765 0.74117647 0.83529412 0.85882353\n",
      " 0.87058824 0.84705882 0.85882353 0.90588235]\n",
      "Mean Cross-Validation Accuracy: 0.8007113543091655\n"
     ]
    }
   ],
   "source": [
    "# Stratified k-fold cross-validation:\n",
    "# This method can be beneficial for imbalanced datasets \n",
    "# because it maintains the ratio of the classes in each fold.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Initialize the Random Forest Classifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# Define the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Use cross_val_score for model evaluation\n",
    "cross_val_scores = cross_val_score(rf_best, X_res, y_res, cv=skf)\n",
    "\n",
    "# Print the cross-validation accuracy scores and the mean accuracy score\n",
    "print(\"Cross-Validation Accuracy Scores:\", cross_val_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", cross_val_scores.mean())\n",
    "\n",
    "# Stratified k-fold cross-validation keeps the ratio of the classes in each fold consistent with the ratio\n",
    "# in the full dataset. This method can lead to more accurate evaluation results on imbalanced datasets, \n",
    "# because it ensures that each class has a representative amount of samples in each fold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f60cc",
   "metadata": {},
   "source": [
    "The cross-validation results indicate that the model's performance is consistent across different subsets of your data, which is a good sign. However, there is some discrepancy between the perfect accuracy obtained previously and the cross-validation scores. It's crucial to keep in mind that a perfect accuracy score could be a result of overfitting on the training data or a result of testing on a very similar distribution of data as your training set.\n",
    "\n",
    "Cross-validation provides a more robust estimate of the model's ability to generalize to unseen data since it trains and evaluates the model on different subsets of the training data. Thus, the average cross-validation accuracy of approximately 0.79 is a more reliable estimate of your model's expected performance.\n",
    "\n",
    "You can further attempt to improve this by:\n",
    "\n",
    "Further hyperparameter tuning: Try tuning other hyperparameters of the model, for example, max_depth, min_samples_split, etc. for the random forest classifier.\n",
    "\n",
    "Feature Engineering: Creating new features or modifying existing ones can often help improve model performance.\n",
    "\n",
    "Ensemble Methods: Combining predictions from multiple models can often yield better results than using a single model.\n",
    "\n",
    "Exploring other algorithms: Different machine learning algorithms may perform better or worse depending on the specific dataset and problem. Experimenting with different models (SVM, gradient boosting, neural networks etc.) might lead to better results.\n",
    "\n",
    "Stratified k-fold cross-validation: This method can be beneficial for imbalanced datasets because it maintains the ratio of the classes in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 172800 candidates, totalling 518400 fits\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for the \"\"Random Forest Classifier\"\".... \"\"Grid Search-type-2\"\"\"\"\"\"\".....@@###############\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3],\n",
    "    'max_leaf_nodes': [None, 10, 20, 30, 40],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit grid_search to the data\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print the best parameters\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730322f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 max_depth=best_params['max_depth'],\n",
    "                                 min_samples_split=best_params['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                 bootstrap=best_params['bootstrap'],\n",
    "                                 criterion=best_params['criterion'],\n",
    "                                 min_weight_fraction_leaf=best_params['min_weight_fraction_leaf'],\n",
    "                                 max_leaf_nodes=best_params['max_leaf_nodes'],\n",
    "                                 min_impurity_decrease=best_params['min_impurity_decrease'],\n",
    "                                 class_weight=best_params['class_weight'],\n",
    "                                 random_state=42)\n",
    "\n",
    "# Fit the model to the resampled data\n",
    "rf_best.fit(X_res, y_res)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix, accuracy, and classification report \n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5716d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'n_estimators': 1400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for the \"\"Random Forest Classifier\"\".... \"\"RandomizedSearchCV-type-1\"\"\"\"\"\"\".....@@##########\n",
    "\n",
    "# RandomizedSearchCV parameters :n_estimators, max_features,max_depth, min_samples_split, min_samples_leaf, bootstrap\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_res, y_res)\n",
    "\n",
    "# Output the best parameters\n",
    "print(rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a077843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0  0]\n",
      " [ 0 42  0  0]\n",
      " [ 0  0 42  0]\n",
      " [ 0  0  0 42]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        42\n",
      "           2       1.00      1.00      1.00        42\n",
      "           3       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00       171\n",
      "   macro avg       1.00      1.00      1.00       171\n",
      "weighted avg       1.00      1.00      1.00       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params = rf_random.best_params_\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 max_depth=best_params['max_depth'],\n",
    "                                 min_samples_split=best_params['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                 bootstrap=best_params['bootstrap'],\n",
    "                                 random_state=42)\n",
    "\n",
    "# Fit the model to the resampled data\n",
    "rf_best.fit(X_res, y_res)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix, accuracy, and classification report \n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "292e3f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.68604651 0.69767442 0.72941176 0.78823529 0.84705882 0.88235294\n",
      " 0.92941176 0.90588235 0.88235294 0.91764706]\n",
      "Mean Cross-Validation Accuracy: 0.8266073871409029\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-fold Cross Validation-codetype-1: \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Perform cross-validation on the model\n",
    "cv_scores = cross_val_score(rf_best, X_res, y_res, cv=strat_k_fold, scoring='accuracy')\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean Cross-Validation Accuracy: {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "022516b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.68604651 0.69767442 0.72941176 0.78823529 0.84705882 0.88235294\n",
      " 0.92941176 0.90588235 0.88235294 0.91764706]\n",
      "Mean Cross-Validation Accuracy: 0.8266073871409029\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-fold Cross Validation-codetype-2:\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 max_depth=best_params['max_depth'],\n",
    "                                 min_samples_split=best_params['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                 bootstrap=best_params['bootstrap'],\n",
    "                                 random_state=42)\n",
    "\n",
    "# Define the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Perform cross-validation on the model\n",
    "cv_scores = cross_val_score(rf_best, X_res, y_res, cv=skf)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean Cross-Validation Accuracy: {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16df5064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'n_estimators': 100, 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 4, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 45, 'max_features': 'auto', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# # hyperparameter tuning for the \"\"Random Forest Classifier\"\".... \"\"RandomizedSearchCV-type-1\"\"\"\"\"\"\".....@@##########\n",
    "# RandomizedSearchCV parameters : criterion,min_weight_fraction_leaf, max_leaf_nodes,  \n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the hyperparameters\n",
    "hyperparameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_weight_fraction_leaf': np.linspace(0.0, 0.5, 5),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_impurity_decrease': np.linspace(0, 0.2, 4),\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'n_estimators': list(range(100, 301, 100)),\n",
    "    'max_depth': list(range(3, 20)),\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Define the scoring function\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Initialize a RandomizedSearchCV object\n",
    "rf_random = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
    "                               param_distributions=hyperparameters,\n",
    "                               n_iter=100,\n",
    "                               scoring=scorer,\n",
    "                               cv=3,\n",
    "                               verbose=1,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the data\n",
    "rf_random.fit(X_res, y_res)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = rf_random.best_params_\n",
    "\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "46a91282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  0  3  1]\n",
      " [ 0 42  0  0]\n",
      " [ 0  0 42  0]\n",
      " [ 2  1  0 39]]\n",
      "0.9590643274853801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        45\n",
      "           1       0.98      1.00      0.99        42\n",
      "           2       0.93      1.00      0.97        42\n",
      "           3       0.97      0.93      0.95        42\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params = rf_random.best_params_\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 max_depth=best_params['max_depth'],\n",
    "                                 min_samples_split=best_params['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                 bootstrap=best_params['bootstrap'],\n",
    "                                 criterion=best_params['criterion'],\n",
    "                                 min_weight_fraction_leaf=best_params['min_weight_fraction_leaf'],\n",
    "                                 max_leaf_nodes=best_params['max_leaf_nodes'],\n",
    "                                 min_impurity_decrease=best_params['min_impurity_decrease'],\n",
    "                                 class_weight=best_params['class_weight'],\n",
    "                                 random_state=42)\n",
    "\n",
    "# Fit the model to the resampled data\n",
    "rf_best.fit(X_res, y_res)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix, accuracy, and classification report \n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "#  class_weight='balanced' will adjust weights inversely proportional to class frequencies in the input data.\n",
    "# It could be helpful if your classes are imbalanced. If 'None', all classes are supposed to have weight one.\n",
    "# You can also specify your own weights as a dictionary in the form {class_label: weight}. For example,\n",
    "# if you want to double the weight of class 1, you could set class_weight={0: 1, 1: 2}.\n",
    "# In this script, I've included 'None' and 'balanced' in the grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8faf2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.55813953 0.65116279 0.62352941 0.68235294 0.78823529 0.77647059\n",
      " 0.81176471 0.77647059 0.8        0.78823529]\n",
      "Mean Cross-Validation Accuracy: 0.7256361149110807\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-fold Cross Validation-codetype-1: \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Perform cross-validation on the model\n",
    "cv_scores = cross_val_score(rf_best, X_res, y_res, cv=strat_k_fold, scoring='accuracy')\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean Cross-Validation Accuracy: {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34885ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.56976744 0.65116279 0.67058824 0.63529412 0.83529412 0.82352941\n",
      " 0.87058824 0.83529412 0.83529412 0.84705882]\n",
      "Mean Cross-Validation Accuracy: 0.7573871409028727\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-fold Cross Validation-codetype-2:\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters\n",
    "rf_best = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 max_depth=best_params['max_depth'],\n",
    "                                 min_samples_split=best_params['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                 bootstrap=best_params['bootstrap'],\n",
    "                                 random_state=42)\n",
    "\n",
    "# Define the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Perform cross-validation on the model\n",
    "cv_scores = cross_val_score(rf_best, X_res, y_res, cv=skf)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean Cross-Validation Accuracy: {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6d290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d033f9",
   "metadata": {},
   "source": [
    "These are perfect results, with an accuracy of 1.0 and all metrics in the classification report also being 1.0. However, please note that getting a perfect result on your test set may also indicate that your model might be overfitting the data.\n",
    "\n",
    "Overfitting occurs when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. But these concepts do not apply to new data and negatively impact the model's ability to generalize.\n",
    "\n",
    "While the above results seem impressive, you should ensure the model's ability to generalize by doing one of the following:\n",
    "\n",
    "Cross-Validation: This involves splitting the training data into several parts and training the model on different combinations of these parts, then validating the model on the remaining part(s).\n",
    "\n",
    "Train with more data: If possible, providing more data to the model can help it generalize better.\n",
    "\n",
    "Simplify the model: If your model is complex, try to simplify it by selecting fewer features, using simpler models, or tuning hyperparameters to reduce complexity.\n",
    "\n",
    "Use regularization techniques: Regularization methods like L1 or L2 regularization, dropout etc., can help prevent overfitting by adding a penalty for complexity in the model.\n",
    "\n",
    "Remember, while a model that perfectly fits the data might seem like the goal, it's essential that the model also performs well on unseen data. You might want to explore the above options to ensure your model is robust and can generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b47736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@........................................................................"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
